{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "root=\"data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = {}\n",
    "for k in [\"train\", \"val\", \"test\"]:\n",
    "    df[k] = {}\n",
    "    for c in [\"nlfl\", \"mf\"]:\n",
    "        df[k][c] = pd.read_excel(root+f\"{c}_{k}_sample_v3.xlsx\", index_col=0) if c == \"nlfl\" else pd.read_excel(root+f\"{c}_features_{k}_task_C1.xlsx\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in [\"train\", \"val\", \"test\"]:\n",
    "    df[k][\"mf\"] = df[k][\"mf\"].loc[df[k][\"nlfl\"][\"id\"]].reset_index().drop(columns=\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_mf = [c for c in df[\"train\"][\"mf\"].columns if \"linguistic\" not in c]\n",
    "cols_nlfl = [c for c in df[\"train\"][\"nlfl\"].columns if \"chatgpt_\" in c and \"(\" in c]\n",
    "\n",
    "X_train = pd.concat([df[\"train\"][\"nlfl\"][cols_nlfl], df[\"train\"][\"mf\"][cols_mf]], axis=1)\n",
    "X_val = pd.concat([df[\"val\"][\"nlfl\"][cols_nlfl], df[\"val\"][\"mf\"][cols_mf]], axis=1)\n",
    "X_test = pd.concat([df[\"test\"][\"nlfl\"][cols_nlfl], df[\"test\"][\"mf\"][cols_mf]], axis=1)\n",
    "\n",
    "X_train = X_train.loc[:, ~X_train.columns.duplicated()]\n",
    "X_val = X_val.loc[:, ~X_val.columns.duplicated()]\n",
    "X_test = X_test.loc[:, ~X_test.columns.duplicated()]\n",
    "\n",
    "y_train = (df[\"train\"][\"nlfl\"][\"label\"]).apply(int)\n",
    "y_val = (df[\"val\"][\"nlfl\"][\"label\"]).apply(int)\n",
    "y_test = (df[\"test\"][\"nlfl\"][\"label\"]).apply(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chatgpt_v1 (N)</th>\n",
       "      <th>chatgpt_v1 (Y)</th>\n",
       "      <th>chatgpt_v2 (N)</th>\n",
       "      <th>chatgpt_v2 (Y)</th>\n",
       "      <th>chatgpt_v3 (N)</th>\n",
       "      <th>chatgpt_v3 (Y)</th>\n",
       "      <th>chatgpt_v4 (N)</th>\n",
       "      <th>chatgpt_v4 (Y)</th>\n",
       "      <th>chatgpt_v5 (N)</th>\n",
       "      <th>chatgpt_v5 (Y)</th>\n",
       "      <th>...</th>\n",
       "      <th>semantic&lt;&amp;&gt;ratio_ud</th>\n",
       "      <th>semantic&lt;&amp;&gt;ratio_slang</th>\n",
       "      <th>semantic&lt;&amp;&gt;ratio_keywords</th>\n",
       "      <th>semantic&lt;&amp;&gt;ratio_faces</th>\n",
       "      <th>traditional&lt;&amp;&gt;ratio_vowel</th>\n",
       "      <th>traditional&lt;&amp;&gt;ratio_no_numbers</th>\n",
       "      <th>traditional&lt;&amp;&gt;ratio_punct</th>\n",
       "      <th>traditional&lt;&amp;&gt;exist_numbs</th>\n",
       "      <th>traditional&lt;&amp;&gt;max_len_number</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.837045</td>\n",
       "      <td>0.074928</td>\n",
       "      <td>0.874950</td>\n",
       "      <td>0.058878</td>\n",
       "      <td>0.842697</td>\n",
       "      <td>0.072170</td>\n",
       "      <td>0.872751</td>\n",
       "      <td>0.065264</td>\n",
       "      <td>0.944624</td>\n",
       "      <td>0.030124</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.893856</td>\n",
       "      <td>0.042877</td>\n",
       "      <td>0.917656</td>\n",
       "      <td>0.033072</td>\n",
       "      <td>0.899637</td>\n",
       "      <td>0.040439</td>\n",
       "      <td>0.919270</td>\n",
       "      <td>0.035785</td>\n",
       "      <td>0.960115</td>\n",
       "      <td>0.017034</td>\n",
       "      <td>...</td>\n",
       "      <td>0.244898</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>0.044444</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.032000</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.868321</td>\n",
       "      <td>0.068624</td>\n",
       "      <td>0.888266</td>\n",
       "      <td>0.058634</td>\n",
       "      <td>0.876257</td>\n",
       "      <td>0.065225</td>\n",
       "      <td>0.896162</td>\n",
       "      <td>0.053497</td>\n",
       "      <td>0.960362</td>\n",
       "      <td>0.025203</td>\n",
       "      <td>...</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.830221</td>\n",
       "      <td>0.069570</td>\n",
       "      <td>0.884124</td>\n",
       "      <td>0.056058</td>\n",
       "      <td>0.857856</td>\n",
       "      <td>0.066485</td>\n",
       "      <td>0.863737</td>\n",
       "      <td>0.065393</td>\n",
       "      <td>0.939130</td>\n",
       "      <td>0.027966</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.456522</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.037736</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.810073</td>\n",
       "      <td>0.117722</td>\n",
       "      <td>0.856272</td>\n",
       "      <td>0.095584</td>\n",
       "      <td>0.831209</td>\n",
       "      <td>0.106522</td>\n",
       "      <td>0.850595</td>\n",
       "      <td>0.084074</td>\n",
       "      <td>0.957828</td>\n",
       "      <td>0.023903</td>\n",
       "      <td>...</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14452</th>\n",
       "      <td>0.884656</td>\n",
       "      <td>0.133864</td>\n",
       "      <td>0.945302</td>\n",
       "      <td>0.070176</td>\n",
       "      <td>0.900210</td>\n",
       "      <td>0.115229</td>\n",
       "      <td>0.884784</td>\n",
       "      <td>0.121732</td>\n",
       "      <td>0.959946</td>\n",
       "      <td>0.035919</td>\n",
       "      <td>...</td>\n",
       "      <td>0.046512</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.463235</td>\n",
       "      <td>1.025000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14453</th>\n",
       "      <td>0.797020</td>\n",
       "      <td>0.158155</td>\n",
       "      <td>0.883019</td>\n",
       "      <td>0.101123</td>\n",
       "      <td>0.816630</td>\n",
       "      <td>0.145359</td>\n",
       "      <td>0.812437</td>\n",
       "      <td>0.146260</td>\n",
       "      <td>0.944786</td>\n",
       "      <td>0.042557</td>\n",
       "      <td>...</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>0.044444</td>\n",
       "      <td>0.445122</td>\n",
       "      <td>1.022222</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14454</th>\n",
       "      <td>0.833436</td>\n",
       "      <td>0.106078</td>\n",
       "      <td>0.914619</td>\n",
       "      <td>0.062911</td>\n",
       "      <td>0.853236</td>\n",
       "      <td>0.097988</td>\n",
       "      <td>0.850571</td>\n",
       "      <td>0.091232</td>\n",
       "      <td>0.947122</td>\n",
       "      <td>0.033179</td>\n",
       "      <td>...</td>\n",
       "      <td>0.036364</td>\n",
       "      <td>0.039216</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019608</td>\n",
       "      <td>0.483146</td>\n",
       "      <td>1.019608</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14455</th>\n",
       "      <td>0.839765</td>\n",
       "      <td>0.180800</td>\n",
       "      <td>0.940706</td>\n",
       "      <td>0.092435</td>\n",
       "      <td>0.874007</td>\n",
       "      <td>0.157076</td>\n",
       "      <td>0.803798</td>\n",
       "      <td>0.165990</td>\n",
       "      <td>0.936916</td>\n",
       "      <td>0.056630</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.468085</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14456</th>\n",
       "      <td>0.895826</td>\n",
       "      <td>0.092715</td>\n",
       "      <td>0.935934</td>\n",
       "      <td>0.065756</td>\n",
       "      <td>0.908812</td>\n",
       "      <td>0.086468</td>\n",
       "      <td>0.903472</td>\n",
       "      <td>0.082264</td>\n",
       "      <td>0.959712</td>\n",
       "      <td>0.028834</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.016949</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.050847</td>\n",
       "      <td>0.468750</td>\n",
       "      <td>0.949153</td>\n",
       "      <td>0.012876</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14457 rows × 211 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       chatgpt_v1 (N)  chatgpt_v1 (Y)  chatgpt_v2 (N)  chatgpt_v2 (Y)  \\\n",
       "0            0.837045        0.074928        0.874950        0.058878   \n",
       "1            0.893856        0.042877        0.917656        0.033072   \n",
       "2            0.868321        0.068624        0.888266        0.058634   \n",
       "3            0.830221        0.069570        0.884124        0.056058   \n",
       "4            0.810073        0.117722        0.856272        0.095584   \n",
       "...               ...             ...             ...             ...   \n",
       "14452        0.884656        0.133864        0.945302        0.070176   \n",
       "14453        0.797020        0.158155        0.883019        0.101123   \n",
       "14454        0.833436        0.106078        0.914619        0.062911   \n",
       "14455        0.839765        0.180800        0.940706        0.092435   \n",
       "14456        0.895826        0.092715        0.935934        0.065756   \n",
       "\n",
       "       chatgpt_v3 (N)  chatgpt_v3 (Y)  chatgpt_v4 (N)  chatgpt_v4 (Y)  \\\n",
       "0            0.842697        0.072170        0.872751        0.065264   \n",
       "1            0.899637        0.040439        0.919270        0.035785   \n",
       "2            0.876257        0.065225        0.896162        0.053497   \n",
       "3            0.857856        0.066485        0.863737        0.065393   \n",
       "4            0.831209        0.106522        0.850595        0.084074   \n",
       "...               ...             ...             ...             ...   \n",
       "14452        0.900210        0.115229        0.884784        0.121732   \n",
       "14453        0.816630        0.145359        0.812437        0.146260   \n",
       "14454        0.853236        0.097988        0.850571        0.091232   \n",
       "14455        0.874007        0.157076        0.803798        0.165990   \n",
       "14456        0.908812        0.086468        0.903472        0.082264   \n",
       "\n",
       "       chatgpt_v5 (N)  chatgpt_v5 (Y)  ...  semantic<&>ratio_ud  \\\n",
       "0            0.944624        0.030124  ...             0.000000   \n",
       "1            0.960115        0.017034  ...             0.244898   \n",
       "2            0.960362        0.025203  ...             0.437500   \n",
       "3            0.939130        0.027966  ...             0.333333   \n",
       "4            0.957828        0.023903  ...             0.384615   \n",
       "...               ...             ...  ...                  ...   \n",
       "14452        0.959946        0.035919  ...             0.046512   \n",
       "14453        0.944786        0.042557  ...             0.058824   \n",
       "14454        0.947122        0.033179  ...             0.036364   \n",
       "14455        0.936916        0.056630  ...             0.000000   \n",
       "14456        0.959712        0.028834  ...             0.066667   \n",
       "\n",
       "       semantic<&>ratio_slang  semantic<&>ratio_keywords  \\\n",
       "0                    0.000000                   0.000000   \n",
       "1                    0.022222                   0.022222   \n",
       "2                    0.066667                   0.066667   \n",
       "3                    0.133333                   0.000000   \n",
       "4                    0.000000                   0.000000   \n",
       "...                       ...                        ...   \n",
       "14452                0.000000                   0.000000   \n",
       "14453                0.022222                   0.022222   \n",
       "14454                0.039216                   0.000000   \n",
       "14455                0.100000                   0.100000   \n",
       "14456                0.016949                   0.000000   \n",
       "\n",
       "       semantic<&>ratio_faces  traditional<&>ratio_vowel  \\\n",
       "0                    1.000000                   0.333333   \n",
       "1                    0.044444                   0.421053   \n",
       "2                    0.000000                   0.428571   \n",
       "3                    0.000000                   0.456522   \n",
       "4                    0.083333                   0.523810   \n",
       "...                       ...                        ...   \n",
       "14452                0.050000                   0.463235   \n",
       "14453                0.044444                   0.445122   \n",
       "14454                0.019608                   0.483146   \n",
       "14455                0.100000                   0.468085   \n",
       "14456                0.050847                   0.468750   \n",
       "\n",
       "       traditional<&>ratio_no_numbers  traditional<&>ratio_punct  \\\n",
       "0                            1.000000                   0.000000   \n",
       "1                            0.555556                   0.032000   \n",
       "2                            0.533333                   0.045455   \n",
       "3                            0.800000                   0.037736   \n",
       "4                            0.500000                   0.027027   \n",
       "...                               ...                        ...   \n",
       "14452                        1.025000                   0.000000   \n",
       "14453                        1.022222                   0.000000   \n",
       "14454                        1.019608                   0.000000   \n",
       "14455                        1.000000                   0.000000   \n",
       "14456                        0.949153                   0.012876   \n",
       "\n",
       "       traditional<&>exist_numbs  traditional<&>max_len_number  label  \n",
       "0                              1                             1      0  \n",
       "1                              1                             4      0  \n",
       "2                              1                             3      0  \n",
       "3                              1                             2      0  \n",
       "4                              1                             3      0  \n",
       "...                          ...                           ...    ...  \n",
       "14452                          1                             2      0  \n",
       "14453                          1                             2      0  \n",
       "14454                          1                             2      0  \n",
       "14455                          0                             0      0  \n",
       "14456                          1                             3      0  \n",
       "\n",
       "[14457 rows x 211 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test_sample = pd.concat([\n",
    "    pd.concat([X_train, y_train], axis=1), \n",
    "    pd.concat([X_val, y_val], axis=1)\n",
    "    ], ignore_index=True)\n",
    "train_test_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9440409490212354\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9324    0.9686    0.9501       541\n",
      "           1     0.8522    0.7206    0.7809       136\n",
      "\n",
      "    accuracy                         0.9188       677\n",
      "   macro avg     0.8923    0.8446    0.8655       677\n",
      "weighted avg     0.9163    0.9188    0.9161       677\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'0': {'precision': 0.9323843416370107,\n",
       "  'recall': 0.9685767097966729,\n",
       "  'f1-score': 0.9501359927470535,\n",
       "  'support': 541},\n",
       " '1': {'precision': 0.8521739130434782,\n",
       "  'recall': 0.7205882352941176,\n",
       "  'f1-score': 0.7808764940239042,\n",
       "  'support': 136},\n",
       " 'accuracy': 0.9187592319054653,\n",
       " 'macro avg': {'precision': 0.8922791273402444,\n",
       "  'recall': 0.8445824725453952,\n",
       "  'f1-score': 0.8655062433854789,\n",
       "  'support': 677},\n",
       " 'weighted avg': {'precision': 0.9162711683892699,\n",
       "  'recall': 0.9187592319054653,\n",
       "  'f1-score': 0.9161340845840574,\n",
       "  'support': 677}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F_features1 = np.load(\"output/nllf_features.npy\")\n",
    "F_features2 = np.load(\"output/mf_features.npy\")\n",
    "features1, counts1 = np.unique(F_features1, return_counts=True)\n",
    "features2, counts2 = np.unique(F_features2, return_counts=True)\n",
    "k = 5\n",
    "new_best_features = list(features1[counts1>=k]) + list(features2[counts2>=k])\n",
    "\n",
    "X_train_val = train_test_sample.drop(columns=\"label\")\n",
    "y_train_val = train_test_sample[\"label\"]\n",
    "\n",
    "clf = DecisionTreeClassifier(random_state=42, max_depth=5)\n",
    "clf.fit(X_train_val[new_best_features], y_train_val)\n",
    "print(clf.score(X_train_val[new_best_features], y_train_val))\n",
    "print(classification_report(y_test, clf.predict(X_test[new_best_features]), digits=4))\n",
    "o = classification_report(y_test, clf.predict(X_test[new_best_features]), digits=4, output_dict=True)\n",
    "o"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "net",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
