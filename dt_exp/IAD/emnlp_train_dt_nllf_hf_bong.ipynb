{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "root=\"data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = {}\n",
    "for k in [\"train\", \"val\", \"test\"]:\n",
    "    df[k] = {}\n",
    "    for c in [\"nlfl\", \"mf\", \"bong\"]:\n",
    "        df[k][c] = pd.read_excel(root+f\"{c}_{k}_sample_v3.xlsx\", index_col=0) if c == \"nlfl\" else pd.read_excel(root+f\"{c}_features_{k}_task_C1.xlsx\", index_col=0) if c == \"mf\" else pd.read_excel(root+f\"{c}_{k}.xlsx\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in [\"train\", \"val\", \"test\"]:\n",
    "    df[k][\"mf\"] = df[k][\"mf\"].loc[df[k][\"nlfl\"][\"id\"]].reset_index().drop(columns=\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_mf = [c for c in df[\"train\"][\"mf\"].columns if \"linguistic\" not in c]\n",
    "cols_nlfl = [c for c in df[\"train\"][\"nlfl\"].columns if \"chatgpt_\" in c and \"(\" in c]\n",
    "cols_bong = [c for c in df[\"train\"][\"bong\"].columns if c not in [\"id\", \"label\"]]\n",
    "\n",
    "X_train = pd.concat([df[\"train\"][\"nlfl\"][cols_nlfl], df[\"train\"][\"mf\"][cols_mf], df[\"train\"][\"bong\"][cols_bong]], axis=1)\n",
    "X_val = pd.concat([df[\"val\"][\"nlfl\"][cols_nlfl], df[\"val\"][\"mf\"][cols_mf], df[\"val\"][\"bong\"][cols_bong]], axis=1)\n",
    "X_test = pd.concat([df[\"test\"][\"nlfl\"][cols_nlfl], df[\"test\"][\"mf\"][cols_mf], df[\"test\"][\"bong\"][cols_bong]], axis=1)\n",
    "\n",
    "X_train = X_train.loc[:, ~X_train.columns.duplicated()]\n",
    "X_val = X_val.loc[:, ~X_val.columns.duplicated()]\n",
    "X_test = X_test.loc[:, ~X_test.columns.duplicated()]\n",
    "\n",
    "y_train = (df[\"train\"][\"nlfl\"][\"label\"]).apply(int)\n",
    "y_val = (df[\"val\"][\"nlfl\"][\"label\"]).apply(int)\n",
    "y_test = (df[\"test\"][\"nlfl\"][\"label\"]).apply(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chatgpt_v1 (N)</th>\n",
       "      <th>chatgpt_v1 (Y)</th>\n",
       "      <th>chatgpt_v2 (N)</th>\n",
       "      <th>chatgpt_v2 (Y)</th>\n",
       "      <th>chatgpt_v3 (N)</th>\n",
       "      <th>chatgpt_v3 (Y)</th>\n",
       "      <th>chatgpt_v4 (N)</th>\n",
       "      <th>chatgpt_v4 (Y)</th>\n",
       "      <th>chatgpt_v5 (N)</th>\n",
       "      <th>chatgpt_v5 (Y)</th>\n",
       "      <th>...</th>\n",
       "      <th>vuelto</th>\n",
       "      <th>ya</th>\n",
       "      <th>ya que</th>\n",
       "      <th>yo</th>\n",
       "      <th>yo creo</th>\n",
       "      <th>yo lo</th>\n",
       "      <th>yo multiplique</th>\n",
       "      <th>yo reste</th>\n",
       "      <th>yo sume</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.837045</td>\n",
       "      <td>0.074928</td>\n",
       "      <td>0.874950</td>\n",
       "      <td>0.058878</td>\n",
       "      <td>0.842697</td>\n",
       "      <td>0.072170</td>\n",
       "      <td>0.872751</td>\n",
       "      <td>0.065264</td>\n",
       "      <td>0.944624</td>\n",
       "      <td>0.030124</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.893856</td>\n",
       "      <td>0.042877</td>\n",
       "      <td>0.917656</td>\n",
       "      <td>0.033072</td>\n",
       "      <td>0.899637</td>\n",
       "      <td>0.040439</td>\n",
       "      <td>0.919270</td>\n",
       "      <td>0.035785</td>\n",
       "      <td>0.960115</td>\n",
       "      <td>0.017034</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.868321</td>\n",
       "      <td>0.068624</td>\n",
       "      <td>0.888266</td>\n",
       "      <td>0.058634</td>\n",
       "      <td>0.876257</td>\n",
       "      <td>0.065225</td>\n",
       "      <td>0.896162</td>\n",
       "      <td>0.053497</td>\n",
       "      <td>0.960362</td>\n",
       "      <td>0.025203</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.830221</td>\n",
       "      <td>0.069570</td>\n",
       "      <td>0.884124</td>\n",
       "      <td>0.056058</td>\n",
       "      <td>0.857856</td>\n",
       "      <td>0.066485</td>\n",
       "      <td>0.863737</td>\n",
       "      <td>0.065393</td>\n",
       "      <td>0.939130</td>\n",
       "      <td>0.027966</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.810073</td>\n",
       "      <td>0.117722</td>\n",
       "      <td>0.856272</td>\n",
       "      <td>0.095584</td>\n",
       "      <td>0.831209</td>\n",
       "      <td>0.106522</td>\n",
       "      <td>0.850595</td>\n",
       "      <td>0.084074</td>\n",
       "      <td>0.957828</td>\n",
       "      <td>0.023903</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14452</th>\n",
       "      <td>0.884656</td>\n",
       "      <td>0.133864</td>\n",
       "      <td>0.945302</td>\n",
       "      <td>0.070176</td>\n",
       "      <td>0.900210</td>\n",
       "      <td>0.115229</td>\n",
       "      <td>0.884784</td>\n",
       "      <td>0.121732</td>\n",
       "      <td>0.959946</td>\n",
       "      <td>0.035919</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14453</th>\n",
       "      <td>0.797020</td>\n",
       "      <td>0.158155</td>\n",
       "      <td>0.883019</td>\n",
       "      <td>0.101123</td>\n",
       "      <td>0.816630</td>\n",
       "      <td>0.145359</td>\n",
       "      <td>0.812437</td>\n",
       "      <td>0.146260</td>\n",
       "      <td>0.944786</td>\n",
       "      <td>0.042557</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.251441</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14454</th>\n",
       "      <td>0.833436</td>\n",
       "      <td>0.106078</td>\n",
       "      <td>0.914619</td>\n",
       "      <td>0.062911</td>\n",
       "      <td>0.853236</td>\n",
       "      <td>0.097988</td>\n",
       "      <td>0.850571</td>\n",
       "      <td>0.091232</td>\n",
       "      <td>0.947122</td>\n",
       "      <td>0.033179</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14455</th>\n",
       "      <td>0.839765</td>\n",
       "      <td>0.180800</td>\n",
       "      <td>0.940706</td>\n",
       "      <td>0.092435</td>\n",
       "      <td>0.874007</td>\n",
       "      <td>0.157076</td>\n",
       "      <td>0.803798</td>\n",
       "      <td>0.165990</td>\n",
       "      <td>0.936916</td>\n",
       "      <td>0.056630</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14456</th>\n",
       "      <td>0.895826</td>\n",
       "      <td>0.092715</td>\n",
       "      <td>0.935934</td>\n",
       "      <td>0.065756</td>\n",
       "      <td>0.908812</td>\n",
       "      <td>0.086468</td>\n",
       "      <td>0.903472</td>\n",
       "      <td>0.082264</td>\n",
       "      <td>0.959712</td>\n",
       "      <td>0.028834</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14457 rows Ã— 1211 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       chatgpt_v1 (N)  chatgpt_v1 (Y)  chatgpt_v2 (N)  chatgpt_v2 (Y)  \\\n",
       "0            0.837045        0.074928        0.874950        0.058878   \n",
       "1            0.893856        0.042877        0.917656        0.033072   \n",
       "2            0.868321        0.068624        0.888266        0.058634   \n",
       "3            0.830221        0.069570        0.884124        0.056058   \n",
       "4            0.810073        0.117722        0.856272        0.095584   \n",
       "...               ...             ...             ...             ...   \n",
       "14452        0.884656        0.133864        0.945302        0.070176   \n",
       "14453        0.797020        0.158155        0.883019        0.101123   \n",
       "14454        0.833436        0.106078        0.914619        0.062911   \n",
       "14455        0.839765        0.180800        0.940706        0.092435   \n",
       "14456        0.895826        0.092715        0.935934        0.065756   \n",
       "\n",
       "       chatgpt_v3 (N)  chatgpt_v3 (Y)  chatgpt_v4 (N)  chatgpt_v4 (Y)  \\\n",
       "0            0.842697        0.072170        0.872751        0.065264   \n",
       "1            0.899637        0.040439        0.919270        0.035785   \n",
       "2            0.876257        0.065225        0.896162        0.053497   \n",
       "3            0.857856        0.066485        0.863737        0.065393   \n",
       "4            0.831209        0.106522        0.850595        0.084074   \n",
       "...               ...             ...             ...             ...   \n",
       "14452        0.900210        0.115229        0.884784        0.121732   \n",
       "14453        0.816630        0.145359        0.812437        0.146260   \n",
       "14454        0.853236        0.097988        0.850571        0.091232   \n",
       "14455        0.874007        0.157076        0.803798        0.165990   \n",
       "14456        0.908812        0.086468        0.903472        0.082264   \n",
       "\n",
       "       chatgpt_v5 (N)  chatgpt_v5 (Y)  ...  vuelto   ya  ya que        yo  \\\n",
       "0            0.944624        0.030124  ...     0.0  0.0     0.0  0.000000   \n",
       "1            0.960115        0.017034  ...     0.0  0.0     0.0  0.000000   \n",
       "2            0.960362        0.025203  ...     0.0  0.0     0.0  0.000000   \n",
       "3            0.939130        0.027966  ...     0.0  0.0     0.0  0.000000   \n",
       "4            0.957828        0.023903  ...     0.0  0.0     0.0  0.000000   \n",
       "...               ...             ...  ...     ...  ...     ...       ...   \n",
       "14452        0.959946        0.035919  ...     0.0  0.0     0.0  0.000000   \n",
       "14453        0.944786        0.042557  ...     0.0  0.0     0.0  0.251441   \n",
       "14454        0.947122        0.033179  ...     0.0  0.0     0.0  0.000000   \n",
       "14455        0.936916        0.056630  ...     0.0  0.0     0.0  0.000000   \n",
       "14456        0.959712        0.028834  ...     0.0  0.0     0.0  0.000000   \n",
       "\n",
       "       yo creo  yo lo  yo multiplique  yo reste  yo sume  label  \n",
       "0          0.0    0.0             0.0       0.0      0.0      0  \n",
       "1          0.0    0.0             0.0       0.0      0.0      0  \n",
       "2          0.0    0.0             0.0       0.0      0.0      0  \n",
       "3          0.0    0.0             0.0       0.0      0.0      0  \n",
       "4          0.0    0.0             0.0       0.0      0.0      0  \n",
       "...        ...    ...             ...       ...      ...    ...  \n",
       "14452      0.0    0.0             0.0       0.0      0.0      0  \n",
       "14453      0.0    0.0             0.0       0.0      0.0      0  \n",
       "14454      0.0    0.0             0.0       0.0      0.0      0  \n",
       "14455      0.0    0.0             0.0       0.0      0.0      0  \n",
       "14456      0.0    0.0             0.0       0.0      0.0      0  \n",
       "\n",
       "[14457 rows x 1211 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_test_sample = pd.concat([\n",
    "    pd.concat([X_train, y_train], axis=1), \n",
    "    pd.concat([X_val, y_val], axis=1)\n",
    "    ], ignore_index=True)\n",
    "train_test_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9457702151207028\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9324    0.9686    0.9501       541\n",
      "           1     0.8522    0.7206    0.7809       136\n",
      "\n",
      "    accuracy                         0.9188       677\n",
      "   macro avg     0.8923    0.8446    0.8655       677\n",
      "weighted avg     0.9163    0.9188    0.9161       677\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'0': {'precision': 0.9323843416370107,\n",
       "  'recall': 0.9685767097966729,\n",
       "  'f1-score': 0.9501359927470535,\n",
       "  'support': 541},\n",
       " '1': {'precision': 0.8521739130434782,\n",
       "  'recall': 0.7205882352941176,\n",
       "  'f1-score': 0.7808764940239042,\n",
       "  'support': 136},\n",
       " 'accuracy': 0.9187592319054653,\n",
       " 'macro avg': {'precision': 0.8922791273402444,\n",
       "  'recall': 0.8445824725453952,\n",
       "  'f1-score': 0.8655062433854789,\n",
       "  'support': 677},\n",
       " 'weighted avg': {'precision': 0.9162711683892699,\n",
       "  'recall': 0.9187592319054653,\n",
       "  'f1-score': 0.9161340845840574,\n",
       "  'support': 677}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F_features1 = np.load(\"output/nllf_features.npy\")\n",
    "F_features2 = np.load(\"output/mf_features.npy\")\n",
    "F_features3 = np.load(\"output/bong_features.npy\")\n",
    "\n",
    "features1, counts1 = np.unique(F_features1, return_counts=True)\n",
    "features2, counts2 = np.unique(F_features2, return_counts=True)\n",
    "features3, counts3 = np.unique(F_features3, return_counts=True)\n",
    "k = 5\n",
    "new_best_features = list(features1[counts1>=k]) + list(features2[counts2>=k]) + list(features3[counts3>=k]) \n",
    "\n",
    "X_train_val = train_test_sample.drop(columns=\"label\")\n",
    "y_train_val = train_test_sample[\"label\"]\n",
    "\n",
    "clf = DecisionTreeClassifier(random_state=42, max_depth=5)\n",
    "clf.fit(X_train_val[new_best_features], y_train_val)\n",
    "print(clf.score(X_train_val[new_best_features], y_train_val))\n",
    "print(classification_report(y_test, clf.predict(X_test[new_best_features]), digits=4))\n",
    "o = classification_report(y_test, clf.predict(X_test[new_best_features]), digits=4, output_dict=True)\n",
    "o"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "net",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
