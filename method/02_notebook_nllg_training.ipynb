{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.cuda.is_available()\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "from class_nllfg_training import NLLFGeneratorTraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare bsqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bsqs = [\n",
    "    \"Does the abstract discuss agroecological practices?\",\n",
    "    \"Does the abstract cover climate change mitigation?\",\n",
    "    \"Does the abstract cover climate change adaptation?\",\n",
    "    \"Does the abstract comprehensively cover climate change and environmental aspects?\",\n",
    "    \"Does the abstract address greenhouse gas emissions?\",\n",
    "    \"Does the abstract assess agroecological practices' impact on climate change?\",\n",
    "    \"Does the abstract provide relevance to stakeholders and farmers in the agricultural sector?\",\n",
    "    \"Does the abstract address limitations, challenges, and potential risks?\",\n",
    "    \"Does the abstract address policy implications?\",\n",
    "    \"Does the abstract have a specific geographic focus?\",\n",
    "]\n",
    "\n",
    "dict_bsqs = {f\"q{i}\": bsq for i, bsq in enumerate(bsqs)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = NLLFGeneratorTraining(\n",
    "    dict_bsqs = dict_bsqs, \n",
    "    root_labels = \"01_labels\", \n",
    "    sentence_col_name = \"abstract\", \n",
    "    model_name = \"bert-base-uncased\",\n",
    "    maxlen_s=489,\n",
    "    maxlen_bsq=20,\n",
    "    batch_size=8\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5882    0.5000    0.5405        20\n",
      "           1     0.8795    0.9125    0.8957        80\n",
      "\n",
      "    accuracy                         0.8300       100\n",
      "   macro avg     0.7339    0.7063    0.7181       100\n",
      "weighted avg     0.8213    0.8300    0.8247       100\n",
      "\n",
      "Epoch 1 complete! Validation Accuracy : 0.826923131942749, Validation Loss : 0.48384389309928966\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6000    0.4500    0.5143        20\n",
      "           1     0.8706    0.9250    0.8970        80\n",
      "\n",
      "    accuracy                         0.8300       100\n",
      "   macro avg     0.7353    0.6875    0.7056       100\n",
      "weighted avg     0.8165    0.8300    0.8204       100\n",
      "\n",
      "Epoch 2 complete! Validation Accuracy : 0.817307710647583, Validation Loss : 0.4121549343332075\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6667    0.4000    0.5000        20\n",
      "           1     0.8636    0.9500    0.9048        80\n",
      "\n",
      "    accuracy                         0.8400       100\n",
      "   macro avg     0.7652    0.6750    0.7024       100\n",
      "weighted avg     0.8242    0.8400    0.8238       100\n",
      "\n",
      "Epoch 3 complete! Validation Accuracy : 0.8461538553237915, Validation Loss : 0.3861802219896792\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5625    0.4500    0.5000        20\n",
      "           1     0.8690    0.9125    0.8902        80\n",
      "\n",
      "    accuracy                         0.8200       100\n",
      "   macro avg     0.7158    0.6813    0.6951       100\n",
      "weighted avg     0.8077    0.8200    0.8122       100\n",
      "\n",
      "Epoch 4 complete! Validation Accuracy : 0.7980769276618958, Validation Loss : 0.5267057091337987\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5417    0.6500    0.5909        20\n",
      "           1     0.9079    0.8625    0.8846        80\n",
      "\n",
      "    accuracy                         0.8200       100\n",
      "   macro avg     0.7248    0.7563    0.7378       100\n",
      "weighted avg     0.8346    0.8200    0.8259       100\n",
      "\n",
      "Epoch 5 complete! Validation Accuracy : 0.7884615659713745, Validation Loss : 0.4931469093023155\n"
     ]
    }
   ],
   "source": [
    "training.train(epochs=5, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "training.save(\n",
    "    hf_token = \"<HF-TOKEN>\",  # https://huggingface.co/settings/tokens\n",
    "    repo_name = \"example_juke\",\n",
    "    username= \"<HF-USERNAME>\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
