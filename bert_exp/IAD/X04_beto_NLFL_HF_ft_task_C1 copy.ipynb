{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names = {\n",
    "    \"train\": \"data/train_task_C1.xlsx\",\n",
    "    \"test\": \"data/test_task_C1.xlsx\",\n",
    "    \"val\": \"data/val_task_C1.xlsx\",\n",
    "    \"mf_train\": \"data/mf_features_train_task_C1.xlsx\",\n",
    "    \"mf_test\": \"data/mf_features_test_task_C1.xlsx\",\n",
    "    \"mf_val\": \"data/mf_features_val_task_C1.xlsx\",\n",
    "    \"nlfl_train\": \"data/nlfl_train_sample_v3.xlsx\",\n",
    "    \"nlfl_test\": \"data/nlfl_test_sample_v3.xlsx\",\n",
    "    \"nlfl_val\": \"data/nlfl_val_sample_v3.xlsx\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_train = pd.read_excel(file_names[\"train\"], index_col=\"id\").sample(frac = 1, random_state=2022).reset_index()\n",
    "A_val = pd.read_excel(file_names[\"val\"])\n",
    "A_test = pd.read_excel(file_names[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 51s, sys: 164 ms, total: 1min 51s\n",
      "Wall time: 1min 51s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "mf_A_train = pd.read_excel(file_names[\"mf_train\"])\n",
    "mf_A_val = pd.read_excel(file_names[\"mf_val\"])\n",
    "mf_A_test = pd.read_excel(file_names[\"mf_test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 74.3 ms, sys: 28 ms, total: 102 ms\n",
      "Wall time: 102 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "mf_A_train = mf_A_train.set_index(\"id\").loc[A_train[\"id\"]].reset_index()\n",
    "mf_A_test = mf_A_test.set_index(\"id\").loc[A_test[\"id\"]].reset_index()\n",
    "mf_A_val = mf_A_val.set_index(\"id\").loc[A_val[\"id\"]].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14.4 s, sys: 36.1 ms, total: 14.5 s\n",
      "Wall time: 14.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "nlfl_A_train = pd.read_excel(file_names[\"nlfl_train\"])\n",
    "nlfl_A_val = pd.read_excel(file_names[\"nlfl_val\"])\n",
    "nlfl_A_test = pd.read_excel(file_names[\"nlfl_test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13.2 ms, sys: 346 µs, total: 13.5 ms\n",
      "Wall time: 12.5 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "nlfl_A_train = nlfl_A_train.set_index(\"id\").loc[A_train[\"id\"]].reset_index()\n",
    "nlfl_A_test = nlfl_A_test.set_index(\"id\").loc[A_test[\"id\"]].reset_index()\n",
    "nlfl_A_val = nlfl_A_val.set_index(\"id\").loc[A_val[\"id\"]].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['chatgpt_v1 (N)',\n",
       " 'chatgpt_v1 (Y)',\n",
       " 'chatgpt_v2 (N)',\n",
       " 'chatgpt_v2 (Y)',\n",
       " 'chatgpt_v3 (N)',\n",
       " 'chatgpt_v3 (Y)',\n",
       " 'chatgpt_v4 (N)',\n",
       " 'chatgpt_v4 (Y)',\n",
       " 'chatgpt_v5 (N)',\n",
       " 'chatgpt_v5 (Y)',\n",
       " 'chatgpt_v6 (N)',\n",
       " 'chatgpt_v6 (Y)',\n",
       " 'chatgpt_v7 (N)',\n",
       " 'chatgpt_v7 (Y)',\n",
       " 'chatgpt_v8 (N)',\n",
       " 'chatgpt_v8 (Y)',\n",
       " 'chatgpt_v9 (N)',\n",
       " 'chatgpt_v9 (Y)',\n",
       " 'chatgpt_v10 (N)',\n",
       " 'chatgpt_v10 (Y)',\n",
       " 'chatgpt_v5_1 (N)',\n",
       " 'chatgpt_v5_1 (Y)',\n",
       " 'chatgpt_v5_2 (N)',\n",
       " 'chatgpt_v5_2 (Y)',\n",
       " 'chatgpt_v5_3 (N)',\n",
       " 'chatgpt_v5_3 (Y)',\n",
       " 'chatgpt_v5_4 (N)',\n",
       " 'chatgpt_v5_4 (Y)',\n",
       " 'chatgpt_v5_5 (N)',\n",
       " 'chatgpt_v5_5 (Y)',\n",
       " 'chatgpt_v6_1 (N)',\n",
       " 'chatgpt_v6_1 (Y)',\n",
       " 'chatgpt_v6_2 (N)',\n",
       " 'chatgpt_v6_2 (Y)',\n",
       " 'chatgpt_v6_3 (N)',\n",
       " 'chatgpt_v6_3 (Y)',\n",
       " 'chatgpt_v6_4 (N)',\n",
       " 'chatgpt_v6_4 (Y)',\n",
       " 'chatgpt_Q3_1 (N)',\n",
       " 'chatgpt_Q3_1 (Y)',\n",
       " 'chatgpt_Q3_2 (N)',\n",
       " 'chatgpt_Q3_2 (Y)',\n",
       " 'chatgpt_Q3_3 (N)',\n",
       " 'chatgpt_Q3_3 (Y)',\n",
       " 'chatgpt_Q3_4 (N)',\n",
       " 'chatgpt_Q3_4 (Y)',\n",
       " 'chatgpt_Q3_5 (N)',\n",
       " 'chatgpt_Q3_5 (Y)',\n",
       " 'chatgpt_Q3_6 (N)',\n",
       " 'chatgpt_Q3_6 (Y)',\n",
       " 'chatgpt_Q3_7 (N)',\n",
       " 'chatgpt_Q3_7 (Y)',\n",
       " 'chatgpt_Q3_8 (N)',\n",
       " 'chatgpt_Q3_8 (Y)',\n",
       " 'chatgpt_Q3_9 (N)',\n",
       " 'chatgpt_Q3_9 (Y)',\n",
       " 'chatgpt_Q3_10 (N)',\n",
       " 'chatgpt_Q3_10 (Y)',\n",
       " 'chatgpt_Q3_11 (N)',\n",
       " 'chatgpt_Q3_11 (Y)',\n",
       " 'chatgpt_Q3_12 (N)',\n",
       " 'chatgpt_Q3_12 (Y)',\n",
       " 'chatgpt_Q3_13 (N)',\n",
       " 'chatgpt_Q3_13 (Y)',\n",
       " 'chatgpt_Q3_14 (N)',\n",
       " 'chatgpt_Q3_14 (Y)',\n",
       " 'chatgpt_Q3_15 (N)',\n",
       " 'chatgpt_Q3_15 (Y)',\n",
       " 'chatgpt_Q3_16 (N)',\n",
       " 'chatgpt_Q3_16 (Y)',\n",
       " 'chatgpt_Q3_7_e1 (N)',\n",
       " 'chatgpt_Q3_7_e1 (Y)',\n",
       " 'chatgpt_Q3_7_e2 (N)',\n",
       " 'chatgpt_Q3_7_e2 (Y)',\n",
       " 'chatgpt_Q3_7_e3 (N)',\n",
       " 'chatgpt_Q3_7_e3 (Y)',\n",
       " 'chatgpt_Q3_7_e4 (N)',\n",
       " 'chatgpt_Q3_7_e4 (Y)',\n",
       " 'chatgpt_Q3_7_e5 (N)',\n",
       " 'chatgpt_Q3_7_e5 (Y)',\n",
       " 'chatgpt_10_e1 (N)',\n",
       " 'chatgpt_10_e1 (Y)',\n",
       " 'chatgpt_10_e2 (N)',\n",
       " 'chatgpt_10_e2 (Y)',\n",
       " 'chatgpt_10_e3 (N)',\n",
       " 'chatgpt_10_e3 (Y)',\n",
       " 'chatgpt_10_e4 (N)',\n",
       " 'chatgpt_10_e4 (Y)',\n",
       " 'chatgpt_10_e5 (N)',\n",
       " 'chatgpt_10_e5 (Y)',\n",
       " 'chatgpt_7_e1 (N)',\n",
       " 'chatgpt_7_e1 (Y)',\n",
       " 'chatgpt_7_e2 (N)',\n",
       " 'chatgpt_7_e2 (Y)',\n",
       " 'chatgpt_7_e3 (N)',\n",
       " 'chatgpt_7_e3 (Y)',\n",
       " 'chatgpt_7_e4 (N)',\n",
       " 'chatgpt_7_e4 (Y)',\n",
       " 'chatgpt_7_e5 (N)',\n",
       " 'chatgpt_7_e5 (Y)',\n",
       " 'chatgpt_Q3_4_e1 (N)',\n",
       " 'chatgpt_Q3_4_e1 (Y)',\n",
       " 'chatgpt_Q3_4_e2 (N)',\n",
       " 'chatgpt_Q3_4_e2 (Y)',\n",
       " 'chatgpt_Q3_4_e3 (N)',\n",
       " 'chatgpt_Q3_4_e3 (Y)',\n",
       " 'chatgpt_Q3_4_e4 (N)',\n",
       " 'chatgpt_Q3_4_e4 (Y)',\n",
       " 'chatgpt_Q3_4_e5 (N)',\n",
       " 'chatgpt_Q3_4_e5 (Y)',\n",
       " 'chatgpt_Q3_5_e1 (N)',\n",
       " 'chatgpt_Q3_5_e1 (Y)',\n",
       " 'chatgpt_Q3_5_e2 (N)',\n",
       " 'chatgpt_Q3_5_e2 (Y)',\n",
       " 'chatgpt_Q3_5_e3 (N)',\n",
       " 'chatgpt_Q3_5_e3 (Y)',\n",
       " 'chatgpt_Q3_5_e4 (N)',\n",
       " 'chatgpt_Q3_5_e4 (Y)',\n",
       " 'chatgpt_Q3_5_e5 (N)',\n",
       " 'chatgpt_Q3_5_e5 (Y)',\n",
       " 'chatgpt_HF_1 (N)',\n",
       " 'chatgpt_HF_1 (Y)',\n",
       " 'chatgpt_HF_2 (N)',\n",
       " 'chatgpt_HF_2 (Y)',\n",
       " 'chatgpt_HF_3 (N)',\n",
       " 'chatgpt_HF_3 (Y)',\n",
       " 'chatgpt_HF_4 (N)',\n",
       " 'chatgpt_HF_4 (Y)',\n",
       " 'chatgpt_HF_5 (N)',\n",
       " 'chatgpt_HF_5 (Y)',\n",
       " 'chatgpt_HF_6 (N)',\n",
       " 'chatgpt_HF_6 (Y)',\n",
       " 'chatgpt_SP_1 (N)',\n",
       " 'chatgpt_SP_1 (Y)',\n",
       " 'chatgpt_SP_2 (N)',\n",
       " 'chatgpt_SP_2 (Y)',\n",
       " 'chatgpt_SP_3 (N)',\n",
       " 'chatgpt_SP_3 (Y)',\n",
       " 'chatgpt_SP_4 (N)',\n",
       " 'chatgpt_SP_4 (Y)',\n",
       " 'chatgpt_SP_5 (N)',\n",
       " 'chatgpt_SP_5 (Y)',\n",
       " 'chatgpt_SP_6 (N)',\n",
       " 'chatgpt_SP_6 (Y)']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlfl_rel_cols = [c for c in nlfl_A_train.columns if \"chatgpt_label\" != c and \"chatgpt_\" in c]\n",
    "nlfl_rel_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.2 ms, sys: 0 ns, total: 11.2 ms\n",
      "Wall time: 8.24 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "new_nlfl_A_test = nlfl_A_test.copy()\n",
    "new_nlfl_A_train = nlfl_A_train.copy()\n",
    "new_nlfl_A_val = nlfl_A_val.copy()\n",
    "\n",
    "bigcut = ['chatgpt_v7 (N)', 'chatgpt_v7 (Y)', 'chatgpt_v8 (N)',\n",
    "       'chatgpt_v9 (N)', 'chatgpt_v9 (Y)', 'chatgpt_v10 (Y)',\n",
    "       'chatgpt_v5_2 (Y)', 'chatgpt_v5_4 (Y)', 'chatgpt_v6_1 (Y)',\n",
    "       'chatgpt_Q3_4 (Y)', 'chatgpt_Q3_5 (Y)', 'chatgpt_Q3_7 (Y)',\n",
    "       'chatgpt_Q3_7_e1 (Y)', 'chatgpt_10_e1 (N)', 'chatgpt_10_e2 (N)',\n",
    "       'chatgpt_10_e2 (Y)', 'chatgpt_10_e3 (N)', 'chatgpt_10_e3 (Y)',\n",
    "       'chatgpt_10_e5 (N)', 'chatgpt_7_e1 (Y)', 'chatgpt_7_e2 (N)',\n",
    "       'chatgpt_7_e2 (Y)', 'chatgpt_7_e3 (N)', 'chatgpt_7_e5 (N)',\n",
    "       'chatgpt_Q3_4_e2 (N)', 'chatgpt_Q3_5_e2 (N)',\n",
    "       'chatgpt_Q3_5_e4 (Y)', 'chatgpt_Q3_5_e5 (Y)', 'chatgpt_HF_1 (Y)',\n",
    "       'chatgpt_HF_2 (N)', 'chatgpt_HF_2 (Y)', 'chatgpt_HF_3 (Y)',\n",
    "       'chatgpt_HF_4 (Y)', 'chatgpt_HF_6 (Y)', 'chatgpt_SP_1 (N)',\n",
    "       'chatgpt_SP_3 (N)', 'chatgpt_SP_3 (Y)', 'chatgpt_SP_5 (Y)',\n",
    "       'chatgpt_SP_6 (Y)']\n",
    "len(bigcut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mf_rel_cols = ['contextual<&>Q[quién|cuál|qué]',\n",
    " 'contextual<&>A[binary(si|no)]',\n",
    " 'contextual<&>Q[propn]+&A+',\n",
    " 'contextual<&>Q[quién|cuál]',\n",
    " 'contextual<&>Q[(ser*&correcto)|(tener&razón)]',\n",
    " 'contextual<&>Q[ser*&correcto]',\n",
    " 'contextual<&>Q[tener&razón]',\n",
    " 'contextual<&>injection_index',\n",
    " 'traditional<&>prop_punct',\n",
    " 'semantic<&>A.isface()',\n",
    " 'traditional<&>A.isdigit()',\n",
    " 'traditional<&>frec_char(k)',\n",
    " 'traditional<&>frec_char(y)',\n",
    " 'traditional<&>frec_char(x)',\n",
    " 'traditional<&>frec_char(ñ)',\n",
    " 'semantic<&>A.is(nose)',\n",
    " 'traditional<&>A.is(nan)',\n",
    " 'semantic<&>A.is(ola|hola)',\n",
    " 'semantic<&>A.contains(bad-word)',\n",
    " 'semantic<&>A.contains(punct_faces)',\n",
    " 'traditional<&>prop_no_math_punct',\n",
    " 'traditional<&>max_vowel_rep_char_per_token',\n",
    " 'traditional<&>num_tokens',\n",
    " 'traditional<&>num_numbers',\n",
    " 'traditional<&>num_math_punct',\n",
    " 'semantic<&>num_keywords',\n",
    " 'semantic<&>ratio_ud',\n",
    " 'semantic<&>ratio_slang',\n",
    " 'semantic<&>ratio_keywords',\n",
    " 'traditional<&>ratio_vowel',\n",
    " 'traditional<&>ratio_punct',\n",
    " 'traditional<&>exist_numbs',\n",
    " 'traditional<&>max_len_number']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mf_rel_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: >"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjQAAAGdCAYAAAAFcOm4AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAizklEQVR4nO3df1TUdeLv8dcAMqjBmLCCKCLuVrJRVsNmoG7ZD1w0O93trJYlWnpv7GaKbG2i37OVt5Z2t/W4bf7oh+btZsVptW67l1uOu64/gjIRdi11rSQhBQmzGcoChPf9o+vc78SgzgjiO56Pc+ac5cP78/m8573IPPvMDOMwxhgBAABYLKKnJwAAAHCmCBoAAGA9ggYAAFiPoAEAANYjaAAAgPUIGgAAYD2CBgAAWI+gAQAA1ovq6Qmcjvb2dh06dEixsbFyOBw9PR0AAHAajDFqampScnKyIiK69xqKFUFz6NAhpaSk9PQ0AABAGGprazV06NBuPYcVQRMbGyvpmwWJi4vr4dkAAIDT4fP5lJKS4n8c705WBM2Jp5ni4uIIGgAALHM2Xi7Ci4IBAID1CBoAAGA9ggYAAFiPoAEAANYjaAAAgPUIGgAAYD2CBgAAWI+gAQAA1iNoAACA9UIOmi1btmjy5MlKTk6Ww+HQa6+9dsp9Nm/eLLfbrZiYGI0YMUIrV64MZ64AAABBhRw0X375pUaNGqUnn3zytMZXV1dr4sSJGjdunCorK7Vw4ULNnTtX69atC3myAAAAwYT8WU65ubnKzc097fErV67UsGHDtHTpUklSenq6duzYoccff1y33HJLqKcHAADooNs/nLK8vFw5OTkB2yZMmKBVq1aptbVVffr06bBPc3Ozmpub/V/7fL5umVt7u9Hz5R9r8V93q92Etm90VISuGhGvLfs+PeXY8/v10dFjrf6vhwzoq4Off9Vh3PD4frrmokHasu9T7W/80r/9Vz+5SL9749+nPE/WiHiV7z8S9HtXpg3U9urPvvnfwwdq+8efnfJ4wfz08iFaX3kwYFv64Dg1t7YFzDkURbkjVfx/9oa178n0j47UuAu+p6KJI/XAun/pgkGx+p9vH+jy84QjwqGQf+bCNSjWqYam5lMP7ETCedFq/KKlw/bbRw/T2ndquu28J7j69pExRskD+mpvfZMyhsTp4sEuleyoDZhfdGSEWtraJUljfhCvtz4M/m/hbEiMc+qw7//f987W8NuuHD5Qs8al6Zkt+7XjwFENPb+vHpx8sf7r8zu6c7qnNOnSwfrf/6o75bg/3nqZ5r1c1eXn/28/HqGYqAg98fcPQ9rvTOczIytV/6M8/N8ZQwb01efHWvRlS5tGfK+/9n/6pS5KjFVD09f+x4ScHyZqw+7DYZ/jdNw0KllRkQ592tSsrR80+renxvfTgSPHJEnTr0rVf785o1vn0d0cxpiwf606HA69+uqruvnmmzsdc+GFF2rmzJlauHChf1tZWZnGjBmjQ4cOafDgwR32eeihh/Twww932O71erv007b/V9XBbvnHBwCAbT5+bFKXH9Pn88nlcnX543cwZ+VdTt/+2PATDdXZx4kXFRXJ6/X6b7W1td0yr32Hm7rluAAA4Ozq9qeckpKSVF9fH7CtoaFBUVFRio+PD7qP0+mU0+ns7qkBAIDviG6/QpOVlSWPxxOwbcOGDcrMzAz6+hkAAIBQhRw0X3zxhaqqqlRVVSXpm7dlV1VVqabmmxcHFhUVKS8vzz8+Pz9fBw4cUGFhofbs2aPVq1dr1apVuu+++7rmHgAAgF4v5KecduzYofHjx/u/LiwslCTNmDFDa9asUV1dnT9uJCktLU2lpaWaP3++li1bpuTkZD3xxBO8ZRsAAHSZkIPmmmuu0cneGLVmzZoO266++mrt3Lkz1FMBAACcFj7LCQAAWI+gAQAA1iNoAACA9QgaAABgPYIGAABYj6ABAADWI2gAAID1CBoAAGA9ggYAAFiPoAEAANYjaAAAgPUIGgAAYD2CBgAAWI+gAQAA1iNoAACA9QgaAABgPYIGAABYj6ABAADWI2gAAID1CBoAAGA9ggYAAFiPoAEAANYjaAAAgPUIGgAAYD2CBgAAWI+gAQAA1iNoAACA9QgaAABgPYIGAABYj6ABAADWI2gAAID1CBoAAGA9ggYAAFiPoAEAANYjaAAAgPUIGgAAYD2CBgAAWI+gAQAA1iNoAACA9QgaAABgPYIGAABYj6ABAADWI2gAAID1CBoAAGA9ggYAAFiPoAEAANYjaAAAgPUIGgAAYD2CBgAAWI+gAQAA1iNoAACA9QgaAABgPYIGAABYj6ABAADWI2gAAID1CBoAAGA9ggYAAFgvrKBZvny50tLSFBMTI7fbra1bt550/Nq1azVq1Cj169dPgwcP1p133qkjR46ENWEAAIBvCzloSkpKVFBQoEWLFqmyslLjxo1Tbm6uampqgo7ftm2b8vLyNGvWLL3//vt65ZVX9O6772r27NlnPHkAAAApjKBZsmSJZs2apdmzZys9PV1Lly5VSkqKVqxYEXT822+/reHDh2vu3LlKS0vT2LFjdffdd2vHjh1nPHkAAAApxKBpaWlRRUWFcnJyArbn5OSorKws6D7Z2dn65JNPVFpaKmOMDh8+rD//+c+aNGlSp+dpbm6Wz+cLuAEAAHQmpKBpbGxUW1ubEhMTA7YnJiaqvr4+6D7Z2dlau3atpk6dqujoaCUlJWnAgAH605/+1Ol5iouL5XK5/LeUlJRQpgkAAHqZsF4U7HA4Ar42xnTYdsLu3bs1d+5c/frXv1ZFRYXeeOMNVVdXKz8/v9PjFxUVyev1+m+1tbXhTBMAAPQSUaEMTkhIUGRkZIerMQ0NDR2u2pxQXFysMWPG6P7775ckXXrpperfv7/GjRunRx55RIMHD+6wj9PplNPpDGVqAACgFwvpCk10dLTcbrc8Hk/Ado/Ho+zs7KD7HDt2TBERgaeJjIyU9M2VHQAAgDMV8lNOhYWFevbZZ7V69Wrt2bNH8+fPV01Njf8ppKKiIuXl5fnHT548WevXr9eKFSu0f/9+vfXWW5o7d66uvPJKJScnd909AQAAvVZITzlJ0tSpU3XkyBEtXrxYdXV1ysjIUGlpqVJTUyVJdXV1AX+TZubMmWpqatKTTz6pX/7ylxowYICuvfZa/fa3v+26ewEAAHo1h7HgeR+fzyeXyyWv16u4uLguO+7v39yrZZs+6rLjAQBgq48f6/zPqYSrux6/g+GznAAAgPUIGgAAYD2CBgAAWI+gAQAA1iNoAACA9QgaAABgPYIGAABYj6ABAADWI2gAAID1CBoAAGA9ggYAAFiPoAEAANYjaAAAgPUIGgAAYD2CBgAAWI+gAQAA1iNoAACA9QgaAABgPYIGAABYj6ABAADWI2gAAID1CBoAAGA9ggYAAFiPoAEAANYjaAAAgPUIGgAAYD2CBgAAyBjT01M4IwQNAACwHkEDAACsR9AAAADrETQAAMB6BA0AALAeQQMAAKxH0AAAAOsRNAAAwHoEDQAAsB5BAwAArEfQAAAA6xE0AADAegQNAACwHkEDAACsR9AAAADrETQAAMB6BA0AALAeQQMAAKxH0AAAAOsRNAAAwHoEDQAAsB5BAwAArEfQAAAA6xE0AADAegQNAACwHkEDAACsR9AAAADrETQAAMB6BA0AALBeWEGzfPlypaWlKSYmRm63W1u3bj3p+ObmZi1atEipqalyOp36/ve/r9WrV4c1YQAAgG+LCnWHkpISFRQUaPny5RozZoyeeuop5ebmavfu3Ro2bFjQfaZMmaLDhw9r1apV+sEPfqCGhgYdP378jCcPAAAghRE0S5Ys0axZszR79mxJ0tKlS/Xmm29qxYoVKi4u7jD+jTfe0ObNm7V//34NHDhQkjR8+PAzmzUAAMB/EtJTTi0tLaqoqFBOTk7A9pycHJWVlQXd5/XXX1dmZqZ+97vfaciQIbrwwgt133336auvvur0PM3NzfL5fAE3AADQfYzp6RmcmZCu0DQ2NqqtrU2JiYkB2xMTE1VfXx90n/3792vbtm2KiYnRq6++qsbGRv3iF7/QZ5991unraIqLi/Xwww+HMjUAANCLhfWiYIfDEfC1MabDthPa29vlcDi0du1aXXnllZo4caKWLFmiNWvWdHqVpqioSF6v13+rra0NZ5oAAKCXCOkKTUJCgiIjIztcjWloaOhw1eaEwYMHa8iQIXK5XP5t6enpMsbok08+0QUXXNBhH6fTKafTGcrUAABALxbSFZro6Gi53W55PJ6A7R6PR9nZ2UH3GTNmjA4dOqQvvvjCv23fvn2KiIjQ0KFDw5gyAABAoJCfciosLNSzzz6r1atXa8+ePZo/f75qamqUn58v6Zuni/Ly8vzjp02bpvj4eN15553avXu3tmzZovvvv1933XWX+vbt23X3BAAA9Fohv2176tSpOnLkiBYvXqy6ujplZGSotLRUqampkqS6ujrV1NT4x5933nnyeDy69957lZmZqfj4eE2ZMkWPPPJI190LAADQqzmMOfffqOXz+eRyueT1ehUXF9dlx/39m3u1bNNHXXY8AABstf83ExUREfwNPuHqrsfvYPgsJwAAYD2CBgAAWI+gAQAA1iNoAACA9QgaAABgPYIGAABYj6ABAADWI2gAAID1CBoAAGA9ggYAAFiPoAEAANYjaAAAgPUIGgAAYD2CBgAAWI+gAQAA1iNoAACA9QgaAABgPYIGAABYj6ABAADWI2gAAID1CBoAAGA9ggYAAFiPoAEAANYjaAAAgPUIGgAAYD2CBgAAWI+gAQAAMj09gTNE0AAAAOsRNAAAwHoEDQAAsB5BAwAArEfQAAAA6xE0AADAegQNAACwHkEDAACsR9AAAADrETQAAMB6BA0AALAeQQMAAKxH0AAAAOsRNAAAwHoEDQAAsB5BAwAArEfQAAAA6xE0AADAegQNAACwHkEDAACsR9AAAADrETQAAMB6BA0AALAeQQMAAKxH0AAAAOsRNAAAwHoEDQAAsB5BAwAArEfQAAAA64UVNMuXL1daWppiYmLkdru1devW09rvrbfeUlRUlC677LJwTgsAABBUyEFTUlKigoICLVq0SJWVlRo3bpxyc3NVU1Nz0v28Xq/y8vJ03XXXhT1ZAACAYEIOmiVLlmjWrFmaPXu20tPTtXTpUqWkpGjFihUn3e/uu+/WtGnTlJWVFfZkAQAAggkpaFpaWlRRUaGcnJyA7Tk5OSorK+t0v+eee04fffSRHnzwwdM6T3Nzs3w+X8ANAACgMyEFTWNjo9ra2pSYmBiwPTExUfX19UH3+eCDD7RgwQKtXbtWUVFRp3We4uJiuVwu/y0lJSWUaQIAgBAZY3p6CmckrBcFOxyOgK+NMR22SVJbW5umTZumhx9+WBdeeOFpH7+oqEher9d/q62tDWeaAACglzi9Syb/T0JCgiIjIztcjWloaOhw1UaSmpqatGPHDlVWVmrOnDmSpPb2dhljFBUVpQ0bNujaa6/tsJ/T6ZTT6QxlagAAoBcL6QpNdHS03G63PB5PwHaPx6Ps7OwO4+Pi4rRr1y5VVVX5b/n5+broootUVVWl0aNHn9nsAQAAFOIVGkkqLCzU9OnTlZmZqaysLD399NOqqalRfn6+pG+eLjp48KCef/55RUREKCMjI2D/QYMGKSYmpsN2AACAcIUcNFOnTtWRI0e0ePFi1dXVKSMjQ6WlpUpNTZUk1dXVnfJv0gAAAHQlh7HgZc0+n08ul0ter1dxcXFddtzfv7lXyzZ91GXHAwDAVh8+mquoyK79RKTuevwOhs9yAgAA1iNoAACA9QgaAABgPYIGAABYj6ABAADWI2gAAID1CBoAAGA9ggYAAFiPoAEAANYjaAAAgPUIGgAAYD2CBgAAWI+gAQAA1iNoAACA9QgaAABgPYIGAABYj6ABAADWI2gAAID1CBoAAGA9ggYAAFiPoAEAANYjaAAAgPUIGgAAYD2CBgAAWI+gAQAA1iNoAACA9QgaAAAg09MTOEMEDQAAsB5BAwAArEfQAAAA6xE0AADAegQNAACwHkEDAACsR9AAAADrETQAAMB6BA0AALAeQQMAAKxH0AAAAOsRNAAAwHoEDQAAsB5BAwAArEfQAAAA6xE0AADAegQNAACwHkEDAACsR9AAAADrETQAAMB6BA0AALAeQQMAAKxH0AAAAOsRNAAAwHoEDQAAsB5BAwAArEfQAAAA6xE0AADAegQNAACwXlhBs3z5cqWlpSkmJkZut1tbt27tdOz69et1ww036Hvf+57i4uKUlZWlN998M+wJAwAAfFvIQVNSUqKCggItWrRIlZWVGjdunHJzc1VTUxN0/JYtW3TDDTeotLRUFRUVGj9+vCZPnqzKysoznjwAAIAkOYwxJpQdRo8erSuuuEIrVqzwb0tPT9fNN9+s4uLi0zrGxRdfrKlTp+rXv/71aY33+XxyuVzyer2Ki4sLZbon9fs392rZpo+67HgAANjqg0dz1Seya1+J0l2P38GENPOWlhZVVFQoJycnYHtOTo7KyspO6xjt7e1qamrSwIEDOx3T3Nwsn88XcAMAAOhMSEHT2NiotrY2JSYmBmxPTExUfX39aR3jD3/4g7788ktNmTKl0zHFxcVyuVz+W0pKSijTBAAAIQrt+ZpzT1jXlhwOR8DXxpgO24J56aWX9NBDD6mkpESDBg3qdFxRUZG8Xq//VltbG840AQBALxEVyuCEhARFRkZ2uBrT0NDQ4arNt5WUlGjWrFl65ZVXdP311590rNPplNPpDGVqAACgFwvpCk10dLTcbrc8Hk/Ado/Ho+zs7E73e+mllzRz5ky9+OKLmjRpUngzBQAA6ERIV2gkqbCwUNOnT1dmZqaysrL09NNPq6amRvn5+ZK+ebro4MGDev755yV9EzN5eXn64x//qKuuusp/dadv375yuVxdeFcAAEBvFXLQTJ06VUeOHNHixYtVV1enjIwMlZaWKjU1VZJUV1cX8DdpnnrqKR0/flz33HOP7rnnHv/2GTNmaM2aNWd+DwAAQK8X8t+h6Qn8HRoAALrXvkdyFR3VS/4ODQAAwLmIoAEAANYjaAAAgPUIGgAAYD2CBgAAWI+gAQAA1iNoAACA9QgaAABgPYIGAABYj6ABAADWI2gAAID1CBoAAGA9ggYAAFiPoAEAANYjaAAAgPUIGgAAYD2CBgAAWI+gAQAA1iNoAACA9QgaAABgPYIGAABYj6ABAADWI2gAAID1CBoAAGA9ggYAAFiPoAEAANYjaAAAgIxMT0/hjBA0AADAegQNAACwHkEDAACsR9AAAADrETQAAMB6BA0AALAeQQMAAKxH0AAAAOsRNAAAwHoEDQAAsB5BAwAArEfQAAAA6xE0AADAegQNAACwHkEDAACsR9AAAADrETQAAMB6BA0AALAeQQMAAKxH0AAAAOsRNAAAwHoEDQAAsB5BAwAArEfQAAAA6xE0AADAegQNAACwHkEDAACsR9AAAADrETQAAMB6YQXN8uXLlZaWppiYGLndbm3duvWk4zdv3iy3262YmBiNGDFCK1euDGuyAAAAwYQcNCUlJSooKNCiRYtUWVmpcePGKTc3VzU1NUHHV1dXa+LEiRo3bpwqKyu1cOFCzZ07V+vWrTvjyQMAAEhhBM2SJUs0a9YszZ49W+np6Vq6dKlSUlK0YsWKoONXrlypYcOGaenSpUpPT9fs2bN111136fHHHz/jyQMAAEghBk1LS4sqKiqUk5MTsD0nJ0dlZWVB9ykvL+8wfsKECdqxY4daW1uD7tPc3Cyfzxdw6w7rdx7sluMCAGCb9w52z2Pt2RJS0DQ2NqqtrU2JiYkB2xMTE1VfXx90n/r6+qDjjx8/rsbGxqD7FBcXy+Vy+W8pKSmhTPO0tba1d8txAQCwTc1nX/b0FM5IWC8KdjgcAV8bYzpsO9X4YNtPKCoqktfr9d9qa2vDmeYpPTj5Yg0Z0Ldbjh2uYEsy9Pxza45d7YeD47r1+NNGD5MkDewf3a3n6W1iY6J67Nzx3+H/L380/PyAr7NGxPfQTEKXmXr+qQeFIb5/tGKdof+8nel8oiN7zxuB+0dHamRS9/4u7m4h/YQkJCQoMjKyw9WYhoaGDldhTkhKSgo6PioqSvHxwf+hOp1OOZ3OUKYWlsmjkjV5VHK3nwc97zf/5ZKengIAoBuFlJ/R0dFyu93yeDwB2z0ej7Kzs4Puk5WV1WH8hg0blJmZqT59+oQ4XQAAgI5Cvp5WWFioZ599VqtXr9aePXs0f/581dTUKD8/X9I3Txfl5eX5x+fn5+vAgQMqLCzUnj17tHr1aq1atUr33Xdf190LAADQq4X8pOTUqVN15MgRLV68WHV1dcrIyFBpaalSU1MlSXV1dQF/kyYtLU2lpaWaP3++li1bpuTkZD3xxBO65ZZbuu5eAACAXs1hTrxC9xzm8/nkcrnk9XoVF2f3i5YAAOgtzubjd+95CTcAAPjOImgAAID1CBoAAGA9ggYAAFiPoAEAANYjaAAAgPUIGgAAYD2CBgAAWI+gAQAA1gv989h7wIk/Zuzz+Xp4JgAA4HSdeNw+Gx9KYEXQNDU1SZJSUlJ6eCYAACBUTU1Ncrlc3XoOKz7Lqb29XYcOHVJsbKwcDkeXHdfn8yklJUW1tbV8RlQIWLfwsG7hYd3Cw7qFj7ULT7B1M8aoqalJycnJiojo3le5WHGFJiIiQkOHDu2248fFxfFDGwbWLTysW3hYt/CwbuFj7cLz7XXr7iszJ/CiYAAAYD2CBgAAWK9XB43T6dSDDz4op9PZ01OxCusWHtYtPKxbeFi38LF24enpdbPiRcEAAAAn06uv0AAAgO8GggYAAFiPoAEAANYjaAAAgPV6ddAsX75caWlpiomJkdvt1tatW3t6SmdNcXGxfvSjHyk2NlaDBg3SzTffrH//+98BY4wxeuihh5ScnKy+ffvqmmuu0fvvvx8wprm5Wffee68SEhLUv39/3XTTTfrkk08Cxhw9elTTp0+Xy+WSy+XS9OnT9fnnn3f3Xex2xcXFcjgcKigo8G9jzTp38OBB3XHHHYqPj1e/fv102WWXqaKiwv991q6j48eP6z/+4z+Ulpamvn37asSIEVq8eLHa29v9Y1g3acuWLZo8ebKSk5PlcDj02muvBXz/bK5RTU2NJk+erP79+yshIUFz585VS0tLd9ztM3aydWttbdUDDzygSy65RP3791dycrLy8vJ06NChgGOcU+tmeqmXX37Z9OnTxzzzzDNm9+7dZt68eaZ///7mwIEDPT21s2LChAnmueeeM++9956pqqoykyZNMsOGDTNffPGFf8xjjz1mYmNjzbp168yuXbvM1KlTzeDBg43P5/OPyc/PN0OGDDEej8fs3LnTjB8/3owaNcocP37cP+YnP/mJycjIMGVlZaasrMxkZGSYG2+88aze3662fft2M3z4cHPppZeaefPm+bezZsF99tlnJjU11cycOdO88847prq62mzcuNF8+OGH/jGsXUePPPKIiY+PN3/9619NdXW1eeWVV8x5551nli5d6h/DuhlTWlpqFi1aZNatW2ckmVdffTXg+2drjY4fP24yMjLM+PHjzc6dO43H4zHJyclmzpw53b4G4TjZun3++efm+uuvNyUlJWbv3r2mvLzcjB492rjd7oBjnEvr1muD5sorrzT5+fkB20aOHGkWLFjQQzPqWQ0NDUaS2bx5szHGmPb2dpOUlGQee+wx/5ivv/7auFwus3LlSmPMNz/wffr0MS+//LJ/zMGDB01ERIR54403jDHG7N6920gyb7/9tn9MeXm5kWT27t17Nu5al2tqajIXXHCB8Xg85uqrr/YHDWvWuQceeMCMHTu20++zdsFNmjTJ3HXXXQHbfvrTn5o77rjDGMO6BfPtB+azuUalpaUmIiLCHDx40D/mpZdeMk6n03i93m65v10lWAh+2/bt240k/3/4n2vr1iufcmppaVFFRYVycnICtufk5KisrKyHZtWzvF6vJGngwIGSpOrqatXX1weskdPp1NVXX+1fo4qKCrW2tgaMSU5OVkZGhn9MeXm5XC6XRo8e7R9z1VVXyeVyWbvW99xzjyZNmqTrr78+YDtr1rnXX39dmZmZ+tnPfqZBgwbp8ssv1zPPPOP/PmsX3NixY/W3v/1N+/btkyT985//1LZt2zRx4kRJrNvpOJtrVF5eroyMDCUnJ/vHTJgwQc3NzQFPr9rK6/XK4XBowIABks69dbPiwym7WmNjo9ra2pSYmBiwPTExUfX19T00q55jjFFhYaHGjh2rjIwMSfKvQ7A1OnDggH9MdHS0zj///A5jTuxfX1+vQYMGdTjnoEGDrFzrl19+WTt37tS7777b4XusWef279+vFStWqLCwUAsXLtT27ds1d+5cOZ1O5eXlsXadeOCBB+T1ejVy5EhFRkaqra1Njz76qG677TZJ/MydjrO5RvX19R3Oc/755ys6Otr6dfz666+1YMECTZs2zf/Bk+fauvXKoDnB4XAEfG2M6bCtN5gzZ47+9a9/adu2bR2+F84afXtMsPE2rnVtba3mzZunDRs2KCYmptNxrFlH7e3tyszM1G9+8xtJ0uWXX673339fK1asUF5enn8caxeopKREL7zwgl588UVdfPHFqqqqUkFBgZKTkzVjxgz/ONbt1M7WGn0X17G1tVW33nqr2tvbtXz58lOO76l165VPOSUkJCgyMrJD+TU0NHSoxO+6e++9V6+//ro2bdqkoUOH+rcnJSVJ0knXKCkpSS0tLTp69OhJxxw+fLjDeT/99FPr1rqiokINDQ1yu92KiopSVFSUNm/erCeeeEJRUVH++8OadTR48GD98Ic/DNiWnp6umpoaSfy8deb+++/XggULdOutt+qSSy7R9OnTNX/+fBUXF0ti3U7H2VyjpKSkDuc5evSoWltbrV3H1tZWTZkyRdXV1fJ4PP6rM9K5t269Mmiio6Pldrvl8XgCtns8HmVnZ/fQrM4uY4zmzJmj9evX6+9//7vS0tICvp+WlqakpKSANWppadHmzZv9a+R2u9WnT5+AMXV1dXrvvff8Y7KysuT1erV9+3b/mHfeeUder9e6tb7uuuu0a9cuVVVV+W+ZmZm6/fbbVVVVpREjRrBmnRgzZkyHPwuwb98+paamSuLnrTPHjh1TRETgr+nIyEj/27ZZt1M7m2uUlZWl9957T3V1df4xGzZskNPplNvt7tb72R1OxMwHH3ygjRs3Kj4+PuD759y6nfbLh79jTrxte9WqVWb37t2moKDA9O/f33z88cc9PbWz4uc//7lxuVzmH//4h6mrq/Pfjh075h/z2GOPGZfLZdavX2927dplbrvttqBvdRw6dKjZuHGj2blzp7n22muDvmXv0ksvNeXl5aa8vNxccskl1rwd9FT+87ucjGHNOrN9+3YTFRVlHn30UfPBBx+YtWvXmn79+pkXXnjBP4a162jGjBlmyJAh/rdtr1+/3iQkJJhf/epX/jGs2zfvPKysrDSVlZVGklmyZImprKz0vxvnbK3RibcfX3fddWbnzp1m48aNZujQoefs27ZPtm6tra3mpptuMkOHDjVVVVUBjxPNzc3+Y5xL69Zrg8YYY5YtW2ZSU1NNdHS0ueKKK/xvWe4NJAW9Pffcc/4x7e3t5sEHHzRJSUnG6XSaH//4x2bXrl0Bx/nqq6/MnDlzzMCBA03fvn3NjTfeaGpqagLGHDlyxNx+++0mNjbWxMbGmttvv90cPXr0LNzL7vftoGHNOveXv/zFZGRkGKfTaUaOHGmefvrpgO+zdh35fD4zb948M2zYMBMTE2NGjBhhFi1aFPCAwroZs2nTpqC/z2bMmGGMObtrdODAATNp0iTTt29fM3DgQDNnzhzz9ddfd+fdD9vJ1q26urrTx4lNmzb5j3EurZvDGGNO/3oOAADAuadXvoYGAAB8txA0AADAegQNAACwHkEDAACsR9AAAADrETQAAMB6BA0AALAeQQMAAKxH0AAAAOsRNAAAwHoEDQAAsB5BAwAArPd/AQM0pT1WvzmUAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "A_train[\"label\"].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install transformers\n",
    "!pip install datasets\n",
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dccuchile/bert-base-spanish-wwm-cased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model_name = \"dccuchile/bert-base-spanish-wwm-cased\"\n",
    "beto_model = BertModel.from_pretrained(model_name)\n",
    "beto_tokenizer = BertTokenizer.from_pretrained(model_name, do_lower_case=False)\n",
    "e = beto_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['[UNK]', '[SEP]', '[PAD]', '[CLS]', '[MASK]'], [3, 5, 1, 4, 0])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beto_tokenizer.all_special_tokens, beto_tokenizer.all_special_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "class DatasetTaskC1(Dataset):\n",
    "    def __init__(self, df, df_mf, maxlen):\n",
    "        self.df = df\n",
    "        self.df_mf = df_mf\n",
    "        self.tokenizer = beto_tokenizer\n",
    "        self.maxlen = maxlen\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        sentence1 = str(self.df.loc[index, 'Q'])\n",
    "        sentence2 = str(self.df.loc[index, 'A'])\n",
    "        \n",
    "        sentence1 = \" \".join(str(sentence1).replace(\"\\n\", \" \").split())\n",
    "        sentence2 = \" \".join(str(sentence2).replace(\"\\n\", \" \").split())\n",
    "\n",
    "        label = self.df.loc[index, 'label']\n",
    "        \n",
    "        tokens1 = self.tokenizer.tokenize(sentence1) if len(sentence1)>0 else [\"[UNK]\"]\n",
    "        tokens2 = self.tokenizer.tokenize(sentence2) if len(sentence2)>0 else [\"[UNK]\"]\n",
    "\n",
    "        if len(tokens1) < self.maxlen:\n",
    "            tokens1 = tokens1 + ['[PAD]' for _ in range(self.maxlen - len(tokens1))]\n",
    "        else:\n",
    "            tokens1 = tokens1[:self.maxlen]\n",
    "\n",
    "        if len(tokens2) < self.maxlen:\n",
    "            tokens2 = tokens2 + ['[PAD]' for _ in range(self.maxlen - len(tokens2))]\n",
    "        else:\n",
    "            tokens2 = tokens2[:self.maxlen]\n",
    "          \n",
    "        tokens = [\"[CLS]\"]+tokens1+[\"[SEP]\"]+tokens2+[\"[SEP]\"]\n",
    "        tokens_ids = self.tokenizer.convert_tokens_to_ids(tokens)\n",
    "        tokens_ids_tensor = torch.tensor(tokens_ids)\n",
    "        attn_mask = (tokens_ids_tensor != 1).long() # [PAD] => 1\n",
    "        \n",
    "        mf_tensor = torch.tensor(self.df_mf.loc[index, :].values)\n",
    "        nlfl_tensor = torch.tensor(self.df.loc[index, :][bigcut])\n",
    "        \n",
    "\n",
    "        return nlfl_tensor, mf_tensor, tokens_ids_tensor, attn_mask, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_set = DatasetTaskC1(df = new_nlfl_A_train, df_mf=mf_A_train[mf_rel_cols].astype(float), maxlen = 60)\n",
    "val_set = DatasetTaskC1(df = new_nlfl_A_test, df_mf=mf_A_test[mf_rel_cols].astype(float), maxlen = 60)\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size = 32, num_workers = 2, shuffle=False)\n",
    "val_loader = DataLoader(val_set, batch_size = 32, num_workers = 2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chatgpt_v7 (N)</th>\n",
       "      <th>chatgpt_v7 (Y)</th>\n",
       "      <th>chatgpt_v8 (N)</th>\n",
       "      <th>chatgpt_v9 (N)</th>\n",
       "      <th>chatgpt_v9 (Y)</th>\n",
       "      <th>chatgpt_v10 (Y)</th>\n",
       "      <th>chatgpt_v5_2 (Y)</th>\n",
       "      <th>chatgpt_v5_4 (Y)</th>\n",
       "      <th>chatgpt_v6_1 (Y)</th>\n",
       "      <th>chatgpt_Q3_4 (Y)</th>\n",
       "      <th>...</th>\n",
       "      <th>chatgpt_HF_2 (N)</th>\n",
       "      <th>chatgpt_HF_2 (Y)</th>\n",
       "      <th>chatgpt_HF_3 (Y)</th>\n",
       "      <th>chatgpt_HF_4 (Y)</th>\n",
       "      <th>chatgpt_HF_6 (Y)</th>\n",
       "      <th>chatgpt_SP_1 (N)</th>\n",
       "      <th>chatgpt_SP_3 (N)</th>\n",
       "      <th>chatgpt_SP_3 (Y)</th>\n",
       "      <th>chatgpt_SP_5 (Y)</th>\n",
       "      <th>chatgpt_SP_6 (Y)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.050355</td>\n",
       "      <td>0.954416</td>\n",
       "      <td>0.861216</td>\n",
       "      <td>0.891981</td>\n",
       "      <td>0.079516</td>\n",
       "      <td>0.867311</td>\n",
       "      <td>0.425349</td>\n",
       "      <td>0.290060</td>\n",
       "      <td>0.742486</td>\n",
       "      <td>0.403959</td>\n",
       "      <td>...</td>\n",
       "      <td>0.486101</td>\n",
       "      <td>0.407081</td>\n",
       "      <td>0.266678</td>\n",
       "      <td>0.344915</td>\n",
       "      <td>0.399653</td>\n",
       "      <td>0.211885</td>\n",
       "      <td>0.227395</td>\n",
       "      <td>0.782670</td>\n",
       "      <td>0.440286</td>\n",
       "      <td>0.205009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.061304</td>\n",
       "      <td>0.947527</td>\n",
       "      <td>0.503022</td>\n",
       "      <td>0.654293</td>\n",
       "      <td>0.343887</td>\n",
       "      <td>0.817359</td>\n",
       "      <td>0.649023</td>\n",
       "      <td>0.647596</td>\n",
       "      <td>0.767244</td>\n",
       "      <td>0.700911</td>\n",
       "      <td>...</td>\n",
       "      <td>0.286041</td>\n",
       "      <td>0.739698</td>\n",
       "      <td>0.624346</td>\n",
       "      <td>0.635999</td>\n",
       "      <td>0.668484</td>\n",
       "      <td>0.223496</td>\n",
       "      <td>0.239130</td>\n",
       "      <td>0.797414</td>\n",
       "      <td>0.670254</td>\n",
       "      <td>0.664460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.041318</td>\n",
       "      <td>0.957472</td>\n",
       "      <td>0.497123</td>\n",
       "      <td>0.801994</td>\n",
       "      <td>0.166432</td>\n",
       "      <td>0.856645</td>\n",
       "      <td>0.682702</td>\n",
       "      <td>0.733705</td>\n",
       "      <td>0.804858</td>\n",
       "      <td>0.559936</td>\n",
       "      <td>...</td>\n",
       "      <td>0.307068</td>\n",
       "      <td>0.611335</td>\n",
       "      <td>0.604869</td>\n",
       "      <td>0.649069</td>\n",
       "      <td>0.623687</td>\n",
       "      <td>0.121597</td>\n",
       "      <td>0.135982</td>\n",
       "      <td>0.866083</td>\n",
       "      <td>0.720078</td>\n",
       "      <td>0.692664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.048473</td>\n",
       "      <td>0.949204</td>\n",
       "      <td>0.752415</td>\n",
       "      <td>0.908994</td>\n",
       "      <td>0.054206</td>\n",
       "      <td>0.588132</td>\n",
       "      <td>0.210189</td>\n",
       "      <td>0.219829</td>\n",
       "      <td>0.299731</td>\n",
       "      <td>0.222005</td>\n",
       "      <td>...</td>\n",
       "      <td>0.549203</td>\n",
       "      <td>0.262470</td>\n",
       "      <td>0.248231</td>\n",
       "      <td>0.207272</td>\n",
       "      <td>0.240789</td>\n",
       "      <td>0.403232</td>\n",
       "      <td>0.382491</td>\n",
       "      <td>0.644244</td>\n",
       "      <td>0.243091</td>\n",
       "      <td>0.245129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.732937</td>\n",
       "      <td>0.275971</td>\n",
       "      <td>0.923895</td>\n",
       "      <td>0.949580</td>\n",
       "      <td>0.037766</td>\n",
       "      <td>0.143635</td>\n",
       "      <td>0.065245</td>\n",
       "      <td>0.068979</td>\n",
       "      <td>0.049644</td>\n",
       "      <td>0.063891</td>\n",
       "      <td>...</td>\n",
       "      <td>0.921751</td>\n",
       "      <td>0.068854</td>\n",
       "      <td>0.072694</td>\n",
       "      <td>0.061435</td>\n",
       "      <td>0.091090</td>\n",
       "      <td>0.921096</td>\n",
       "      <td>0.911064</td>\n",
       "      <td>0.090232</td>\n",
       "      <td>0.089723</td>\n",
       "      <td>0.084049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11554</th>\n",
       "      <td>0.059784</td>\n",
       "      <td>0.929024</td>\n",
       "      <td>0.922781</td>\n",
       "      <td>0.947646</td>\n",
       "      <td>0.027274</td>\n",
       "      <td>0.164997</td>\n",
       "      <td>0.035877</td>\n",
       "      <td>0.036507</td>\n",
       "      <td>0.045182</td>\n",
       "      <td>0.046671</td>\n",
       "      <td>...</td>\n",
       "      <td>0.887980</td>\n",
       "      <td>0.049046</td>\n",
       "      <td>0.048388</td>\n",
       "      <td>0.047008</td>\n",
       "      <td>0.047582</td>\n",
       "      <td>0.866427</td>\n",
       "      <td>0.852742</td>\n",
       "      <td>0.068038</td>\n",
       "      <td>0.045668</td>\n",
       "      <td>0.043510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11555</th>\n",
       "      <td>0.050023</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.860114</td>\n",
       "      <td>0.924603</td>\n",
       "      <td>0.057695</td>\n",
       "      <td>0.817929</td>\n",
       "      <td>0.318834</td>\n",
       "      <td>0.291960</td>\n",
       "      <td>0.649999</td>\n",
       "      <td>0.369862</td>\n",
       "      <td>...</td>\n",
       "      <td>0.590166</td>\n",
       "      <td>0.327267</td>\n",
       "      <td>0.276181</td>\n",
       "      <td>0.336579</td>\n",
       "      <td>0.389948</td>\n",
       "      <td>0.259128</td>\n",
       "      <td>0.203707</td>\n",
       "      <td>0.827148</td>\n",
       "      <td>0.362717</td>\n",
       "      <td>0.277307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11556</th>\n",
       "      <td>0.380095</td>\n",
       "      <td>0.588984</td>\n",
       "      <td>0.856748</td>\n",
       "      <td>0.923227</td>\n",
       "      <td>0.072501</td>\n",
       "      <td>0.308636</td>\n",
       "      <td>0.139451</td>\n",
       "      <td>0.141873</td>\n",
       "      <td>0.112474</td>\n",
       "      <td>0.114684</td>\n",
       "      <td>...</td>\n",
       "      <td>0.831090</td>\n",
       "      <td>0.157382</td>\n",
       "      <td>0.159395</td>\n",
       "      <td>0.111050</td>\n",
       "      <td>0.161683</td>\n",
       "      <td>0.842161</td>\n",
       "      <td>0.820981</td>\n",
       "      <td>0.164617</td>\n",
       "      <td>0.181063</td>\n",
       "      <td>0.168443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11557</th>\n",
       "      <td>0.084956</td>\n",
       "      <td>0.873752</td>\n",
       "      <td>0.743644</td>\n",
       "      <td>0.883923</td>\n",
       "      <td>0.040208</td>\n",
       "      <td>0.326852</td>\n",
       "      <td>0.111856</td>\n",
       "      <td>0.090749</td>\n",
       "      <td>0.097967</td>\n",
       "      <td>0.097853</td>\n",
       "      <td>...</td>\n",
       "      <td>0.669376</td>\n",
       "      <td>0.123866</td>\n",
       "      <td>0.115130</td>\n",
       "      <td>0.079318</td>\n",
       "      <td>0.126849</td>\n",
       "      <td>0.603205</td>\n",
       "      <td>0.554979</td>\n",
       "      <td>0.291034</td>\n",
       "      <td>0.112915</td>\n",
       "      <td>0.100972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11558</th>\n",
       "      <td>0.055527</td>\n",
       "      <td>0.937833</td>\n",
       "      <td>0.614745</td>\n",
       "      <td>0.820025</td>\n",
       "      <td>0.087600</td>\n",
       "      <td>0.696926</td>\n",
       "      <td>0.283932</td>\n",
       "      <td>0.317100</td>\n",
       "      <td>0.368393</td>\n",
       "      <td>0.373626</td>\n",
       "      <td>...</td>\n",
       "      <td>0.534605</td>\n",
       "      <td>0.305082</td>\n",
       "      <td>0.251553</td>\n",
       "      <td>0.209121</td>\n",
       "      <td>0.333903</td>\n",
       "      <td>0.341300</td>\n",
       "      <td>0.315997</td>\n",
       "      <td>0.670981</td>\n",
       "      <td>0.306613</td>\n",
       "      <td>0.272084</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11559 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       chatgpt_v7 (N)  chatgpt_v7 (Y)  chatgpt_v8 (N)  chatgpt_v9 (N)  \\\n",
       "0            0.050355        0.954416        0.861216        0.891981   \n",
       "1            0.061304        0.947527        0.503022        0.654293   \n",
       "2            0.041318        0.957472        0.497123        0.801994   \n",
       "3            0.048473        0.949204        0.752415        0.908994   \n",
       "4            0.732937        0.275971        0.923895        0.949580   \n",
       "...               ...             ...             ...             ...   \n",
       "11554        0.059784        0.929024        0.922781        0.947646   \n",
       "11555        0.050023        0.956522        0.860114        0.924603   \n",
       "11556        0.380095        0.588984        0.856748        0.923227   \n",
       "11557        0.084956        0.873752        0.743644        0.883923   \n",
       "11558        0.055527        0.937833        0.614745        0.820025   \n",
       "\n",
       "       chatgpt_v9 (Y)  chatgpt_v10 (Y)  chatgpt_v5_2 (Y)  chatgpt_v5_4 (Y)  \\\n",
       "0            0.079516         0.867311          0.425349          0.290060   \n",
       "1            0.343887         0.817359          0.649023          0.647596   \n",
       "2            0.166432         0.856645          0.682702          0.733705   \n",
       "3            0.054206         0.588132          0.210189          0.219829   \n",
       "4            0.037766         0.143635          0.065245          0.068979   \n",
       "...               ...              ...               ...               ...   \n",
       "11554        0.027274         0.164997          0.035877          0.036507   \n",
       "11555        0.057695         0.817929          0.318834          0.291960   \n",
       "11556        0.072501         0.308636          0.139451          0.141873   \n",
       "11557        0.040208         0.326852          0.111856          0.090749   \n",
       "11558        0.087600         0.696926          0.283932          0.317100   \n",
       "\n",
       "       chatgpt_v6_1 (Y)  chatgpt_Q3_4 (Y)  ...  chatgpt_HF_2 (N)  \\\n",
       "0              0.742486          0.403959  ...          0.486101   \n",
       "1              0.767244          0.700911  ...          0.286041   \n",
       "2              0.804858          0.559936  ...          0.307068   \n",
       "3              0.299731          0.222005  ...          0.549203   \n",
       "4              0.049644          0.063891  ...          0.921751   \n",
       "...                 ...               ...  ...               ...   \n",
       "11554          0.045182          0.046671  ...          0.887980   \n",
       "11555          0.649999          0.369862  ...          0.590166   \n",
       "11556          0.112474          0.114684  ...          0.831090   \n",
       "11557          0.097967          0.097853  ...          0.669376   \n",
       "11558          0.368393          0.373626  ...          0.534605   \n",
       "\n",
       "       chatgpt_HF_2 (Y)  chatgpt_HF_3 (Y)  chatgpt_HF_4 (Y)  chatgpt_HF_6 (Y)  \\\n",
       "0              0.407081          0.266678          0.344915          0.399653   \n",
       "1              0.739698          0.624346          0.635999          0.668484   \n",
       "2              0.611335          0.604869          0.649069          0.623687   \n",
       "3              0.262470          0.248231          0.207272          0.240789   \n",
       "4              0.068854          0.072694          0.061435          0.091090   \n",
       "...                 ...               ...               ...               ...   \n",
       "11554          0.049046          0.048388          0.047008          0.047582   \n",
       "11555          0.327267          0.276181          0.336579          0.389948   \n",
       "11556          0.157382          0.159395          0.111050          0.161683   \n",
       "11557          0.123866          0.115130          0.079318          0.126849   \n",
       "11558          0.305082          0.251553          0.209121          0.333903   \n",
       "\n",
       "       chatgpt_SP_1 (N)  chatgpt_SP_3 (N)  chatgpt_SP_3 (Y)  chatgpt_SP_5 (Y)  \\\n",
       "0              0.211885          0.227395          0.782670          0.440286   \n",
       "1              0.223496          0.239130          0.797414          0.670254   \n",
       "2              0.121597          0.135982          0.866083          0.720078   \n",
       "3              0.403232          0.382491          0.644244          0.243091   \n",
       "4              0.921096          0.911064          0.090232          0.089723   \n",
       "...                 ...               ...               ...               ...   \n",
       "11554          0.866427          0.852742          0.068038          0.045668   \n",
       "11555          0.259128          0.203707          0.827148          0.362717   \n",
       "11556          0.842161          0.820981          0.164617          0.181063   \n",
       "11557          0.603205          0.554979          0.291034          0.112915   \n",
       "11558          0.341300          0.315997          0.670981          0.306613   \n",
       "\n",
       "       chatgpt_SP_6 (Y)  \n",
       "0              0.205009  \n",
       "1              0.664460  \n",
       "2              0.692664  \n",
       "3              0.245129  \n",
       "4              0.084049  \n",
       "...                 ...  \n",
       "11554          0.043510  \n",
       "11555          0.277307  \n",
       "11556          0.168443  \n",
       "11557          0.100972  \n",
       "11558          0.272084  \n",
       "\n",
       "[11559 rows x 39 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_nlfl_A_train.iloc[0:][bigcut]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class C1Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(C1Classifier, self).__init__()\n",
    "        torch.manual_seed(2022)\n",
    "        \n",
    "        self.bert_layer = BertModel.from_pretrained(model_name).cuda()\n",
    "        self.cls_layer = nn.Linear(39+33+768, 2).cuda()\n",
    "        # self.cls_layer2 = nn.Linear(768, 2).cuda()\n",
    "\n",
    "    def forward(self, nlfls, mfs, seq, attn_masks):\n",
    "\n",
    "        cont_reps = self.bert_layer(seq, attention_mask=attn_masks)\n",
    "        \n",
    "        cls_rep = cont_reps.last_hidden_state[:, 0]\n",
    "        mfs = mfs.to(cls_rep.dtype)\n",
    "        nlfls = nlfls.to(cls_rep.dtype)\n",
    "        cls_rep = torch.cat((mfs,cls_rep), 1)\n",
    "        cls_rep = torch.cat((nlfls,cls_rep), 1)\n",
    "        \n",
    "        logits = self.cls_layer(cls_rep)\n",
    "        # logits = self.cls_layer2(inter)\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dccuchile/bert-base-spanish-wwm-cased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "net = C1Classifier()\n",
    "\n",
    "weights = torch.tensor([1., 6.5])\n",
    "criterion = nn.CrossEntropyLoss(weight=weights, reduction='mean').cuda()\n",
    "\n",
    "opti = optim.Adam(net.parameters(), lr = 2e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy_from_logits(logits, labels):\n",
    "    probs = torch.sigmoid(logits)\n",
    "    soft_probs = probs.argmax(1)\n",
    "    acc = (soft_probs.squeeze() == labels).float().mean()\n",
    "    return acc\n",
    "    \n",
    "def evaluate(net, criterion, dataloader):\n",
    "    net.eval()\n",
    "    mean_acc, mean_loss = 0, 0\n",
    "    count = 0\n",
    "    with torch.no_grad():\n",
    "        for nlfls, mfs, seq, attn_masks, labels in dataloader:\n",
    "            nlfls, mfs, seq, attn_masks, labels = nlfls.cuda(), mfs.cuda(), seq.cuda(), attn_masks.cuda(), labels.cuda()\n",
    "            logits = net(nlfls, mfs, seq, attn_masks)\n",
    "            mean_loss += criterion(logits, labels).item()\n",
    "            mean_acc += get_accuracy_from_logits(logits, labels)\n",
    "            count += 1\n",
    "\n",
    "    return mean_acc / count, mean_loss / count\n",
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def evaluate_precision_recall_fscore_support(net, dataloader):\n",
    "    net.eval()\n",
    "    preds = []\n",
    "    tests = []\n",
    "    with torch.no_grad():\n",
    "        for nlfls, mfs, seq, attn_masks, labels in dataloader:\n",
    "            nlfls, mfs, seq, attn_masks, labels = nlfls.cuda(), mfs.cuda(), seq.cuda(), attn_masks.cuda(), labels.cuda()\n",
    "            logits = net(nlfls, mfs, seq, attn_masks)\n",
    "            probs = torch.sigmoid(logits)\n",
    "            soft_probs = probs.argmax(1)\n",
    "            preds += soft_probs.squeeze().tolist()\n",
    "            tests += labels.tolist()\n",
    "    return tests, preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, criterion, opti, train_loader, val_loader, epochs):\n",
    "    for ep in range(epochs):\n",
    "        for it, (nlfls, mfs, seq, attn_masks, labels) in enumerate(train_loader):\n",
    "            opti.zero_grad()  \n",
    "\n",
    "            nlfls, mfs, seq, attn_masks, labels = nlfls.cuda(), mfs.cuda(), seq.cuda(), attn_masks.cuda(), labels.cuda()\n",
    "\n",
    "            logits = net(nlfls, mfs, seq, attn_masks)\n",
    "\n",
    "            loss = criterion(logits, labels)\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            opti.step()\n",
    "\n",
    "            if (it + 1) % 100 == 0:\n",
    "                acc = get_accuracy_from_logits(logits, labels)\n",
    "                # tests, preds = evaluate_precision_recall_fscore_support(net, train_loader)\n",
    "                # print(classification_report(tests, preds))\n",
    "                print(\"Iteration {} of epoch {} complete. Loss : {} Train Accuracy : {}\".format(it+1, ep+1, loss.item(), acc))\n",
    "        val_acc, val_loss = evaluate(net, criterion, val_loader)\n",
    "        tests, preds = evaluate_precision_recall_fscore_support(net, val_loader)\n",
    "        print(classification_report(tests, preds))\n",
    "        print(\"Epoch {} complete! Validation Accuracy : {}, Validation Loss : {}\".format(ep+1, val_acc, val_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 100 of epoch 1 complete. Loss : 0.07518334686756134 Train Accuracy : 0.9375\n",
      "Iteration 200 of epoch 1 complete. Loss : 0.08865189552307129 Train Accuracy : 0.96875\n",
      "Iteration 300 of epoch 1 complete. Loss : 0.06835414469242096 Train Accuracy : 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95       541\n",
      "           1       0.80      0.79      0.79       136\n",
      "\n",
      "    accuracy                           0.92       677\n",
      "   macro avg       0.87      0.87      0.87       677\n",
      "weighted avg       0.92      0.92      0.92       677\n",
      "\n",
      "Epoch 1 complete! Validation Accuracy : 0.9127840995788574, Validation Loss : 0.45458202030171047\n"
     ]
    }
   ],
   "source": [
    "epochs = 1\n",
    "train(net, criterion, opti, train_loader, val_loader, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git config --global credential.helper store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_name = \"beto_best_nllf_hf_ft_task_C1\"\n",
    "net.bert_layer.push_to_hub(repo_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_set.tokenizer.push_to_hub(repo_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.cls_layer, \"cls_layer.torch\")\n",
    "# torch.save(net.cls_layer2, \"cls_layer2.torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import hf_hub_url, cached_download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "863593d394614c8194f4549450116c54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading cls_layer.torch:   0%|          | 0.00/8.43k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "repo_name = \"beto_best_nllf_hf_ft_task_C1\"\n",
    "config_file_url = hf_hub_url(\"X/\"+repo_name, filename=\"cls_layer.torch\")\n",
    "value = cached_download(config_file_url)\n",
    "cls_layer = torch.load(value)\n",
    "# config_file_url = hf_hub_url(\"X/\"+repo_name, filename=\"cls_layer2.torch\")\n",
    "# value = cached_download(config_file_url)\n",
    "# cls_layer2 = torch.load(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a0899edf33a4e80aea600e77bd46ad7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/439M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "beto_model = BertModel.from_pretrained(\"X/\"+repo_name).cuda()\n",
    "beto_tokenizer = BertTokenizer.from_pretrained(\"X/\"+repo_name, do_lower_case=False)\n",
    "e = beto_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproccesing(Q, A, maxlen=60):\n",
    "        sentence1 = str(Q)\n",
    "        sentence2 = str(A)\n",
    "        \n",
    "        sentence1 = \" \".join(str(sentence1).replace(\"\\n\", \" \").split())\n",
    "        sentence2 = \" \".join(str(sentence2).replace(\"\\n\", \" \").split())\n",
    "        \n",
    "        tokens1 = beto_tokenizer.tokenize(sentence1) if len(sentence1)>0 else [\"[UNK]\"]\n",
    "        tokens2 = beto_tokenizer.tokenize(sentence2) if len(sentence2)>0 else [\"[UNK]\"]\n",
    "\n",
    "        if len(tokens1) < maxlen:\n",
    "            tokens1 = tokens1 + ['[PAD]' for _ in range(maxlen - len(tokens1))]\n",
    "        else:\n",
    "            tokens1 = tokens1[:maxlen]\n",
    "\n",
    "        if len(tokens2) < maxlen:\n",
    "            tokens2 = tokens2 + ['[PAD]' for _ in range(maxlen - len(tokens2))]\n",
    "        else:\n",
    "            tokens2 = tokens2[:maxlen]\n",
    "          \n",
    "        tokens = [\"[CLS]\"]+tokens1+[\"[SEP]\"]+tokens2+[\"[SEP]\"]\n",
    "        # tokens = [x for x in tokens if x!=\"[PAD]\"]\n",
    "        tokens_ids = beto_tokenizer.convert_tokens_to_ids(tokens)\n",
    "        tokens_ids_tensor = torch.tensor(tokens_ids)\n",
    "        attn_mask = (tokens_ids_tensor != 1).long() # [PAD] => 1\n",
    "\n",
    "        return tokens_ids_tensor.cuda(), attn_mask.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def C1Classifier(nlfls, mfs, Q, A):\n",
    "    tokens_ids_tensor, attn_mask = preproccesing(Q, A)\n",
    "    cont_reps = beto_model(tokens_ids_tensor.unsqueeze(0), attention_mask = attn_mask.unsqueeze(0))\n",
    "    cls_rep = cont_reps.last_hidden_state[:, 0]\n",
    "    mfs = torch.tensor(mfs).cuda()\n",
    "    nlfls = torch.tensor(nlfls).cuda()\n",
    "    mfs = mfs.to(cls_rep.dtype).unsqueeze(0)\n",
    "    nlfls = nlfls.to(cls_rep.dtype).unsqueeze(0)\n",
    "    cls_rep = torch.cat((mfs,cls_rep), 1)\n",
    "    cls_rep = torch.cat((nlfls,cls_rep), 1)\n",
    "    logits = cls_layer(cls_rep)\n",
    "    # logits = cls_layer2(inter)\n",
    "    probs = torch.sigmoid(logits)\n",
    "    return probs.detach().cpu().numpy()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Luis compró 10 caramelos, de los cuales 4 tenían menta, los demás no. ¿Cuántos caramelos no tenían menta? Representa esta ecuación.',) tiene 30 en total\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.7481085, 0.3794723], dtype=float32)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 0\n",
    "mfs = mf_A_train.iloc[i][mf_rel_cols].values\n",
    "nlfls = new_nlfl_A_train.iloc[i][bigcut]\n",
    "Q = A_train.iloc[i][\"Q\"], \n",
    "A = A_train.iloc[i][\"A\"]\n",
    "print(Q, A)\n",
    "C1Classifier(nlfls, mfs, Q, A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 45s, sys: 20.3 ms, total: 1min 45s\n",
      "Wall time: 1min 45s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.997453</td>\n",
       "      <td>0.869191</td>\n",
       "      <td>0.978112</td>\n",
       "      <td>0.933322</td>\n",
       "      <td>0.980365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.977243</td>\n",
       "      <td>0.983766</td>\n",
       "      <td>0.978112</td>\n",
       "      <td>0.980505</td>\n",
       "      <td>0.978112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.987245</td>\n",
       "      <td>0.922936</td>\n",
       "      <td>0.978112</td>\n",
       "      <td>0.955091</td>\n",
       "      <td>0.978677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>10019.000000</td>\n",
       "      <td>1540.000000</td>\n",
       "      <td>0.978112</td>\n",
       "      <td>11559.000000</td>\n",
       "      <td>11559.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      0            1  accuracy     macro avg  weighted avg\n",
       "precision      0.997453     0.869191  0.978112      0.933322      0.980365\n",
       "recall         0.977243     0.983766  0.978112      0.980505      0.978112\n",
       "f1-score       0.987245     0.922936  0.978112      0.955091      0.978677\n",
       "support    10019.000000  1540.000000  0.978112  11559.000000  11559.000000"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = [ int(\n",
    "    C1Classifier(\n",
    "        nlfls = new_nlfl_A_train.iloc[i][bigcut],\n",
    "        mfs = mf_A_train.iloc[i][mf_rel_cols].values,\n",
    "        Q=A_train.iloc[i][\"Q\"], \n",
    "        A=A_train.iloc[i][\"A\"]\n",
    "        )[0]<0.5) \n",
    "    for i in range(A_train.shape[0])\n",
    "]\n",
    "report = classification_report(A_train[\"label\"], y_pred, output_dict=True)\n",
    "train_report = pd.DataFrame(report)\n",
    "train_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(y_pred, open(\"data/y_pred_train_beto_best_nllf_hf_ft_task_C1.pickle\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 26.4 s, sys: 104 µs, total: 26.4 s\n",
      "Wall time: 26.4 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.978111</td>\n",
       "      <td>0.774942</td>\n",
       "      <td>0.947895</td>\n",
       "      <td>0.876527</td>\n",
       "      <td>0.950910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.961355</td>\n",
       "      <td>0.860825</td>\n",
       "      <td>0.947895</td>\n",
       "      <td>0.911090</td>\n",
       "      <td>0.947895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.969660</td>\n",
       "      <td>0.815629</td>\n",
       "      <td>0.947895</td>\n",
       "      <td>0.892645</td>\n",
       "      <td>0.949038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>2510.000000</td>\n",
       "      <td>388.000000</td>\n",
       "      <td>0.947895</td>\n",
       "      <td>2898.000000</td>\n",
       "      <td>2898.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     0           1  accuracy    macro avg  weighted avg\n",
       "precision     0.978111    0.774942  0.947895     0.876527      0.950910\n",
       "recall        0.961355    0.860825  0.947895     0.911090      0.947895\n",
       "f1-score      0.969660    0.815629  0.947895     0.892645      0.949038\n",
       "support    2510.000000  388.000000  0.947895  2898.000000   2898.000000"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = [ int(\n",
    "    C1Classifier(\n",
    "        new_nlfl_A_val.iloc[i][bigcut],\n",
    "        mf_A_val.iloc[i][mf_rel_cols].values,\n",
    "        A_val.iloc[i][\"Q\"], \n",
    "        A_val.iloc[i][\"A\"]\n",
    "        )[0]<0.5) \n",
    "    for i in range(A_val.shape[0])]\n",
    "report = classification_report(A_val[\"label\"], y_pred, output_dict=True)\n",
    "val_report = pd.DataFrame(report)\n",
    "val_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(y_pred, open(\"data/y_pred_val_beto_best_nllf_hf_ft_task_C1.pickle\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.13 s, sys: 12 µs, total: 6.13 s\n",
      "Wall time: 6.13 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.948718</td>\n",
       "      <td>0.824427</td>\n",
       "      <td>0.924668</td>\n",
       "      <td>0.886573</td>\n",
       "      <td>0.923750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.957486</td>\n",
       "      <td>0.794118</td>\n",
       "      <td>0.924668</td>\n",
       "      <td>0.875802</td>\n",
       "      <td>0.924668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.953082</td>\n",
       "      <td>0.808989</td>\n",
       "      <td>0.924668</td>\n",
       "      <td>0.881035</td>\n",
       "      <td>0.924136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>541.000000</td>\n",
       "      <td>136.000000</td>\n",
       "      <td>0.924668</td>\n",
       "      <td>677.000000</td>\n",
       "      <td>677.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0           1  accuracy   macro avg  weighted avg\n",
       "precision    0.948718    0.824427  0.924668    0.886573      0.923750\n",
       "recall       0.957486    0.794118  0.924668    0.875802      0.924668\n",
       "f1-score     0.953082    0.808989  0.924668    0.881035      0.924136\n",
       "support    541.000000  136.000000  0.924668  677.000000    677.000000"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = [ int(\n",
    "    C1Classifier(\n",
    "        new_nlfl_A_test.iloc[i][bigcut],\n",
    "        mf_A_test.iloc[i][mf_rel_cols].values,\n",
    "        A_test.iloc[i][\"Q\"], \n",
    "        A_test.iloc[i][\"A\"]\n",
    "        )[0]<0.5) \n",
    "    for i in range(A_test.shape[0])]\n",
    "report = classification_report(A_test[\"label\"], y_pred, output_dict=True)\n",
    "test_report = pd.DataFrame(report)\n",
    "test_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(y_pred, open(\"data/y_pred_test_beto_best_nllf_hf_ft_task_C1.pickle\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9809    0.9809    0.9809       262\n",
      "           1     0.8780    0.8780    0.8780        41\n",
      "\n",
      "    accuracy                         0.9670       303\n",
      "   macro avg     0.9295    0.9295    0.9295       303\n",
      "weighted avg     0.9670    0.9670    0.9670       303\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import pickle\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "file_names = {\n",
    "    \"train\": \"data/train_task_C1.xlsx\",\n",
    "    \"test\": \"data/test_task_C1.xlsx\",\n",
    "    \"val\": \"data/val_task_C1.xlsx\",\n",
    "    \"mf_train\": \"data/mf_features_train_task_C1.xlsx\",\n",
    "    \"mf_test\": \"data/mf_features_test_task_C1.xlsx\",\n",
    "    \"mf_val\": \"data/mf_features_val_task_C1.xlsx\",\n",
    "    \"nlfl_train\": \"data/nlfl_train_sample_v2.xlsx\",\n",
    "    \"nlfl_test\": \"data/nlfl_test_sample_v2.xlsx\",\n",
    "    \"nlfl_val\": \"data/nlfl_val_sample_v2.xlsx\",\n",
    "}\n",
    "A_test = pd.read_excel(file_names[\"test\"])\n",
    "test_label_Q = pd.read_excel(\"data/gpt_label_v7_comp.xlsx\")\n",
    "A_test[\"label_Q\"] = A_test.apply(lambda x: test_label_Q[test_label_Q[\"id\"] == x[\"id\"]].iloc[0][\"tipo_preg\"], axis=1)\n",
    "y_pred = pickle.load(open(\"data/y_pred_test_beto_best_nllf_hf_ft_task_C1.pickle\", \"rb\"))\n",
    "sub_index_test = A_test[\"label_Q\"] == 3\n",
    "print(classification_report(A_test.loc[A_test[sub_index_test].index][\"label\"], np.array(y_pred)[sub_index_test.values], digits=4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "net",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7108851178047dc680433843b93ee0e3779b5b27b2c4cebb614195d20b26b968"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
