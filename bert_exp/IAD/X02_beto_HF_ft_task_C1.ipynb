{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names = {\n",
    "    \"train\": \"data/train_task_C1.xlsx\",\n",
    "    \"test\": \"data/test_task_C1.xlsx\",\n",
    "    \"val\": \"data/val_task_C1.xlsx\",\n",
    "    \"mf_train\": \"data/mf_features_train_task_C1.xlsx\",\n",
    "    \"mf_test\": \"data/mf_features_test_task_C1.xlsx\",\n",
    "    \"mf_val\": \"data/mf_features_val_task_C1.xlsx\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_train = pd.read_excel(file_names[\"train\"], index_col=\"id\").sample(frac = 1, random_state=2022).reset_index()\n",
    "A_val = pd.read_excel(file_names[\"val\"])\n",
    "A_test = pd.read_excel(file_names[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: >"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "A_train[\"label\"].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 19s, sys: 244 ms, total: 2min 19s\n",
      "Wall time: 2min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "mf_A_train = pd.read_excel(file_names[\"mf_train\"])\n",
    "mf_A_val = pd.read_excel(file_names[\"mf_val\"])\n",
    "mf_A_test = pd.read_excel(file_names[\"mf_test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 73.3 ms, sys: 23.9 ms, total: 97.2 ms\n",
      "Wall time: 106 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "mf_A_train = mf_A_train.set_index(\"id\").loc[A_train[\"id\"]].reset_index()\n",
    "mf_A_test = mf_A_test.set_index(\"id\").loc[A_test[\"id\"]].reset_index()\n",
    "mf_A_val = mf_A_val.set_index(\"id\").loc[A_val[\"id\"]].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rel_cols = [c for c in mf_A_train.columns if \"id\" != c and \"linguistic\" not in c]\n",
    "len(rel_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install transformers\n",
    "!pip install datasets\n",
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aaff77ad5bde4cff94ef5ae68bf7488e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/648 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17a0d966b06b4e83b133742d994f226c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dccuchile/bert-base-spanish-wwm-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46117ab42ac84059ade0242d6e4802c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/242k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51ca243be8064b6da0ea33b025178fb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/134 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e111f9fc2f54ea8b4961aac95e4dff8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/364 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"dccuchile/bert-base-spanish-wwm-cased\"\n",
    "beto_model = BertModel.from_pretrained(model_name)\n",
    "beto_tokenizer = BertTokenizer.from_pretrained(model_name, do_lower_case=False)\n",
    "e = beto_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['[UNK]', '[SEP]', '[PAD]', '[CLS]', '[MASK]'], [3, 5, 1, 4, 0])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beto_tokenizer.all_special_tokens, beto_tokenizer.all_special_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "class DatasetTaskC1(Dataset):\n",
    "    def __init__(self, df, df_mf, maxlen):\n",
    "        self.df = df\n",
    "        self.df_mf = df_mf\n",
    "        self.tokenizer = beto_tokenizer\n",
    "        self.maxlen = maxlen\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        sentence1 = str(self.df.loc[index, 'Q'])\n",
    "        sentence2 = str(self.df.loc[index, 'A'])\n",
    "        \n",
    "        sentence1 = \" \".join(str(sentence1).replace(\"\\n\", \" \").split())\n",
    "        sentence2 = \" \".join(str(sentence2).replace(\"\\n\", \" \").split())\n",
    "\n",
    "        label = self.df.loc[index, 'label']\n",
    "        \n",
    "        tokens1 = self.tokenizer.tokenize(sentence1) if len(sentence1)>0 else [\"[UNK]\"]\n",
    "        tokens2 = self.tokenizer.tokenize(sentence2) if len(sentence2)>0 else [\"[UNK]\"]\n",
    "\n",
    "        if len(tokens1) < self.maxlen:\n",
    "            tokens1 = tokens1 + ['[PAD]' for _ in range(self.maxlen - len(tokens1))]\n",
    "        else:\n",
    "            tokens1 = tokens1[:self.maxlen]\n",
    "\n",
    "        if len(tokens2) < self.maxlen:\n",
    "            tokens2 = tokens2 + ['[PAD]' for _ in range(self.maxlen - len(tokens2))]\n",
    "        else:\n",
    "            tokens2 = tokens2[:self.maxlen]\n",
    "          \n",
    "        tokens = [\"[CLS]\"]+tokens1+[\"[SEP]\"]+tokens2+[\"[SEP]\"]\n",
    "        tokens_ids = self.tokenizer.convert_tokens_to_ids(tokens)\n",
    "        tokens_ids_tensor = torch.tensor(tokens_ids)\n",
    "        attn_mask = (tokens_ids_tensor != 1).long() # [PAD] => 1\n",
    "\n",
    "        mf_tensor = torch.tensor(self.df_mf.loc[index, :].values)\n",
    "\n",
    "        return mf_tensor, tokens_ids_tensor, attn_mask, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_set = DatasetTaskC1(df = A_train, df_mf = mf_A_train[rel_cols].astype(float), maxlen = 60)\n",
    "val_set = DatasetTaskC1(df = A_val, df_mf = mf_A_val[rel_cols].astype(float), maxlen = 60)\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size = 32, num_workers = 2, shuffle=False)\n",
    "val_loader = DataLoader(val_set, batch_size = 32, num_workers = 2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class C1Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(C1Classifier, self).__init__()\n",
    "        torch.manual_seed(2022)\n",
    "        \n",
    "        self.bert_layer = BertModel.from_pretrained(model_name).cuda()\n",
    "        self.cls_layer = nn.Linear(66+768, 2).cuda()\n",
    "\n",
    "    def forward(self, mfs, seq, attn_masks):\n",
    "\n",
    "        cont_reps = self.bert_layer(seq, attention_mask=attn_masks)\n",
    "        \n",
    "        cls_rep = cont_reps.last_hidden_state[:, 0]\n",
    "        mfs = mfs.to(cls_rep.dtype)\n",
    "        cls_rep = torch.cat((mfs,cls_rep), 1)\n",
    "\n",
    "        logits = self.cls_layer(cls_rep)\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dccuchile/bert-base-spanish-wwm-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "net = C1Classifier()\n",
    "\n",
    "weights = torch.tensor([1., 6.5])\n",
    "criterion = nn.CrossEntropyLoss(weight=weights, reduction='mean').cuda()\n",
    "\n",
    "opti = optim.Adam(net.parameters(), lr = 2e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy_from_logits(logits, labels):\n",
    "    probs = torch.sigmoid(logits)\n",
    "    soft_probs = probs.argmax(1)\n",
    "    acc = (soft_probs.squeeze() == labels).float().mean()\n",
    "    return acc\n",
    "    \n",
    "def evaluate(net, criterion, dataloader):\n",
    "    net.eval()\n",
    "    mean_acc, mean_loss = 0, 0\n",
    "    count = 0\n",
    "    with torch.no_grad():\n",
    "        for mfs, seq, attn_masks, labels in dataloader:\n",
    "            mfs, seq, attn_masks, labels = mfs.cuda(), seq.cuda(), attn_masks.cuda(), labels.cuda()\n",
    "            logits = net(mfs, seq, attn_masks)\n",
    "            mean_loss += criterion(logits, labels).item()\n",
    "            mean_acc += get_accuracy_from_logits(logits, labels)\n",
    "            count += 1\n",
    "\n",
    "    return mean_acc / count, mean_loss / count\n",
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def evaluate_precision_recall_fscore_support(net, dataloader):\n",
    "    net.eval()\n",
    "    preds = []\n",
    "    tests = []\n",
    "    with torch.no_grad():\n",
    "        for mfs, seq, attn_masks, labels in dataloader:\n",
    "            mfs, seq, attn_masks, labels = mfs.cuda(), seq.cuda(), attn_masks.cuda(), labels.cuda()\n",
    "            logits = net(mfs, seq, attn_masks)\n",
    "            probs = torch.sigmoid(logits)\n",
    "            soft_probs = probs.argmax(1)\n",
    "            preds += soft_probs.squeeze().tolist()\n",
    "            tests += labels.tolist()\n",
    "    return tests, preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, criterion, opti, train_loader, val_loader, epochs):\n",
    "    for ep in range(epochs):\n",
    "        for it, (mfs, seq, attn_masks, labels) in enumerate(train_loader):\n",
    "            opti.zero_grad()  \n",
    "\n",
    "            mfs, seq, attn_masks, labels = mfs.cuda(), seq.cuda(), attn_masks.cuda(), labels.cuda()\n",
    "\n",
    "            logits = net(mfs, seq, attn_masks)\n",
    "\n",
    "            loss = criterion(logits, labels)\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            opti.step()\n",
    "\n",
    "            if (it + 1) % 100 == 0:\n",
    "                acc = get_accuracy_from_logits(logits, labels)\n",
    "                # tests, preds = evaluate_precision_recall_fscore_support(net, train_loader)\n",
    "                # print(classification_report(tests, preds))\n",
    "                print(\"Iteration {} of epoch {} complete. Loss : {} Train Accuracy : {}\".format(it+1, ep+1, loss.item(), acc))\n",
    "        val_acc, val_loss = evaluate(net, criterion, val_loader)\n",
    "        tests, preds = evaluate_precision_recall_fscore_support(net, val_loader)\n",
    "        print(classification_report(tests, preds))\n",
    "        print(\"Epoch {} complete! Validation Accuracy : {}, Validation Loss : {}\".format(ep+1, val_acc, val_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 100 of epoch 1 complete. Loss : 0.25465142726898193 Train Accuracy : 0.90625\n",
      "Iteration 200 of epoch 1 complete. Loss : 0.26307180523872375 Train Accuracy : 0.96875\n",
      "Iteration 300 of epoch 1 complete. Loss : 0.6701672077178955 Train Accuracy : 0.9375\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97      2510\n",
      "           1       0.80      0.82      0.81       388\n",
      "\n",
      "    accuracy                           0.95      2898\n",
      "   macro avg       0.89      0.89      0.89      2898\n",
      "weighted avg       0.95      0.95      0.95      2898\n",
      "\n",
      "Epoch 1 complete! Validation Accuracy : 0.9489087462425232, Validation Loss : 0.2551502956097925\n",
      "Iteration 100 of epoch 2 complete. Loss : 0.10069958120584488 Train Accuracy : 0.9375\n",
      "Iteration 200 of epoch 2 complete. Loss : 0.12246681749820709 Train Accuracy : 0.96875\n",
      "Iteration 300 of epoch 2 complete. Loss : 0.011322111822664738 Train Accuracy : 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.96      2510\n",
      "           1       0.72      0.91      0.80       388\n",
      "\n",
      "    accuracy                           0.94      2898\n",
      "   macro avg       0.85      0.93      0.88      2898\n",
      "weighted avg       0.95      0.94      0.94      2898\n",
      "\n",
      "Epoch 2 complete! Validation Accuracy : 0.939980149269104, Validation Loss : 0.21622989468972434\n",
      "Iteration 100 of epoch 3 complete. Loss : 0.012133700773119926 Train Accuracy : 1.0\n",
      "Iteration 200 of epoch 3 complete. Loss : 0.007169779390096664 Train Accuracy : 1.0\n",
      "Iteration 300 of epoch 3 complete. Loss : 0.007017764262855053 Train Accuracy : 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.86      0.92      2510\n",
      "           1       0.51      0.96      0.67       388\n",
      "\n",
      "    accuracy                           0.87      2898\n",
      "   macro avg       0.75      0.91      0.79      2898\n",
      "weighted avg       0.93      0.87      0.89      2898\n",
      "\n",
      "Epoch 3 complete! Validation Accuracy : 0.8711081147193909, Validation Loss : 0.31894523209308856\n",
      "Iteration 100 of epoch 4 complete. Loss : 0.017473705112934113 Train Accuracy : 1.0\n",
      "Iteration 200 of epoch 4 complete. Loss : 0.0020616224501281977 Train Accuracy : 1.0\n",
      "Iteration 300 of epoch 4 complete. Loss : 0.02225239761173725 Train Accuracy : 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97      2510\n",
      "           1       0.78      0.87      0.82       388\n",
      "\n",
      "    accuracy                           0.95      2898\n",
      "   macro avg       0.88      0.92      0.90      2898\n",
      "weighted avg       0.95      0.95      0.95      2898\n",
      "\n",
      "Epoch 4 complete! Validation Accuracy : 0.9492521286010742, Validation Loss : 0.37006256345193833\n",
      "Iteration 100 of epoch 5 complete. Loss : 0.010326338931918144 Train Accuracy : 1.0\n",
      "Iteration 200 of epoch 5 complete. Loss : 0.00045913353096693754 Train Accuracy : 1.0\n",
      "Iteration 300 of epoch 5 complete. Loss : 0.0015968772349879146 Train Accuracy : 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98      2510\n",
      "           1       0.87      0.82      0.84       388\n",
      "\n",
      "    accuracy                           0.96      2898\n",
      "   macro avg       0.92      0.90      0.91      2898\n",
      "weighted avg       0.96      0.96      0.96      2898\n",
      "\n",
      "Epoch 5 complete! Validation Accuracy : 0.9588675498962402, Validation Loss : 0.566502051317062\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "train(net, criterion, opti, train_loader, val_loader, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git config --global credential.helper store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'net' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m repo_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbeto_hf_ft_task_C1\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m net\u001b[39m.\u001b[39mbert_layer\u001b[39m.\u001b[39mpush_to_hub(repo_name)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'net' is not defined"
     ]
    }
   ],
   "source": [
    "repo_name = \"beto_hf_ft_task_C1\"\n",
    "net.bert_layer.push_to_hub(repo_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'val_set' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m val_set\u001b[39m.\u001b[39mtokenizer\u001b[39m.\u001b[39mpush_to_hub(repo_name)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'val_set' is not defined"
     ]
    }
   ],
   "source": [
    "val_set.tokenizer.push_to_hub(repo_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.cls_layer, \"cls_layer.torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import hf_hub_url, cached_download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hf_hub_url' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m repo_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbeto_hf_ft_task_C1\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m config_file_url \u001b[39m=\u001b[39m hf_hub_url(\u001b[39m\"\u001b[39m\u001b[39mX/\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m+\u001b[39mrepo_name, filename\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcls_layer.torch\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m value \u001b[39m=\u001b[39m cached_download(config_file_url)\n\u001b[1;32m      4\u001b[0m cls_layer \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mload(value)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'hf_hub_url' is not defined"
     ]
    }
   ],
   "source": [
    "repo_name = \"beto_hf_ft_task_C1\"\n",
    "config_file_url = hf_hub_url(\"X/\"+repo_name, filename=\"cls_layer.torch\")\n",
    "value = cached_download(config_file_url)\n",
    "cls_layer = torch.load(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'BertModel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m beto_model \u001b[39m=\u001b[39m BertModel\u001b[39m.\u001b[39mfrom_pretrained(\u001b[39m\"\u001b[39m\u001b[39mX/\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m+\u001b[39mrepo_name)\u001b[39m.\u001b[39mcuda()\n\u001b[1;32m      2\u001b[0m beto_tokenizer \u001b[39m=\u001b[39m BertTokenizer\u001b[39m.\u001b[39mfrom_pretrained(\u001b[39m\"\u001b[39m\u001b[39mX/\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m+\u001b[39mrepo_name, do_lower_case\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[1;32m      3\u001b[0m e \u001b[39m=\u001b[39m beto_model\u001b[39m.\u001b[39meval()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'BertModel' is not defined"
     ]
    }
   ],
   "source": [
    "beto_model = BertModel.from_pretrained(\"X/\"+repo_name).cuda()\n",
    "beto_tokenizer = BertTokenizer.from_pretrained(\"X/\"+repo_name, do_lower_case=False)\n",
    "e = beto_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproccesing(Q, A, maxlen=60):\n",
    "        sentence1 = str(Q)\n",
    "        sentence2 = str(A)\n",
    "        \n",
    "        sentence1 = \" \".join(str(sentence1).replace(\"\\n\", \" \").split())\n",
    "        sentence2 = \" \".join(str(sentence2).replace(\"\\n\", \" \").split())\n",
    "        \n",
    "        tokens1 = beto_tokenizer.tokenize(sentence1) if len(sentence1)>0 else [\"[UNK]\"]\n",
    "        tokens2 = beto_tokenizer.tokenize(sentence2) if len(sentence2)>0 else [\"[UNK]\"]\n",
    "\n",
    "        if len(tokens1) < maxlen:\n",
    "            tokens1 = tokens1 + ['[PAD]' for _ in range(maxlen - len(tokens1))]\n",
    "        else:\n",
    "            tokens1 = tokens1[:maxlen]\n",
    "\n",
    "        if len(tokens2) < maxlen:\n",
    "            tokens2 = tokens2 + ['[PAD]' for _ in range(maxlen - len(tokens2))]\n",
    "        else:\n",
    "            tokens2 = tokens2[:maxlen]\n",
    "          \n",
    "        tokens = [\"[CLS]\"]+tokens1+[\"[SEP]\"]+tokens2+[\"[SEP]\"]\n",
    "        # tokens = [x for x in tokens if x!=\"[PAD]\"]\n",
    "        tokens_ids = beto_tokenizer.convert_tokens_to_ids(tokens)\n",
    "        tokens_ids_tensor = torch.tensor(tokens_ids)\n",
    "        attn_mask = (tokens_ids_tensor != 1).long() # [PAD] => 1\n",
    "\n",
    "        return tokens_ids_tensor.cuda(), attn_mask.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def C1Classifier(mfs, Q, A):\n",
    "    tokens_ids_tensor, attn_mask = preproccesing(Q, A)\n",
    "    cont_reps = beto_model(tokens_ids_tensor.unsqueeze(0), attention_mask = attn_mask.unsqueeze(0))\n",
    "    cls_rep = cont_reps.last_hidden_state[:, 0]\n",
    "    mfs = torch.tensor(mfs).cuda()\n",
    "    mfs = mfs.to(cls_rep.dtype).unsqueeze(0)\n",
    "    cls_rep = torch.cat((mfs,cls_rep), 1)\n",
    "    logits = cls_layer(cls_rep)\n",
    "    probs = torch.sigmoid(logits)\n",
    "    return probs.detach().cpu().numpy()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Luis compró 10 caramelos, de los cuales 4 tenían menta, los demás no. ¿Cuántos caramelos no tenían menta? Representa esta ecuación.',) tiene 30 en total\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.98354834, 0.02162533], dtype=float32)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 0\n",
    "mfs = mf_A_train.iloc[i][rel_cols]\n",
    "Q = A_train.iloc[i][\"Q\"], \n",
    "A = A_train.iloc[i][\"A\"]\n",
    "print(Q, A)\n",
    "C1Classifier(mfs, Q, A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 50s, sys: 30.2 ms, total: 1min 50s\n",
      "Wall time: 1min 50s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.998901</td>\n",
       "      <td>0.985816</td>\n",
       "      <td>0.997145</td>\n",
       "      <td>0.992358</td>\n",
       "      <td>0.997158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.997804</td>\n",
       "      <td>0.992857</td>\n",
       "      <td>0.997145</td>\n",
       "      <td>0.995331</td>\n",
       "      <td>0.997145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.998352</td>\n",
       "      <td>0.989324</td>\n",
       "      <td>0.997145</td>\n",
       "      <td>0.993838</td>\n",
       "      <td>0.997149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>10019.000000</td>\n",
       "      <td>1540.000000</td>\n",
       "      <td>0.997145</td>\n",
       "      <td>11559.000000</td>\n",
       "      <td>11559.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      0            1  accuracy     macro avg  weighted avg\n",
       "precision      0.998901     0.985816  0.997145      0.992358      0.997158\n",
       "recall         0.997804     0.992857  0.997145      0.995331      0.997145\n",
       "f1-score       0.998352     0.989324  0.997145      0.993838      0.997149\n",
       "support    10019.000000  1540.000000  0.997145  11559.000000  11559.000000"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = [ int(\n",
    "    C1Classifier(\n",
    "        mfs=mf_A_train.iloc[i][rel_cols], \n",
    "        Q=A_train.iloc[i][\"Q\"], \n",
    "        A=A_train.iloc[i][\"A\"]\n",
    "        )[0]<0.5) \n",
    "    for i in range(A_train.shape[0])\n",
    "]\n",
    "report = classification_report(A_train[\"label\"], y_pred, output_dict=True)\n",
    "train_report = pd.DataFrame(report)\n",
    "train_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(y_pred, open(\"data/y_pred_train_beto_hf_ft_task_C1.pickle\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 27.1 s, sys: 8.18 ms, total: 27.1 s\n",
      "Wall time: 27.1 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.970901</td>\n",
       "      <td>0.884507</td>\n",
       "      <td>0.960317</td>\n",
       "      <td>0.927704</td>\n",
       "      <td>0.959334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.983665</td>\n",
       "      <td>0.809278</td>\n",
       "      <td>0.960317</td>\n",
       "      <td>0.896472</td>\n",
       "      <td>0.960317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.977241</td>\n",
       "      <td>0.845222</td>\n",
       "      <td>0.960317</td>\n",
       "      <td>0.911232</td>\n",
       "      <td>0.959566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>2510.000000</td>\n",
       "      <td>388.000000</td>\n",
       "      <td>0.960317</td>\n",
       "      <td>2898.000000</td>\n",
       "      <td>2898.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     0           1  accuracy    macro avg  weighted avg\n",
       "precision     0.970901    0.884507  0.960317     0.927704      0.959334\n",
       "recall        0.983665    0.809278  0.960317     0.896472      0.960317\n",
       "f1-score      0.977241    0.845222  0.960317     0.911232      0.959566\n",
       "support    2510.000000  388.000000  0.960317  2898.000000   2898.000000"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = [ int(\n",
    "    C1Classifier(\n",
    "        mf_A_val.iloc[i][rel_cols], \n",
    "        A_val.iloc[i][\"Q\"], \n",
    "        A_val.iloc[i][\"A\"]\n",
    "        )[0]<0.5) \n",
    "    for i in range(A_val.shape[0])]\n",
    "report = classification_report(A_val[\"label\"], y_pred, output_dict=True)\n",
    "val_report = pd.DataFrame(report)\n",
    "val_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(y_pred, open(\"data/y_pred_val_beto_hf_ft_task_C1.pickle\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.59 s, sys: 1.01 ms, total: 6.59 s\n",
      "Wall time: 6.59 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.932384</td>\n",
       "      <td>0.852174</td>\n",
       "      <td>0.918759</td>\n",
       "      <td>0.892279</td>\n",
       "      <td>0.916271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.968577</td>\n",
       "      <td>0.720588</td>\n",
       "      <td>0.918759</td>\n",
       "      <td>0.844582</td>\n",
       "      <td>0.918759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.950136</td>\n",
       "      <td>0.780876</td>\n",
       "      <td>0.918759</td>\n",
       "      <td>0.865506</td>\n",
       "      <td>0.916134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>541.000000</td>\n",
       "      <td>136.000000</td>\n",
       "      <td>0.918759</td>\n",
       "      <td>677.000000</td>\n",
       "      <td>677.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0           1  accuracy   macro avg  weighted avg\n",
       "precision    0.932384    0.852174  0.918759    0.892279      0.916271\n",
       "recall       0.968577    0.720588  0.918759    0.844582      0.918759\n",
       "f1-score     0.950136    0.780876  0.918759    0.865506      0.916134\n",
       "support    541.000000  136.000000  0.918759  677.000000    677.000000"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = [ int(\n",
    "    C1Classifier(\n",
    "        mf_A_test.iloc[i][rel_cols], \n",
    "        A_test.iloc[i][\"Q\"], \n",
    "        A_test.iloc[i][\"A\"]\n",
    "        )[0]<0.5) \n",
    "    for i in range(A_test.shape[0])]\n",
    "report = classification_report(A_test[\"label\"], y_pred, output_dict=True)\n",
    "test_report = pd.DataFrame(report)\n",
    "test_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(y_pred, open(\"data/y_pred_test_beto_hf_ft_task_C1.pickle\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9739    0.9962    0.9849       262\n",
      "           1     0.9714    0.8293    0.8947        41\n",
      "\n",
      "    accuracy                         0.9736       303\n",
      "   macro avg     0.9727    0.9127    0.9398       303\n",
      "weighted avg     0.9735    0.9736    0.9727       303\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import pickle\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "file_names = {\n",
    "    \"train\": \"data/train_task_C1.xlsx\",\n",
    "    \"test\": \"data/test_task_C1.xlsx\",\n",
    "    \"val\": \"data/val_task_C1.xlsx\",\n",
    "    \"mf_train\": \"data/mf_features_train_task_C1.xlsx\",\n",
    "    \"mf_test\": \"data/mf_features_test_task_C1.xlsx\",\n",
    "    \"mf_val\": \"data/mf_features_val_task_C1.xlsx\",\n",
    "}\n",
    "A_test = pd.read_excel(file_names[\"test\"])\n",
    "test_label_Q = pd.read_excel(\"data/gpt_label_v7_comp.xlsx\")\n",
    "A_test[\"label_Q\"] = A_test.apply(lambda x: test_label_Q[test_label_Q[\"id\"] == x[\"id\"]].iloc[0][\"tipo_preg\"], axis=1)\n",
    "y_pred = pickle.load(open(\"data/y_pred_test_beto_hf_ft_task_C1.pickle\", \"rb\"))\n",
    "sub_index_test = A_test[\"label_Q\"] == 3\n",
    "print(classification_report(A_test.loc[A_test[sub_index_test].index][\"label\"], np.array(y_pred)[sub_index_test.values], digits=4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
