{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names = {\n",
    "    \"train\": \"data/nlfl_train_sample_v2.xlsx\",\n",
    "    \"test\": \"data/nlfl_test_sample_v2.xlsx\",\n",
    "    \"val\": \"data/nlfl_val_sample_v2.xlsx\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_train = pd.read_excel(file_names[\"train\"], index_col=\"id\").sample(frac = 1, random_state=2022).reset_index()\n",
    "A_val = pd.read_excel(file_names[\"val\"])\n",
    "A_test = pd.read_excel(file_names[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: >"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "A_train[\"label\"].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['chatgpt_v1 (N)',\n",
       " 'chatgpt_v1 (Y)',\n",
       " 'chatgpt_v2 (N)',\n",
       " 'chatgpt_v2 (Y)',\n",
       " 'chatgpt_v3 (N)',\n",
       " 'chatgpt_v3 (Y)',\n",
       " 'chatgpt_v4 (N)',\n",
       " 'chatgpt_v4 (Y)',\n",
       " 'chatgpt_v5 (N)',\n",
       " 'chatgpt_v5 (Y)',\n",
       " 'chatgpt_v6 (N)',\n",
       " 'chatgpt_v6 (Y)',\n",
       " 'chatgpt_v7 (N)',\n",
       " 'chatgpt_v7 (Y)',\n",
       " 'chatgpt_v8 (N)',\n",
       " 'chatgpt_v8 (Y)',\n",
       " 'chatgpt_v9 (N)',\n",
       " 'chatgpt_v9 (Y)',\n",
       " 'chatgpt_v10 (N)',\n",
       " 'chatgpt_v10 (Y)',\n",
       " 'chatgpt_v5_1 (N)',\n",
       " 'chatgpt_v5_1 (Y)',\n",
       " 'chatgpt_v5_2 (N)',\n",
       " 'chatgpt_v5_2 (Y)',\n",
       " 'chatgpt_v5_3 (N)',\n",
       " 'chatgpt_v5_3 (Y)',\n",
       " 'chatgpt_v5_4 (N)',\n",
       " 'chatgpt_v5_4 (Y)',\n",
       " 'chatgpt_v5_5 (N)',\n",
       " 'chatgpt_v5_5 (Y)',\n",
       " 'chatgpt_v6_1 (N)',\n",
       " 'chatgpt_v6_1 (Y)',\n",
       " 'chatgpt_v6_2 (N)',\n",
       " 'chatgpt_v6_2 (Y)',\n",
       " 'chatgpt_v6_3 (N)',\n",
       " 'chatgpt_v6_3 (Y)',\n",
       " 'chatgpt_v6_4 (N)',\n",
       " 'chatgpt_v6_4 (Y)',\n",
       " 'chatgpt_Q3_1 (N)',\n",
       " 'chatgpt_Q3_1 (Y)',\n",
       " 'chatgpt_Q3_2 (N)',\n",
       " 'chatgpt_Q3_2 (Y)',\n",
       " 'chatgpt_Q3_3 (N)',\n",
       " 'chatgpt_Q3_3 (Y)',\n",
       " 'chatgpt_Q3_4 (N)',\n",
       " 'chatgpt_Q3_4 (Y)',\n",
       " 'chatgpt_Q3_5 (N)',\n",
       " 'chatgpt_Q3_5 (Y)',\n",
       " 'chatgpt_Q3_6 (N)',\n",
       " 'chatgpt_Q3_6 (Y)',\n",
       " 'chatgpt_Q3_7 (N)',\n",
       " 'chatgpt_Q3_7 (Y)',\n",
       " 'chatgpt_Q3_8 (N)',\n",
       " 'chatgpt_Q3_8 (Y)',\n",
       " 'chatgpt_Q3_9 (N)',\n",
       " 'chatgpt_Q3_9 (Y)',\n",
       " 'chatgpt_Q3_10 (N)',\n",
       " 'chatgpt_Q3_10 (Y)',\n",
       " 'chatgpt_Q3_11 (N)',\n",
       " 'chatgpt_Q3_11 (Y)',\n",
       " 'chatgpt_Q3_12 (N)',\n",
       " 'chatgpt_Q3_12 (Y)',\n",
       " 'chatgpt_Q3_13 (N)',\n",
       " 'chatgpt_Q3_13 (Y)',\n",
       " 'chatgpt_Q3_14 (N)',\n",
       " 'chatgpt_Q3_14 (Y)',\n",
       " 'chatgpt_Q3_15 (N)',\n",
       " 'chatgpt_Q3_15 (Y)',\n",
       " 'chatgpt_Q3_16 (N)',\n",
       " 'chatgpt_Q3_16 (Y)',\n",
       " 'chatgpt_Q3_7_e1 (N)',\n",
       " 'chatgpt_Q3_7_e1 (Y)',\n",
       " 'chatgpt_Q3_7_e2 (N)',\n",
       " 'chatgpt_Q3_7_e2 (Y)',\n",
       " 'chatgpt_Q3_7_e3 (N)',\n",
       " 'chatgpt_Q3_7_e3 (Y)',\n",
       " 'chatgpt_Q3_7_e4 (N)',\n",
       " 'chatgpt_Q3_7_e4 (Y)',\n",
       " 'chatgpt_Q3_7_e5 (N)',\n",
       " 'chatgpt_Q3_7_e5 (Y)',\n",
       " 'chatgpt_10_e1 (N)',\n",
       " 'chatgpt_10_e1 (Y)',\n",
       " 'chatgpt_10_e2 (N)',\n",
       " 'chatgpt_10_e2 (Y)',\n",
       " 'chatgpt_10_e3 (N)',\n",
       " 'chatgpt_10_e3 (Y)',\n",
       " 'chatgpt_10_e4 (N)',\n",
       " 'chatgpt_10_e4 (Y)',\n",
       " 'chatgpt_10_e5 (N)',\n",
       " 'chatgpt_10_e5 (Y)',\n",
       " 'chatgpt_7_e1 (N)',\n",
       " 'chatgpt_7_e1 (Y)',\n",
       " 'chatgpt_7_e2 (N)',\n",
       " 'chatgpt_7_e2 (Y)',\n",
       " 'chatgpt_7_e3 (N)',\n",
       " 'chatgpt_7_e3 (Y)',\n",
       " 'chatgpt_7_e4 (N)',\n",
       " 'chatgpt_7_e4 (Y)',\n",
       " 'chatgpt_7_e5 (N)',\n",
       " 'chatgpt_7_e5 (Y)',\n",
       " 'chatgpt_Q3_4_e1 (N)',\n",
       " 'chatgpt_Q3_4_e1 (Y)',\n",
       " 'chatgpt_Q3_4_e2 (N)',\n",
       " 'chatgpt_Q3_4_e2 (Y)',\n",
       " 'chatgpt_Q3_4_e3 (N)',\n",
       " 'chatgpt_Q3_4_e3 (Y)',\n",
       " 'chatgpt_Q3_4_e4 (N)',\n",
       " 'chatgpt_Q3_4_e4 (Y)',\n",
       " 'chatgpt_Q3_4_e5 (N)',\n",
       " 'chatgpt_Q3_4_e5 (Y)',\n",
       " 'chatgpt_Q3_5_e1 (N)',\n",
       " 'chatgpt_Q3_5_e1 (Y)',\n",
       " 'chatgpt_Q3_5_e2 (N)',\n",
       " 'chatgpt_Q3_5_e2 (Y)',\n",
       " 'chatgpt_Q3_5_e3 (N)',\n",
       " 'chatgpt_Q3_5_e3 (Y)',\n",
       " 'chatgpt_Q3_5_e4 (N)',\n",
       " 'chatgpt_Q3_5_e4 (Y)',\n",
       " 'chatgpt_Q3_5_e5 (N)',\n",
       " 'chatgpt_Q3_5_e5 (Y)',\n",
       " 'chatgpt_HF_1 (N)',\n",
       " 'chatgpt_HF_1 (Y)',\n",
       " 'chatgpt_HF_2 (N)',\n",
       " 'chatgpt_HF_2 (Y)',\n",
       " 'chatgpt_HF_3 (N)',\n",
       " 'chatgpt_HF_3 (Y)',\n",
       " 'chatgpt_HF_4 (N)',\n",
       " 'chatgpt_HF_4 (Y)',\n",
       " 'chatgpt_HF_5 (N)',\n",
       " 'chatgpt_HF_5 (Y)',\n",
       " 'chatgpt_HF_6 (N)',\n",
       " 'chatgpt_HF_6 (Y)']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rel_cols = [c for c in A_train.columns if \"chatgpt_label\" != c and \"chatgpt_\" in c]\n",
    "rel_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 146 ms, sys: 0 ns, total: 146 ms\n",
      "Wall time: 145 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "new_A_test = A_test.copy().drop(columns=rel_cols)\n",
    "new_A_train = A_train.copy().drop(columns=rel_cols)\n",
    "new_A_val = A_val.copy().drop(columns=rel_cols)\n",
    "\n",
    "bigcut = list(set([c.split()[0] for c in rel_cols]))\n",
    "\n",
    "for bc in bigcut:\n",
    "    new_A_train[bc]  = A_train[f\"{bc} (Y)\"] / A_train[[f'{bc} (N)',f'{bc} (Y)']].sum(axis=1)\n",
    "    new_A_test[bc]  = A_test[f\"{bc} (Y)\"] / A_test[[f'{bc} (N)',f'{bc} (Y)']].sum(axis=1)\n",
    "    new_A_val[bc]  = A_val[f\"{bc} (Y)\"] / A_val[[f'{bc} (N)',f'{bc} (Y)']].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install transformers\n",
    "!pip install datasets\n",
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dccuchile/bert-base-spanish-wwm-cased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model_name = \"dccuchile/bert-base-spanish-wwm-cased\"\n",
    "beto_model = BertModel.from_pretrained(model_name)\n",
    "beto_tokenizer = BertTokenizer.from_pretrained(model_name, do_lower_case=False)\n",
    "e = beto_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['[UNK]', '[SEP]', '[PAD]', '[CLS]', '[MASK]'], [3, 5, 1, 4, 0])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beto_tokenizer.all_special_tokens, beto_tokenizer.all_special_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "class DatasetTaskC1(Dataset):\n",
    "    def __init__(self, df, maxlen):\n",
    "        self.df = df\n",
    "        self.tokenizer = beto_tokenizer\n",
    "        self.maxlen = maxlen\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        sentence1 = str(self.df.loc[index, 'Q'])\n",
    "        sentence2 = str(self.df.loc[index, 'A'])\n",
    "        \n",
    "        sentence1 = \" \".join(str(sentence1).replace(\"\\n\", \" \").split())\n",
    "        sentence2 = \" \".join(str(sentence2).replace(\"\\n\", \" \").split())\n",
    "\n",
    "        label = self.df.loc[index, 'label']\n",
    "        \n",
    "        tokens1 = self.tokenizer.tokenize(sentence1) if len(sentence1)>0 else [\"[UNK]\"]\n",
    "        tokens2 = self.tokenizer.tokenize(sentence2) if len(sentence2)>0 else [\"[UNK]\"]\n",
    "\n",
    "        if len(tokens1) < self.maxlen:\n",
    "            tokens1 = tokens1 + ['[PAD]' for _ in range(self.maxlen - len(tokens1))]\n",
    "        else:\n",
    "            tokens1 = tokens1[:self.maxlen]\n",
    "\n",
    "        if len(tokens2) < self.maxlen:\n",
    "            tokens2 = tokens2 + ['[PAD]' for _ in range(self.maxlen - len(tokens2))]\n",
    "        else:\n",
    "            tokens2 = tokens2[:self.maxlen]\n",
    "          \n",
    "        tokens = [\"[CLS]\"]+tokens1+[\"[SEP]\"]+tokens2+[\"[SEP]\"]\n",
    "        tokens_ids = self.tokenizer.convert_tokens_to_ids(tokens)\n",
    "        tokens_ids_tensor = torch.tensor(tokens_ids)\n",
    "        attn_mask = (tokens_ids_tensor != 1).long() # [PAD] => 1\n",
    "\n",
    "        mf_tensor = torch.tensor(self.df.loc[index, :][bigcut])\n",
    "\n",
    "        return mf_tensor, tokens_ids_tensor, attn_mask, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_set = DatasetTaskC1(df = new_A_train, maxlen = 60)\n",
    "val_set = DatasetTaskC1(df = new_A_val, maxlen = 60)\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size = 32, num_workers = 2, shuffle=False)\n",
    "val_loader = DataLoader(val_set, batch_size = 32, num_workers = 2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class C1Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(C1Classifier, self).__init__()\n",
    "        torch.manual_seed(2022)\n",
    "        \n",
    "        self.bert_layer = BertModel.from_pretrained(model_name).cuda()\n",
    "        self.cls_layer = nn.Linear(66+768, 2).cuda()\n",
    "\n",
    "    def forward(self, mfs, seq, attn_masks):\n",
    "\n",
    "        cont_reps = self.bert_layer(seq, attention_mask=attn_masks)\n",
    "        \n",
    "        cls_rep = cont_reps.last_hidden_state[:, 0]\n",
    "        mfs = mfs.to(cls_rep.dtype)\n",
    "        cls_rep = torch.cat((mfs,cls_rep), 1)\n",
    "\n",
    "        logits = self.cls_layer(cls_rep)\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dccuchile/bert-base-spanish-wwm-cased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "net = C1Classifier()\n",
    "\n",
    "weights = torch.tensor([1., 6.5])\n",
    "criterion = nn.CrossEntropyLoss(weight=weights, reduction='mean').cuda()\n",
    "\n",
    "opti = optim.Adam(net.parameters(), lr = 2e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy_from_logits(logits, labels):\n",
    "    probs = torch.sigmoid(logits)\n",
    "    soft_probs = probs.argmax(1)\n",
    "    acc = (soft_probs.squeeze() == labels).float().mean()\n",
    "    return acc\n",
    "    \n",
    "def evaluate(net, criterion, dataloader):\n",
    "    net.eval()\n",
    "    mean_acc, mean_loss = 0, 0\n",
    "    count = 0\n",
    "    with torch.no_grad():\n",
    "        for mfs, seq, attn_masks, labels in dataloader:\n",
    "            mfs, seq, attn_masks, labels = mfs.cuda(), seq.cuda(), attn_masks.cuda(), labels.cuda()\n",
    "            logits = net(mfs, seq, attn_masks)\n",
    "            mean_loss += criterion(logits, labels).item()\n",
    "            mean_acc += get_accuracy_from_logits(logits, labels)\n",
    "            count += 1\n",
    "\n",
    "    return mean_acc / count, mean_loss / count\n",
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def evaluate_precision_recall_fscore_support(net, dataloader):\n",
    "    net.eval()\n",
    "    preds = []\n",
    "    tests = []\n",
    "    with torch.no_grad():\n",
    "        for mfs, seq, attn_masks, labels in dataloader:\n",
    "            mfs, seq, attn_masks, labels = mfs.cuda(), seq.cuda(), attn_masks.cuda(), labels.cuda()\n",
    "            logits = net(mfs, seq, attn_masks)\n",
    "            probs = torch.sigmoid(logits)\n",
    "            soft_probs = probs.argmax(1)\n",
    "            preds += soft_probs.squeeze().tolist()\n",
    "            tests += labels.tolist()\n",
    "    return tests, preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, criterion, opti, train_loader, val_loader, epochs):\n",
    "    for ep in range(epochs):\n",
    "        for it, (mfs, seq, attn_masks, labels) in enumerate(train_loader):\n",
    "            opti.zero_grad()  \n",
    "\n",
    "            mfs, seq, attn_masks, labels = mfs.cuda(), seq.cuda(), attn_masks.cuda(), labels.cuda()\n",
    "\n",
    "            logits = net(mfs, seq, attn_masks)\n",
    "\n",
    "            loss = criterion(logits, labels)\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            opti.step()\n",
    "\n",
    "            if (it + 1) % 100 == 0:\n",
    "                acc = get_accuracy_from_logits(logits, labels)\n",
    "                # tests, preds = evaluate_precision_recall_fscore_support(net, train_loader)\n",
    "                # print(classification_report(tests, preds))\n",
    "                print(\"Iteration {} of epoch {} complete. Loss : {} Train Accuracy : {}\".format(it+1, ep+1, loss.item(), acc))\n",
    "        val_acc, val_loss = evaluate(net, criterion, val_loader)\n",
    "        tests, preds = evaluate_precision_recall_fscore_support(net, val_loader)\n",
    "        print(classification_report(tests, preds))\n",
    "        print(\"Epoch {} complete! Validation Accuracy : {}, Validation Loss : {}\".format(ep+1, val_acc, val_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 100 of epoch 1 complete. Loss : 0.3337494432926178 Train Accuracy : 0.9375\n",
      "Iteration 200 of epoch 1 complete. Loss : 0.24811017513275146 Train Accuracy : 0.90625\n",
      "Iteration 300 of epoch 1 complete. Loss : 0.5886850953102112 Train Accuracy : 0.9375\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97      2510\n",
      "           1       0.81      0.80      0.80       388\n",
      "\n",
      "    accuracy                           0.95      2898\n",
      "   macro avg       0.89      0.88      0.89      2898\n",
      "weighted avg       0.95      0.95      0.95      2898\n",
      "\n",
      "Epoch 1 complete! Validation Accuracy : 0.9478785395622253, Validation Loss : 0.2640212265426641\n",
      "Iteration 100 of epoch 2 complete. Loss : 0.031450241804122925 Train Accuracy : 0.96875\n",
      "Iteration 200 of epoch 2 complete. Loss : 0.03476683795452118 Train Accuracy : 1.0\n",
      "Iteration 300 of epoch 2 complete. Loss : 0.04133869707584381 Train Accuracy : 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97      2510\n",
      "           1       0.77      0.85      0.81       388\n",
      "\n",
      "    accuracy                           0.95      2898\n",
      "   macro avg       0.87      0.91      0.89      2898\n",
      "weighted avg       0.95      0.95      0.95      2898\n",
      "\n",
      "Epoch 2 complete! Validation Accuracy : 0.9454746842384338, Validation Loss : 0.26437806952130666\n",
      "Iteration 100 of epoch 3 complete. Loss : 0.01823677122592926 Train Accuracy : 1.0\n",
      "Iteration 200 of epoch 3 complete. Loss : 0.003115327563136816 Train Accuracy : 1.0\n",
      "Iteration 300 of epoch 3 complete. Loss : 0.024068884551525116 Train Accuracy : 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.91      0.95      2510\n",
      "           1       0.62      0.91      0.74       388\n",
      "\n",
      "    accuracy                           0.91      2898\n",
      "   macro avg       0.80      0.91      0.84      2898\n",
      "weighted avg       0.94      0.91      0.92      2898\n",
      "\n",
      "Epoch 3 complete! Validation Accuracy : 0.913537859916687, Validation Loss : 0.2787380856820024\n",
      "Iteration 100 of epoch 4 complete. Loss : 0.018182329833507538 Train Accuracy : 0.96875\n",
      "Iteration 200 of epoch 4 complete. Loss : 0.009142599068582058 Train Accuracy : 1.0\n",
      "Iteration 300 of epoch 4 complete. Loss : 0.01957070454955101 Train Accuracy : 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97      2510\n",
      "           1       0.80      0.85      0.82       388\n",
      "\n",
      "    accuracy                           0.95      2898\n",
      "   macro avg       0.89      0.91      0.90      2898\n",
      "weighted avg       0.95      0.95      0.95      2898\n",
      "\n",
      "Epoch 4 complete! Validation Accuracy : 0.9513126015663147, Validation Loss : 0.3503152599185961\n",
      "Iteration 100 of epoch 5 complete. Loss : 0.02220964804291725 Train Accuracy : 1.0\n",
      "Iteration 200 of epoch 5 complete. Loss : 0.018777040764689445 Train Accuracy : 1.0\n",
      "Iteration 300 of epoch 5 complete. Loss : 0.00829297211021185 Train Accuracy : 1.0\n"
     ]
    }
   ],
   "source": [
    "epochs = 7\n",
    "train(net, criterion, opti, train_loader, val_loader, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'notebook_login' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m notebook_login()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'notebook_login' is not defined"
     ]
    }
   ],
   "source": [
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git config --global credential.helper store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'net' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m repo_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbeto_nllf_ft_task_C1\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m net\u001b[39m.\u001b[39mbert_layer\u001b[39m.\u001b[39mpush_to_hub(repo_name)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'net' is not defined"
     ]
    }
   ],
   "source": [
    "repo_name = \"beto_nllf_ft_task_C1\"\n",
    "net.bert_layer.push_to_hub(repo_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'val_set' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m val_set\u001b[39m.\u001b[39mtokenizer\u001b[39m.\u001b[39mpush_to_hub(repo_name)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'val_set' is not defined"
     ]
    }
   ],
   "source": [
    "val_set.tokenizer.push_to_hub(repo_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.cls_layer, \"cls_layer.torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import hf_hub_url, cached_download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hf_hub_url' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m repo_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbeto_nllf_ft_task_C1\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m config_file_url \u001b[39m=\u001b[39m hf_hub_url(\u001b[39m\"\u001b[39m\u001b[39mX/\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m+\u001b[39mrepo_name, filename\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcls_layer.torch\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m value \u001b[39m=\u001b[39m cached_download(config_file_url)\n\u001b[1;32m      4\u001b[0m cls_layer \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mload(value)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'hf_hub_url' is not defined"
     ]
    }
   ],
   "source": [
    "repo_name = \"beto_nllf_ft_task_C1\"\n",
    "config_file_url = hf_hub_url(\"X/\"+repo_name, filename=\"cls_layer.torch\")\n",
    "value = cached_download(config_file_url)\n",
    "cls_layer = torch.load(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04688c34747f41fc9140c0224f5b8a66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/701 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a520e70eb82143daaf50e145762c7913",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/439M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6e357b554eb44dd93ae528d91d1f5c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/242k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a3a3fa767014e1d99949d84286e71ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c90f9279a2b04ad59dc6fa65fe211268",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/368 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "beto_model = BertModel.from_pretrained(\"X/\"+repo_name).cuda()\n",
    "beto_tokenizer = BertTokenizer.from_pretrained(\"X/\"+repo_name, do_lower_case=False)\n",
    "e = beto_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproccesing(Q, A, maxlen=60):\n",
    "        sentence1 = str(Q)\n",
    "        sentence2 = str(A)\n",
    "        \n",
    "        sentence1 = \" \".join(str(sentence1).replace(\"\\n\", \" \").split())\n",
    "        sentence2 = \" \".join(str(sentence2).replace(\"\\n\", \" \").split())\n",
    "        \n",
    "        tokens1 = beto_tokenizer.tokenize(sentence1) if len(sentence1)>0 else [\"[UNK]\"]\n",
    "        tokens2 = beto_tokenizer.tokenize(sentence2) if len(sentence2)>0 else [\"[UNK]\"]\n",
    "\n",
    "        if len(tokens1) < maxlen:\n",
    "            tokens1 = tokens1 + ['[PAD]' for _ in range(maxlen - len(tokens1))]\n",
    "        else:\n",
    "            tokens1 = tokens1[:maxlen]\n",
    "\n",
    "        if len(tokens2) < maxlen:\n",
    "            tokens2 = tokens2 + ['[PAD]' for _ in range(maxlen - len(tokens2))]\n",
    "        else:\n",
    "            tokens2 = tokens2[:maxlen]\n",
    "          \n",
    "        tokens = [\"[CLS]\"]+tokens1+[\"[SEP]\"]+tokens2+[\"[SEP]\"]\n",
    "        # tokens = [x for x in tokens if x!=\"[PAD]\"]\n",
    "        tokens_ids = beto_tokenizer.convert_tokens_to_ids(tokens)\n",
    "        tokens_ids_tensor = torch.tensor(tokens_ids)\n",
    "        attn_mask = (tokens_ids_tensor != 1).long() # [PAD] => 1\n",
    "\n",
    "        return tokens_ids_tensor.cuda(), attn_mask.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def C1Classifier(mfs, Q, A):\n",
    "    tokens_ids_tensor, attn_mask = preproccesing(Q, A)\n",
    "    cont_reps = beto_model(tokens_ids_tensor.unsqueeze(0), attention_mask = attn_mask.unsqueeze(0))\n",
    "    cls_rep = cont_reps.last_hidden_state[:, 0]\n",
    "    mfs = torch.tensor(mfs).cuda()\n",
    "    mfs = mfs.to(cls_rep.dtype).unsqueeze(0)\n",
    "    cls_rep = torch.cat((mfs,cls_rep), 1)\n",
    "    logits = cls_layer(cls_rep)\n",
    "    probs = torch.sigmoid(logits)\n",
    "    return probs.detach().cpu().numpy()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Luis compró 10 caramelos, de los cuales 4 tenían menta, los demás no. ¿Cuántos caramelos no tenían menta? Representa esta ecuación.',) tiene 30 en total\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.92760646, 0.10513163], dtype=float32)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 0\n",
    "mfs = new_A_train.iloc[i][bigcut]\n",
    "Q = A_train.iloc[i][\"Q\"], \n",
    "A = A_train.iloc[i][\"A\"]\n",
    "print(Q, A)\n",
    "C1Classifier(mfs, Q, A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 55s, sys: 38.5 ms, total: 1min 55s\n",
      "Wall time: 1min 55s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.882521</td>\n",
       "      <td>0.982265</td>\n",
       "      <td>0.941261</td>\n",
       "      <td>0.984348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.979539</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.982265</td>\n",
       "      <td>0.989769</td>\n",
       "      <td>0.982265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.989664</td>\n",
       "      <td>0.937595</td>\n",
       "      <td>0.982265</td>\n",
       "      <td>0.963629</td>\n",
       "      <td>0.982727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>10019.000000</td>\n",
       "      <td>1540.000000</td>\n",
       "      <td>0.982265</td>\n",
       "      <td>11559.000000</td>\n",
       "      <td>11559.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      0            1  accuracy     macro avg  weighted avg\n",
       "precision      1.000000     0.882521  0.982265      0.941261      0.984348\n",
       "recall         0.979539     1.000000  0.982265      0.989769      0.982265\n",
       "f1-score       0.989664     0.937595  0.982265      0.963629      0.982727\n",
       "support    10019.000000  1540.000000  0.982265  11559.000000  11559.000000"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = [ int(\n",
    "    C1Classifier(\n",
    "        mfs=new_A_train.iloc[i][bigcut], \n",
    "        Q=A_train.iloc[i][\"Q\"], \n",
    "        A=A_train.iloc[i][\"A\"]\n",
    "        )[0]<0.5) \n",
    "    for i in range(A_train.shape[0])\n",
    "]\n",
    "report = classification_report(A_train[\"label\"], y_pred, output_dict=True)\n",
    "train_report = pd.DataFrame(report)\n",
    "train_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(y_pred, open(\"data/y_pred_train_beto_nllf_ft_task_C1.pickle\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 28.7 s, sys: 4.36 ms, total: 28.7 s\n",
      "Wall time: 28.7 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.981743</td>\n",
       "      <td>0.704918</td>\n",
       "      <td>0.935128</td>\n",
       "      <td>0.843330</td>\n",
       "      <td>0.944680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.942629</td>\n",
       "      <td>0.886598</td>\n",
       "      <td>0.935128</td>\n",
       "      <td>0.914614</td>\n",
       "      <td>0.935128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.961789</td>\n",
       "      <td>0.785388</td>\n",
       "      <td>0.935128</td>\n",
       "      <td>0.873588</td>\n",
       "      <td>0.938171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>2510.000000</td>\n",
       "      <td>388.000000</td>\n",
       "      <td>0.935128</td>\n",
       "      <td>2898.000000</td>\n",
       "      <td>2898.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     0           1  accuracy    macro avg  weighted avg\n",
       "precision     0.981743    0.704918  0.935128     0.843330      0.944680\n",
       "recall        0.942629    0.886598  0.935128     0.914614      0.935128\n",
       "f1-score      0.961789    0.785388  0.935128     0.873588      0.938171\n",
       "support    2510.000000  388.000000  0.935128  2898.000000   2898.000000"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = [ int(\n",
    "    C1Classifier(\n",
    "        new_A_val.iloc[i][bigcut], \n",
    "        A_val.iloc[i][\"Q\"], \n",
    "        A_val.iloc[i][\"A\"]\n",
    "        )[0]<0.5) \n",
    "    for i in range(A_val.shape[0])]\n",
    "report = classification_report(A_val[\"label\"], y_pred, output_dict=True)\n",
    "val_report = pd.DataFrame(report)\n",
    "val_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(y_pred, open(\"data/y_pred_val_beto_nllf_ft_task_C1.pickle\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.57 s, sys: 3.96 ms, total: 6.58 s\n",
      "Wall time: 6.58 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.966292</td>\n",
       "      <td>0.521552</td>\n",
       "      <td>0.813885</td>\n",
       "      <td>0.743922</td>\n",
       "      <td>0.876950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.794824</td>\n",
       "      <td>0.889706</td>\n",
       "      <td>0.813885</td>\n",
       "      <td>0.842265</td>\n",
       "      <td>0.813885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.872211</td>\n",
       "      <td>0.657609</td>\n",
       "      <td>0.813885</td>\n",
       "      <td>0.764910</td>\n",
       "      <td>0.829100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>541.000000</td>\n",
       "      <td>136.000000</td>\n",
       "      <td>0.813885</td>\n",
       "      <td>677.000000</td>\n",
       "      <td>677.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0           1  accuracy   macro avg  weighted avg\n",
       "precision    0.966292    0.521552  0.813885    0.743922      0.876950\n",
       "recall       0.794824    0.889706  0.813885    0.842265      0.813885\n",
       "f1-score     0.872211    0.657609  0.813885    0.764910      0.829100\n",
       "support    541.000000  136.000000  0.813885  677.000000    677.000000"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = [ int(\n",
    "    C1Classifier(\n",
    "        new_A_test.iloc[i][bigcut], \n",
    "        A_test.iloc[i][\"Q\"], \n",
    "        A_test.iloc[i][\"A\"]\n",
    "        )[0]<0.5) \n",
    "    for i in range(A_test.shape[0])]\n",
    "report = classification_report(A_test[\"label\"], y_pred, output_dict=True)\n",
    "test_report = pd.DataFrame(report)\n",
    "test_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(y_pred, open(\"data/y_pred_test_beto_nllf_ft_task_C1.pickle\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9811    0.9924    0.9867       262\n",
      "           1     0.9474    0.8780    0.9114        41\n",
      "\n",
      "    accuracy                         0.9769       303\n",
      "   macro avg     0.9643    0.9352    0.9491       303\n",
      "weighted avg     0.9766    0.9769    0.9765       303\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import pickle\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "file_names = {\n",
    "    \"train\": \"data/train_task_C1.xlsx\",\n",
    "    \"test\": \"data/test_task_C1.xlsx\",\n",
    "    \"val\": \"data/val_task_C1.xlsx\",\n",
    "    \"mf_train\": \"data/mf_features_train_task_C1.xlsx\",\n",
    "    \"mf_test\": \"data/mf_features_test_task_C1.xlsx\",\n",
    "    \"mf_val\": \"data/mf_features_val_task_C1.xlsx\",\n",
    "}\n",
    "A_test = pd.read_excel(file_names[\"test\"])\n",
    "test_label_Q = pd.read_excel(\"data/gpt_label_v7_comp.xlsx\")\n",
    "A_test[\"label_Q\"] = A_test.apply(lambda x: test_label_Q[test_label_Q[\"id\"] == x[\"id\"]].iloc[0][\"tipo_preg\"], axis=1)\n",
    "y_pred = pickle.load(open(\"data/y_pred_test_beto_nllf_ft_task_C1.pickle\", \"rb\"))\n",
    "sub_index_test = A_test[\"label_Q\"] == 3\n",
    "print(classification_report(A_test.loc[A_test[sub_index_test].index][\"label\"], np.array(y_pred)[sub_index_test.values], digits=4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "net",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7108851178047dc680433843b93ee0e3779b5b27b2c4cebb614195d20b26b968"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
