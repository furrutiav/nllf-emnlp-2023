{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names = {\n",
    "    \"train\": \"data/nlfl_train_sample_v3.xlsx\",\n",
    "    \"test\": \"data/nlfl_test_sample_v3.xlsx\",\n",
    "    \"val\": \"data/nlfl_val_sample_v3.xlsx\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_train = pd.read_excel(file_names[\"train\"], index_col=\"id\").sample(frac = 1, random_state=2022).reset_index()\n",
    "A_val = pd.read_excel(file_names[\"val\"])\n",
    "A_test = pd.read_excel(file_names[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: >"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "A_train[\"label\"].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['chatgpt_v1 (N)',\n",
       " 'chatgpt_v1 (Y)',\n",
       " 'chatgpt_v2 (N)',\n",
       " 'chatgpt_v2 (Y)',\n",
       " 'chatgpt_v3 (N)',\n",
       " 'chatgpt_v3 (Y)',\n",
       " 'chatgpt_v4 (N)',\n",
       " 'chatgpt_v4 (Y)',\n",
       " 'chatgpt_v5 (N)',\n",
       " 'chatgpt_v5 (Y)',\n",
       " 'chatgpt_v6 (N)',\n",
       " 'chatgpt_v6 (Y)',\n",
       " 'chatgpt_v7 (N)',\n",
       " 'chatgpt_v7 (Y)',\n",
       " 'chatgpt_v8 (N)',\n",
       " 'chatgpt_v8 (Y)',\n",
       " 'chatgpt_v9 (N)',\n",
       " 'chatgpt_v9 (Y)',\n",
       " 'chatgpt_v10 (N)',\n",
       " 'chatgpt_v10 (Y)',\n",
       " 'chatgpt_v5_1 (N)',\n",
       " 'chatgpt_v5_1 (Y)',\n",
       " 'chatgpt_v5_2 (N)',\n",
       " 'chatgpt_v5_2 (Y)',\n",
       " 'chatgpt_v5_3 (N)',\n",
       " 'chatgpt_v5_3 (Y)',\n",
       " 'chatgpt_v5_4 (N)',\n",
       " 'chatgpt_v5_4 (Y)',\n",
       " 'chatgpt_v5_5 (N)',\n",
       " 'chatgpt_v5_5 (Y)',\n",
       " 'chatgpt_v6_1 (N)',\n",
       " 'chatgpt_v6_1 (Y)',\n",
       " 'chatgpt_v6_2 (N)',\n",
       " 'chatgpt_v6_2 (Y)',\n",
       " 'chatgpt_v6_3 (N)',\n",
       " 'chatgpt_v6_3 (Y)',\n",
       " 'chatgpt_v6_4 (N)',\n",
       " 'chatgpt_v6_4 (Y)',\n",
       " 'chatgpt_Q3_1 (N)',\n",
       " 'chatgpt_Q3_1 (Y)',\n",
       " 'chatgpt_Q3_2 (N)',\n",
       " 'chatgpt_Q3_2 (Y)',\n",
       " 'chatgpt_Q3_3 (N)',\n",
       " 'chatgpt_Q3_3 (Y)',\n",
       " 'chatgpt_Q3_4 (N)',\n",
       " 'chatgpt_Q3_4 (Y)',\n",
       " 'chatgpt_Q3_5 (N)',\n",
       " 'chatgpt_Q3_5 (Y)',\n",
       " 'chatgpt_Q3_6 (N)',\n",
       " 'chatgpt_Q3_6 (Y)',\n",
       " 'chatgpt_Q3_7 (N)',\n",
       " 'chatgpt_Q3_7 (Y)',\n",
       " 'chatgpt_Q3_8 (N)',\n",
       " 'chatgpt_Q3_8 (Y)',\n",
       " 'chatgpt_Q3_9 (N)',\n",
       " 'chatgpt_Q3_9 (Y)',\n",
       " 'chatgpt_Q3_10 (N)',\n",
       " 'chatgpt_Q3_10 (Y)',\n",
       " 'chatgpt_Q3_11 (N)',\n",
       " 'chatgpt_Q3_11 (Y)',\n",
       " 'chatgpt_Q3_12 (N)',\n",
       " 'chatgpt_Q3_12 (Y)',\n",
       " 'chatgpt_Q3_13 (N)',\n",
       " 'chatgpt_Q3_13 (Y)',\n",
       " 'chatgpt_Q3_14 (N)',\n",
       " 'chatgpt_Q3_14 (Y)',\n",
       " 'chatgpt_Q3_15 (N)',\n",
       " 'chatgpt_Q3_15 (Y)',\n",
       " 'chatgpt_Q3_16 (N)',\n",
       " 'chatgpt_Q3_16 (Y)',\n",
       " 'chatgpt_Q3_7_e1 (N)',\n",
       " 'chatgpt_Q3_7_e1 (Y)',\n",
       " 'chatgpt_Q3_7_e2 (N)',\n",
       " 'chatgpt_Q3_7_e2 (Y)',\n",
       " 'chatgpt_Q3_7_e3 (N)',\n",
       " 'chatgpt_Q3_7_e3 (Y)',\n",
       " 'chatgpt_Q3_7_e4 (N)',\n",
       " 'chatgpt_Q3_7_e4 (Y)',\n",
       " 'chatgpt_Q3_7_e5 (N)',\n",
       " 'chatgpt_Q3_7_e5 (Y)',\n",
       " 'chatgpt_10_e1 (N)',\n",
       " 'chatgpt_10_e1 (Y)',\n",
       " 'chatgpt_10_e2 (N)',\n",
       " 'chatgpt_10_e2 (Y)',\n",
       " 'chatgpt_10_e3 (N)',\n",
       " 'chatgpt_10_e3 (Y)',\n",
       " 'chatgpt_10_e4 (N)',\n",
       " 'chatgpt_10_e4 (Y)',\n",
       " 'chatgpt_10_e5 (N)',\n",
       " 'chatgpt_10_e5 (Y)',\n",
       " 'chatgpt_7_e1 (N)',\n",
       " 'chatgpt_7_e1 (Y)',\n",
       " 'chatgpt_7_e2 (N)',\n",
       " 'chatgpt_7_e2 (Y)',\n",
       " 'chatgpt_7_e3 (N)',\n",
       " 'chatgpt_7_e3 (Y)',\n",
       " 'chatgpt_7_e4 (N)',\n",
       " 'chatgpt_7_e4 (Y)',\n",
       " 'chatgpt_7_e5 (N)',\n",
       " 'chatgpt_7_e5 (Y)',\n",
       " 'chatgpt_Q3_4_e1 (N)',\n",
       " 'chatgpt_Q3_4_e1 (Y)',\n",
       " 'chatgpt_Q3_4_e2 (N)',\n",
       " 'chatgpt_Q3_4_e2 (Y)',\n",
       " 'chatgpt_Q3_4_e3 (N)',\n",
       " 'chatgpt_Q3_4_e3 (Y)',\n",
       " 'chatgpt_Q3_4_e4 (N)',\n",
       " 'chatgpt_Q3_4_e4 (Y)',\n",
       " 'chatgpt_Q3_4_e5 (N)',\n",
       " 'chatgpt_Q3_4_e5 (Y)',\n",
       " 'chatgpt_Q3_5_e1 (N)',\n",
       " 'chatgpt_Q3_5_e1 (Y)',\n",
       " 'chatgpt_Q3_5_e2 (N)',\n",
       " 'chatgpt_Q3_5_e2 (Y)',\n",
       " 'chatgpt_Q3_5_e3 (N)',\n",
       " 'chatgpt_Q3_5_e3 (Y)',\n",
       " 'chatgpt_Q3_5_e4 (N)',\n",
       " 'chatgpt_Q3_5_e4 (Y)',\n",
       " 'chatgpt_Q3_5_e5 (N)',\n",
       " 'chatgpt_Q3_5_e5 (Y)',\n",
       " 'chatgpt_HF_1 (N)',\n",
       " 'chatgpt_HF_1 (Y)',\n",
       " 'chatgpt_HF_2 (N)',\n",
       " 'chatgpt_HF_2 (Y)',\n",
       " 'chatgpt_HF_3 (N)',\n",
       " 'chatgpt_HF_3 (Y)',\n",
       " 'chatgpt_HF_4 (N)',\n",
       " 'chatgpt_HF_4 (Y)',\n",
       " 'chatgpt_HF_5 (N)',\n",
       " 'chatgpt_HF_5 (Y)',\n",
       " 'chatgpt_HF_6 (N)',\n",
       " 'chatgpt_HF_6 (Y)',\n",
       " 'chatgpt_SP_1 (N)',\n",
       " 'chatgpt_SP_1 (Y)',\n",
       " 'chatgpt_SP_2 (N)',\n",
       " 'chatgpt_SP_2 (Y)',\n",
       " 'chatgpt_SP_3 (N)',\n",
       " 'chatgpt_SP_3 (Y)',\n",
       " 'chatgpt_SP_4 (N)',\n",
       " 'chatgpt_SP_4 (Y)',\n",
       " 'chatgpt_SP_5 (N)',\n",
       " 'chatgpt_SP_5 (Y)',\n",
       " 'chatgpt_SP_6 (N)',\n",
       " 'chatgpt_SP_6 (Y)']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rel_cols = [c for c in A_train.columns if \"chatgpt_label\" != c and \"chatgpt_\" in c]\n",
    "rel_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 3.65 ms, total: 3.65 ms\n",
      "Wall time: 3.4 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "new_A_test = A_test.copy()\n",
    "new_A_train = A_train.copy()\n",
    "new_A_val = A_val.copy()\n",
    "\n",
    "bigcut = ['chatgpt_v1 (Y)', 'chatgpt_v2 (Y)', 'chatgpt_v3 (N)',\n",
    "       'chatgpt_v5 (N)', 'chatgpt_v6 (N)', 'chatgpt_v6 (Y)',\n",
    "       'chatgpt_v7 (N)', 'chatgpt_v8 (Y)', 'chatgpt_v10 (Y)',\n",
    "       'chatgpt_v5_2 (Y)', 'chatgpt_v5_3 (N)', 'chatgpt_v5_3 (Y)',\n",
    "       'chatgpt_v5_4 (N)', 'chatgpt_v5_5 (Y)', 'chatgpt_v6_1 (N)',\n",
    "       'chatgpt_v6_1 (Y)', 'chatgpt_Q3_1 (N)', 'chatgpt_Q3_1 (Y)',\n",
    "       'chatgpt_Q3_2 (N)', 'chatgpt_Q3_2 (Y)', 'chatgpt_Q3_3 (Y)',\n",
    "       'chatgpt_Q3_5 (N)', 'chatgpt_Q3_6 (N)', 'chatgpt_Q3_6 (Y)',\n",
    "       'chatgpt_Q3_8 (N)', 'chatgpt_Q3_8 (Y)', 'chatgpt_Q3_9 (N)',\n",
    "       'chatgpt_Q3_10 (N)', 'chatgpt_Q3_10 (Y)', 'chatgpt_Q3_12 (N)',\n",
    "       'chatgpt_Q3_14 (N)', 'chatgpt_Q3_14 (Y)', 'chatgpt_Q3_15 (N)',\n",
    "       'chatgpt_Q3_15 (Y)', 'chatgpt_Q3_16 (N)', 'chatgpt_Q3_7_e1 (N)',\n",
    "       'chatgpt_Q3_7_e1 (Y)', 'chatgpt_Q3_7_e2 (Y)',\n",
    "       'chatgpt_Q3_7_e3 (N)', 'chatgpt_Q3_7_e4 (Y)',\n",
    "       'chatgpt_Q3_7_e5 (Y)', 'chatgpt_10_e1 (N)', 'chatgpt_10_e5 (Y)',\n",
    "       'chatgpt_7_e1 (N)', 'chatgpt_7_e1 (Y)', 'chatgpt_7_e2 (N)',\n",
    "       'chatgpt_7_e3 (N)', 'chatgpt_7_e4 (N)', 'chatgpt_Q3_4_e1 (N)',\n",
    "       'chatgpt_Q3_4_e1 (Y)', 'chatgpt_Q3_4_e2 (Y)',\n",
    "       'chatgpt_Q3_4_e3 (Y)', 'chatgpt_Q3_4_e4 (Y)',\n",
    "       'chatgpt_Q3_5_e2 (N)', 'chatgpt_Q3_5_e4 (Y)', 'chatgpt_HF_2 (Y)',\n",
    "       'chatgpt_HF_3 (Y)', 'chatgpt_HF_4 (N)', 'chatgpt_SP_1 (N)',\n",
    "       'chatgpt_SP_2 (Y)', 'chatgpt_SP_4 (Y)', 'chatgpt_SP_5 (N)',\n",
    "       'chatgpt_SP_6 (N)', 'chatgpt_SP_6 (Y)']\n",
    "len(bigcut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chatgpt_v1 (Y)</th>\n",
       "      <th>chatgpt_v2 (Y)</th>\n",
       "      <th>chatgpt_v3 (N)</th>\n",
       "      <th>chatgpt_v5 (N)</th>\n",
       "      <th>chatgpt_v6 (N)</th>\n",
       "      <th>chatgpt_v6 (Y)</th>\n",
       "      <th>chatgpt_v7 (N)</th>\n",
       "      <th>chatgpt_v8 (Y)</th>\n",
       "      <th>chatgpt_v10 (Y)</th>\n",
       "      <th>chatgpt_v5_2 (Y)</th>\n",
       "      <th>...</th>\n",
       "      <th>chatgpt_Q3_5_e4 (Y)</th>\n",
       "      <th>chatgpt_HF_2 (Y)</th>\n",
       "      <th>chatgpt_HF_3 (Y)</th>\n",
       "      <th>chatgpt_HF_4 (N)</th>\n",
       "      <th>chatgpt_SP_1 (N)</th>\n",
       "      <th>chatgpt_SP_2 (Y)</th>\n",
       "      <th>chatgpt_SP_4 (Y)</th>\n",
       "      <th>chatgpt_SP_5 (N)</th>\n",
       "      <th>chatgpt_SP_6 (N)</th>\n",
       "      <th>chatgpt_SP_6 (Y)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.188718</td>\n",
       "      <td>0.132679</td>\n",
       "      <td>0.871060</td>\n",
       "      <td>0.907873</td>\n",
       "      <td>0.874617</td>\n",
       "      <td>0.147539</td>\n",
       "      <td>0.050355</td>\n",
       "      <td>0.258807</td>\n",
       "      <td>0.867311</td>\n",
       "      <td>0.425349</td>\n",
       "      <td>...</td>\n",
       "      <td>0.202222</td>\n",
       "      <td>0.407081</td>\n",
       "      <td>0.266678</td>\n",
       "      <td>0.565818</td>\n",
       "      <td>0.211885</td>\n",
       "      <td>0.225311</td>\n",
       "      <td>0.611836</td>\n",
       "      <td>0.689286</td>\n",
       "      <td>0.769335</td>\n",
       "      <td>0.205009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.649700</td>\n",
       "      <td>0.606070</td>\n",
       "      <td>0.433825</td>\n",
       "      <td>0.800133</td>\n",
       "      <td>0.721065</td>\n",
       "      <td>0.334636</td>\n",
       "      <td>0.061304</td>\n",
       "      <td>0.610766</td>\n",
       "      <td>0.817359</td>\n",
       "      <td>0.649023</td>\n",
       "      <td>...</td>\n",
       "      <td>0.657997</td>\n",
       "      <td>0.739698</td>\n",
       "      <td>0.624346</td>\n",
       "      <td>0.371578</td>\n",
       "      <td>0.223496</td>\n",
       "      <td>0.647350</td>\n",
       "      <td>0.677812</td>\n",
       "      <td>0.411591</td>\n",
       "      <td>0.415988</td>\n",
       "      <td>0.664460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.695815</td>\n",
       "      <td>0.622938</td>\n",
       "      <td>0.394148</td>\n",
       "      <td>0.753878</td>\n",
       "      <td>0.537597</td>\n",
       "      <td>0.458100</td>\n",
       "      <td>0.041318</td>\n",
       "      <td>0.598321</td>\n",
       "      <td>0.856645</td>\n",
       "      <td>0.682702</td>\n",
       "      <td>...</td>\n",
       "      <td>0.665142</td>\n",
       "      <td>0.611335</td>\n",
       "      <td>0.604869</td>\n",
       "      <td>0.326528</td>\n",
       "      <td>0.121597</td>\n",
       "      <td>0.699322</td>\n",
       "      <td>0.748506</td>\n",
       "      <td>0.342123</td>\n",
       "      <td>0.395269</td>\n",
       "      <td>0.692664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.234357</td>\n",
       "      <td>0.171390</td>\n",
       "      <td>0.733718</td>\n",
       "      <td>0.937383</td>\n",
       "      <td>0.923375</td>\n",
       "      <td>0.059339</td>\n",
       "      <td>0.048473</td>\n",
       "      <td>0.220668</td>\n",
       "      <td>0.588132</td>\n",
       "      <td>0.210189</td>\n",
       "      <td>...</td>\n",
       "      <td>0.224726</td>\n",
       "      <td>0.262470</td>\n",
       "      <td>0.248231</td>\n",
       "      <td>0.656185</td>\n",
       "      <td>0.403232</td>\n",
       "      <td>0.227442</td>\n",
       "      <td>0.255073</td>\n",
       "      <td>0.726112</td>\n",
       "      <td>0.711837</td>\n",
       "      <td>0.245129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.078039</td>\n",
       "      <td>0.061976</td>\n",
       "      <td>0.926050</td>\n",
       "      <td>0.970505</td>\n",
       "      <td>0.969734</td>\n",
       "      <td>0.028052</td>\n",
       "      <td>0.732937</td>\n",
       "      <td>0.078929</td>\n",
       "      <td>0.143635</td>\n",
       "      <td>0.065245</td>\n",
       "      <td>...</td>\n",
       "      <td>0.074230</td>\n",
       "      <td>0.068854</td>\n",
       "      <td>0.072694</td>\n",
       "      <td>0.931767</td>\n",
       "      <td>0.921096</td>\n",
       "      <td>0.080596</td>\n",
       "      <td>0.064752</td>\n",
       "      <td>0.920716</td>\n",
       "      <td>0.915882</td>\n",
       "      <td>0.084049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11554</th>\n",
       "      <td>0.035683</td>\n",
       "      <td>0.031398</td>\n",
       "      <td>0.929730</td>\n",
       "      <td>0.961836</td>\n",
       "      <td>0.968757</td>\n",
       "      <td>0.018661</td>\n",
       "      <td>0.059784</td>\n",
       "      <td>0.037715</td>\n",
       "      <td>0.164997</td>\n",
       "      <td>0.035877</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043750</td>\n",
       "      <td>0.049046</td>\n",
       "      <td>0.048388</td>\n",
       "      <td>0.904142</td>\n",
       "      <td>0.866427</td>\n",
       "      <td>0.042227</td>\n",
       "      <td>0.038966</td>\n",
       "      <td>0.912885</td>\n",
       "      <td>0.907543</td>\n",
       "      <td>0.043510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11555</th>\n",
       "      <td>0.269840</td>\n",
       "      <td>0.177807</td>\n",
       "      <td>0.841410</td>\n",
       "      <td>0.955108</td>\n",
       "      <td>0.899107</td>\n",
       "      <td>0.140256</td>\n",
       "      <td>0.050023</td>\n",
       "      <td>0.276454</td>\n",
       "      <td>0.817929</td>\n",
       "      <td>0.318834</td>\n",
       "      <td>...</td>\n",
       "      <td>0.269855</td>\n",
       "      <td>0.327267</td>\n",
       "      <td>0.276181</td>\n",
       "      <td>0.655347</td>\n",
       "      <td>0.259128</td>\n",
       "      <td>0.277478</td>\n",
       "      <td>0.444294</td>\n",
       "      <td>0.794465</td>\n",
       "      <td>0.794085</td>\n",
       "      <td>0.277307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11556</th>\n",
       "      <td>0.168320</td>\n",
       "      <td>0.121525</td>\n",
       "      <td>0.843283</td>\n",
       "      <td>0.960292</td>\n",
       "      <td>0.950777</td>\n",
       "      <td>0.047455</td>\n",
       "      <td>0.380095</td>\n",
       "      <td>0.154911</td>\n",
       "      <td>0.308636</td>\n",
       "      <td>0.139451</td>\n",
       "      <td>...</td>\n",
       "      <td>0.163535</td>\n",
       "      <td>0.157382</td>\n",
       "      <td>0.159395</td>\n",
       "      <td>0.866256</td>\n",
       "      <td>0.842161</td>\n",
       "      <td>0.168887</td>\n",
       "      <td>0.149274</td>\n",
       "      <td>0.839866</td>\n",
       "      <td>0.846077</td>\n",
       "      <td>0.168443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11557</th>\n",
       "      <td>0.091335</td>\n",
       "      <td>0.063889</td>\n",
       "      <td>0.734949</td>\n",
       "      <td>0.940178</td>\n",
       "      <td>0.924499</td>\n",
       "      <td>0.027063</td>\n",
       "      <td>0.084956</td>\n",
       "      <td>0.091127</td>\n",
       "      <td>0.326852</td>\n",
       "      <td>0.111856</td>\n",
       "      <td>...</td>\n",
       "      <td>0.110005</td>\n",
       "      <td>0.123866</td>\n",
       "      <td>0.115130</td>\n",
       "      <td>0.777414</td>\n",
       "      <td>0.603205</td>\n",
       "      <td>0.096358</td>\n",
       "      <td>0.128685</td>\n",
       "      <td>0.726397</td>\n",
       "      <td>0.725586</td>\n",
       "      <td>0.100972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11558</th>\n",
       "      <td>0.272725</td>\n",
       "      <td>0.238044</td>\n",
       "      <td>0.609554</td>\n",
       "      <td>0.904263</td>\n",
       "      <td>0.830434</td>\n",
       "      <td>0.077877</td>\n",
       "      <td>0.055527</td>\n",
       "      <td>0.292863</td>\n",
       "      <td>0.696926</td>\n",
       "      <td>0.283932</td>\n",
       "      <td>...</td>\n",
       "      <td>0.304071</td>\n",
       "      <td>0.305082</td>\n",
       "      <td>0.251553</td>\n",
       "      <td>0.625725</td>\n",
       "      <td>0.341300</td>\n",
       "      <td>0.293823</td>\n",
       "      <td>0.352750</td>\n",
       "      <td>0.591897</td>\n",
       "      <td>0.605963</td>\n",
       "      <td>0.272084</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11559 rows Ã— 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       chatgpt_v1 (Y)  chatgpt_v2 (Y)  chatgpt_v3 (N)  chatgpt_v5 (N)  \\\n",
       "0            0.188718        0.132679        0.871060        0.907873   \n",
       "1            0.649700        0.606070        0.433825        0.800133   \n",
       "2            0.695815        0.622938        0.394148        0.753878   \n",
       "3            0.234357        0.171390        0.733718        0.937383   \n",
       "4            0.078039        0.061976        0.926050        0.970505   \n",
       "...               ...             ...             ...             ...   \n",
       "11554        0.035683        0.031398        0.929730        0.961836   \n",
       "11555        0.269840        0.177807        0.841410        0.955108   \n",
       "11556        0.168320        0.121525        0.843283        0.960292   \n",
       "11557        0.091335        0.063889        0.734949        0.940178   \n",
       "11558        0.272725        0.238044        0.609554        0.904263   \n",
       "\n",
       "       chatgpt_v6 (N)  chatgpt_v6 (Y)  chatgpt_v7 (N)  chatgpt_v8 (Y)  \\\n",
       "0            0.874617        0.147539        0.050355        0.258807   \n",
       "1            0.721065        0.334636        0.061304        0.610766   \n",
       "2            0.537597        0.458100        0.041318        0.598321   \n",
       "3            0.923375        0.059339        0.048473        0.220668   \n",
       "4            0.969734        0.028052        0.732937        0.078929   \n",
       "...               ...             ...             ...             ...   \n",
       "11554        0.968757        0.018661        0.059784        0.037715   \n",
       "11555        0.899107        0.140256        0.050023        0.276454   \n",
       "11556        0.950777        0.047455        0.380095        0.154911   \n",
       "11557        0.924499        0.027063        0.084956        0.091127   \n",
       "11558        0.830434        0.077877        0.055527        0.292863   \n",
       "\n",
       "       chatgpt_v10 (Y)  chatgpt_v5_2 (Y)  ...  chatgpt_Q3_5_e4 (Y)  \\\n",
       "0             0.867311          0.425349  ...             0.202222   \n",
       "1             0.817359          0.649023  ...             0.657997   \n",
       "2             0.856645          0.682702  ...             0.665142   \n",
       "3             0.588132          0.210189  ...             0.224726   \n",
       "4             0.143635          0.065245  ...             0.074230   \n",
       "...                ...               ...  ...                  ...   \n",
       "11554         0.164997          0.035877  ...             0.043750   \n",
       "11555         0.817929          0.318834  ...             0.269855   \n",
       "11556         0.308636          0.139451  ...             0.163535   \n",
       "11557         0.326852          0.111856  ...             0.110005   \n",
       "11558         0.696926          0.283932  ...             0.304071   \n",
       "\n",
       "       chatgpt_HF_2 (Y)  chatgpt_HF_3 (Y)  chatgpt_HF_4 (N)  chatgpt_SP_1 (N)  \\\n",
       "0              0.407081          0.266678          0.565818          0.211885   \n",
       "1              0.739698          0.624346          0.371578          0.223496   \n",
       "2              0.611335          0.604869          0.326528          0.121597   \n",
       "3              0.262470          0.248231          0.656185          0.403232   \n",
       "4              0.068854          0.072694          0.931767          0.921096   \n",
       "...                 ...               ...               ...               ...   \n",
       "11554          0.049046          0.048388          0.904142          0.866427   \n",
       "11555          0.327267          0.276181          0.655347          0.259128   \n",
       "11556          0.157382          0.159395          0.866256          0.842161   \n",
       "11557          0.123866          0.115130          0.777414          0.603205   \n",
       "11558          0.305082          0.251553          0.625725          0.341300   \n",
       "\n",
       "       chatgpt_SP_2 (Y)  chatgpt_SP_4 (Y)  chatgpt_SP_5 (N)  chatgpt_SP_6 (N)  \\\n",
       "0              0.225311          0.611836          0.689286          0.769335   \n",
       "1              0.647350          0.677812          0.411591          0.415988   \n",
       "2              0.699322          0.748506          0.342123          0.395269   \n",
       "3              0.227442          0.255073          0.726112          0.711837   \n",
       "4              0.080596          0.064752          0.920716          0.915882   \n",
       "...                 ...               ...               ...               ...   \n",
       "11554          0.042227          0.038966          0.912885          0.907543   \n",
       "11555          0.277478          0.444294          0.794465          0.794085   \n",
       "11556          0.168887          0.149274          0.839866          0.846077   \n",
       "11557          0.096358          0.128685          0.726397          0.725586   \n",
       "11558          0.293823          0.352750          0.591897          0.605963   \n",
       "\n",
       "       chatgpt_SP_6 (Y)  \n",
       "0              0.205009  \n",
       "1              0.664460  \n",
       "2              0.692664  \n",
       "3              0.245129  \n",
       "4              0.084049  \n",
       "...                 ...  \n",
       "11554          0.043510  \n",
       "11555          0.277307  \n",
       "11556          0.168443  \n",
       "11557          0.100972  \n",
       "11558          0.272084  \n",
       "\n",
       "[11559 rows x 64 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_A_train.iloc[0:][bigcut]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install transformers\n",
    "!pip install datasets\n",
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dccuchile/bert-base-spanish-wwm-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model_name = \"dccuchile/bert-base-spanish-wwm-cased\"\n",
    "beto_model = BertModel.from_pretrained(model_name)\n",
    "beto_tokenizer = BertTokenizer.from_pretrained(model_name, do_lower_case=False)\n",
    "e = beto_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['[UNK]', '[SEP]', '[PAD]', '[CLS]', '[MASK]'], [3, 5, 1, 4, 0])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beto_tokenizer.all_special_tokens, beto_tokenizer.all_special_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "class DatasetTaskC1(Dataset):\n",
    "    def __init__(self, df, maxlen):\n",
    "        self.df = df\n",
    "        self.tokenizer = beto_tokenizer\n",
    "        self.maxlen = maxlen\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        sentence1 = str(self.df.loc[index, 'Q'])\n",
    "        sentence2 = str(self.df.loc[index, 'A'])\n",
    "        \n",
    "        sentence1 = \" \".join(str(sentence1).replace(\"\\n\", \" \").split())\n",
    "        sentence2 = \" \".join(str(sentence2).replace(\"\\n\", \" \").split())\n",
    "\n",
    "        label = self.df.loc[index, 'label']\n",
    "        \n",
    "        tokens1 = self.tokenizer.tokenize(sentence1) if len(sentence1)>0 else [\"[UNK]\"]\n",
    "        tokens2 = self.tokenizer.tokenize(sentence2) if len(sentence2)>0 else [\"[UNK]\"]\n",
    "\n",
    "        if len(tokens1) < self.maxlen:\n",
    "            tokens1 = tokens1 + ['[PAD]' for _ in range(self.maxlen - len(tokens1))]\n",
    "        else:\n",
    "            tokens1 = tokens1[:self.maxlen]\n",
    "\n",
    "        if len(tokens2) < self.maxlen:\n",
    "            tokens2 = tokens2 + ['[PAD]' for _ in range(self.maxlen - len(tokens2))]\n",
    "        else:\n",
    "            tokens2 = tokens2[:self.maxlen]\n",
    "          \n",
    "        tokens = [\"[CLS]\"]+tokens1+[\"[SEP]\"]+tokens2+[\"[SEP]\"]\n",
    "        tokens_ids = self.tokenizer.convert_tokens_to_ids(tokens)\n",
    "        tokens_ids_tensor = torch.tensor(tokens_ids)\n",
    "        attn_mask = (tokens_ids_tensor != 1).long() # [PAD] => 1\n",
    "\n",
    "        mf_tensor = torch.tensor(self.df.loc[index, :][bigcut])\n",
    "\n",
    "        return mf_tensor, tokens_ids_tensor, attn_mask, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_set = DatasetTaskC1(df = new_A_train, maxlen = 60)\n",
    "val_set = DatasetTaskC1(df = new_A_test, maxlen = 60)\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size = 32, num_workers = 2, shuffle=False)\n",
    "val_loader = DataLoader(val_set, batch_size = 32, num_workers = 2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class C1Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(C1Classifier, self).__init__()\n",
    "        torch.manual_seed(2022)\n",
    "        \n",
    "        self.bert_layer = BertModel.from_pretrained(model_name).cuda()\n",
    "        self.cls_layer = nn.Linear(64+768, 2).cuda()\n",
    "        # self.cls_layer2 = nn.Linear(768, 2).cuda()\n",
    "\n",
    "    def forward(self, mfs, seq, attn_masks):\n",
    "\n",
    "        cont_reps = self.bert_layer(seq, attention_mask=attn_masks)\n",
    "        \n",
    "        cls_rep = cont_reps.last_hidden_state[:, 0]\n",
    "        mfs = mfs.to(cls_rep.dtype)\n",
    "        cls_rep = torch.cat((mfs,cls_rep), 1)\n",
    "\n",
    "        logits = self.cls_layer(cls_rep)\n",
    "        # logits = self.cls_layer2(inter)\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dccuchile/bert-base-spanish-wwm-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "net = C1Classifier()\n",
    "\n",
    "weights = torch.tensor([1., 6.5])\n",
    "criterion = nn.CrossEntropyLoss(weight=weights, reduction='mean').cuda()\n",
    "\n",
    "opti = optim.Adam(net.parameters(), lr = 2e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy_from_logits(logits, labels):\n",
    "    probs = torch.sigmoid(logits)\n",
    "    soft_probs = probs.argmax(1)\n",
    "    acc = (soft_probs.squeeze() == labels).float().mean()\n",
    "    return acc\n",
    "    \n",
    "def evaluate(net, criterion, dataloader):\n",
    "    net.eval()\n",
    "    mean_acc, mean_loss = 0, 0\n",
    "    count = 0\n",
    "    with torch.no_grad():\n",
    "        for mfs, seq, attn_masks, labels in dataloader:\n",
    "            mfs, seq, attn_masks, labels = mfs.cuda(), seq.cuda(), attn_masks.cuda(), labels.cuda()\n",
    "            logits = net(mfs, seq, attn_masks)\n",
    "            mean_loss += criterion(logits, labels).item()\n",
    "            mean_acc += get_accuracy_from_logits(logits, labels)\n",
    "            count += 1\n",
    "\n",
    "    return mean_acc / count, mean_loss / count\n",
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def evaluate_precision_recall_fscore_support(net, dataloader):\n",
    "    net.eval()\n",
    "    preds = []\n",
    "    tests = []\n",
    "    with torch.no_grad():\n",
    "        for mfs, seq, attn_masks, labels in dataloader:\n",
    "            mfs, seq, attn_masks, labels = mfs.cuda(), seq.cuda(), attn_masks.cuda(), labels.cuda()\n",
    "            logits = net(mfs, seq, attn_masks)\n",
    "            probs = torch.sigmoid(logits)\n",
    "            soft_probs = probs.argmax(1)\n",
    "            preds += soft_probs.squeeze().tolist()\n",
    "            tests += labels.tolist()\n",
    "    return tests, preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, criterion, opti, train_loader, val_loader, epochs):\n",
    "    for ep in range(epochs):\n",
    "        for it, (mfs, seq, attn_masks, labels) in enumerate(train_loader):\n",
    "            opti.zero_grad()  \n",
    "\n",
    "            mfs, seq, attn_masks, labels = mfs.cuda(), seq.cuda(), attn_masks.cuda(), labels.cuda()\n",
    "\n",
    "            logits = net(mfs, seq, attn_masks)\n",
    "\n",
    "            loss = criterion(logits, labels)\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            opti.step()\n",
    "\n",
    "            if (it + 1) % 100 == 0:\n",
    "                acc = get_accuracy_from_logits(logits, labels)\n",
    "                # tests, preds = evaluate_precision_recall_fscore_support(net, train_loader)\n",
    "                # print(classification_report(tests, preds))\n",
    "                print(\"Iteration {} of epoch {} complete. Loss : {} Train Accuracy : {}\".format(it+1, ep+1, loss.item(), acc))\n",
    "        val_acc, val_loss = evaluate(net, criterion, val_loader)\n",
    "        tests, preds = evaluate_precision_recall_fscore_support(net, val_loader)\n",
    "        print(classification_report(tests, preds))\n",
    "        print(\"Epoch {} complete! Validation Accuracy : {}, Validation Loss : {}\".format(ep+1, val_acc, val_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 100 of epoch 1 complete. Loss : 0.28104883432388306 Train Accuracy : 0.9375\n",
      "Iteration 200 of epoch 1 complete. Loss : 0.1956568956375122 Train Accuracy : 0.96875\n",
      "Iteration 300 of epoch 1 complete. Loss : 0.4584180414676666 Train Accuracy : 0.9375\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94       541\n",
      "           1       0.77      0.76      0.77       136\n",
      "\n",
      "    accuracy                           0.91       677\n",
      "   macro avg       0.86      0.85      0.85       677\n",
      "weighted avg       0.91      0.91      0.91       677\n",
      "\n",
      "Epoch 1 complete! Validation Accuracy : 0.9105113744735718, Validation Loss : 0.35147314180027356\n"
     ]
    }
   ],
   "source": [
    "epochs = 1\n",
    "train(net, criterion, opti, train_loader, val_loader, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'notebook_login' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m notebook_login()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'notebook_login' is not defined"
     ]
    }
   ],
   "source": [
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git config --global credential.helper store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'net' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m repo_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbeto_best_nllf_ft_task_C1\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m net\u001b[39m.\u001b[39mbert_layer\u001b[39m.\u001b[39mpush_to_hub(repo_name)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'net' is not defined"
     ]
    }
   ],
   "source": [
    "repo_name = \"beto_best_nllf_ft_task_C1\"\n",
    "net.bert_layer.push_to_hub(repo_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'val_set' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m val_set\u001b[39m.\u001b[39mtokenizer\u001b[39m.\u001b[39mpush_to_hub(repo_name)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'val_set' is not defined"
     ]
    }
   ],
   "source": [
    "val_set.tokenizer.push_to_hub(repo_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.cls_layer, \"cls_layer.torch\")\n",
    "# torch.save(net.cls_layer2, \"cls_layer2.torch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import hf_hub_url, cached_download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hf_hub_url' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m repo_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbeto_best_nllf_ft_task_C1\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m config_file_url \u001b[39m=\u001b[39m hf_hub_url(\u001b[39m\"\u001b[39m\u001b[39mX/\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m+\u001b[39mrepo_name, filename\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcls_layer.torch\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m value \u001b[39m=\u001b[39m cached_download(config_file_url)\n\u001b[1;32m      4\u001b[0m cls_layer \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mload(value)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'hf_hub_url' is not defined"
     ]
    }
   ],
   "source": [
    "repo_name = \"beto_best_nllf_ft_task_C1\"\n",
    "config_file_url = hf_hub_url(\"X/\"+repo_name, filename=\"cls_layer.torch\")\n",
    "value = cached_download(config_file_url)\n",
    "cls_layer = torch.load(value)\n",
    "# config_file_url = hf_hub_url(\"X/\"+repo_name, filename=\"cls_layer2.torch\")\n",
    "# value = cached_download(config_file_url)\n",
    "# cls_layer2 = torch.load(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c215f7f66cd64408b41542dd76d6eb31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/439M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "beto_model = BertModel.from_pretrained(\"X/\"+repo_name).cuda()\n",
    "beto_tokenizer = BertTokenizer.from_pretrained(\"X/\"+repo_name, do_lower_case=False)\n",
    "e = beto_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproccesing(Q, A, maxlen=60):\n",
    "        sentence1 = str(Q)\n",
    "        sentence2 = str(A)\n",
    "        \n",
    "        sentence1 = \" \".join(str(sentence1).replace(\"\\n\", \" \").split())\n",
    "        sentence2 = \" \".join(str(sentence2).replace(\"\\n\", \" \").split())\n",
    "        \n",
    "        tokens1 = beto_tokenizer.tokenize(sentence1) if len(sentence1)>0 else [\"[UNK]\"]\n",
    "        tokens2 = beto_tokenizer.tokenize(sentence2) if len(sentence2)>0 else [\"[UNK]\"]\n",
    "\n",
    "        if len(tokens1) < maxlen:\n",
    "            tokens1 = tokens1 + ['[PAD]' for _ in range(maxlen - len(tokens1))]\n",
    "        else:\n",
    "            tokens1 = tokens1[:maxlen]\n",
    "\n",
    "        if len(tokens2) < maxlen:\n",
    "            tokens2 = tokens2 + ['[PAD]' for _ in range(maxlen - len(tokens2))]\n",
    "        else:\n",
    "            tokens2 = tokens2[:maxlen]\n",
    "          \n",
    "        tokens = [\"[CLS]\"]+tokens1+[\"[SEP]\"]+tokens2+[\"[SEP]\"]\n",
    "        # tokens = [x for x in tokens if x!=\"[PAD]\"]\n",
    "        tokens_ids = beto_tokenizer.convert_tokens_to_ids(tokens)\n",
    "        tokens_ids_tensor = torch.tensor(tokens_ids)\n",
    "        attn_mask = (tokens_ids_tensor != 1).long() # [PAD] => 1\n",
    "\n",
    "        return tokens_ids_tensor.cuda(), attn_mask.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def C1Classifier(mfs, Q, A):\n",
    "    tokens_ids_tensor, attn_mask = preproccesing(Q, A)\n",
    "    cont_reps = beto_model(tokens_ids_tensor.unsqueeze(0), attention_mask = attn_mask.unsqueeze(0))\n",
    "    cls_rep = cont_reps.last_hidden_state[:, 0]\n",
    "    mfs = torch.tensor(mfs).cuda()\n",
    "    mfs = mfs.to(cls_rep.dtype).unsqueeze(0)\n",
    "    cls_rep = torch.cat((mfs,cls_rep), 1)\n",
    "    logits = cls_layer(cls_rep)\n",
    "    # logits = cls_layer2(inter)\n",
    "    probs = torch.sigmoid(logits)\n",
    "    return probs.detach().cpu().numpy()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Luis comprÃ³ 10 caramelos, de los cuales 4 tenÃ­an menta, los demÃ¡s no. Â¿CuÃ¡ntos caramelos no tenÃ­an menta? Representa esta ecuaciÃ³n.',) tiene 30 en total\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.6068136, 0.553164 ], dtype=float32)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 0\n",
    "mfs = new_A_train.iloc[i][bigcut]\n",
    "Q = A_train.iloc[i][\"Q\"], \n",
    "A = A_train.iloc[i][\"A\"]\n",
    "print(Q, A)\n",
    "C1Classifier(mfs, Q, A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 41s, sys: 16.2 ms, total: 1min 41s\n",
      "Wall time: 1min 41s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.986329</td>\n",
       "      <td>0.912224</td>\n",
       "      <td>0.976469</td>\n",
       "      <td>0.949276</td>\n",
       "      <td>0.976456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.986526</td>\n",
       "      <td>0.911039</td>\n",
       "      <td>0.976469</td>\n",
       "      <td>0.948782</td>\n",
       "      <td>0.976469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.986427</td>\n",
       "      <td>0.911631</td>\n",
       "      <td>0.976469</td>\n",
       "      <td>0.949029</td>\n",
       "      <td>0.976462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>10019.000000</td>\n",
       "      <td>1540.000000</td>\n",
       "      <td>0.976469</td>\n",
       "      <td>11559.000000</td>\n",
       "      <td>11559.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      0            1  accuracy     macro avg  weighted avg\n",
       "precision      0.986329     0.912224  0.976469      0.949276      0.976456\n",
       "recall         0.986526     0.911039  0.976469      0.948782      0.976469\n",
       "f1-score       0.986427     0.911631  0.976469      0.949029      0.976462\n",
       "support    10019.000000  1540.000000  0.976469  11559.000000  11559.000000"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = [ int(\n",
    "    C1Classifier(\n",
    "        mfs=new_A_train.iloc[i][bigcut], \n",
    "        Q=A_train.iloc[i][\"Q\"], \n",
    "        A=A_train.iloc[i][\"A\"]\n",
    "        )[0]<0.5) \n",
    "    for i in range(A_train.shape[0])\n",
    "]\n",
    "report = classification_report(A_train[\"label\"], y_pred, output_dict=True)\n",
    "train_report = pd.DataFrame(report)\n",
    "train_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(y_pred, open(\"data/y_pred_train_beto_best_nllf_ft_task_C1.pickle\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 25.4 s, sys: 4.05 ms, total: 25.4 s\n",
      "Wall time: 25.4 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.969243</td>\n",
       "      <td>0.856354</td>\n",
       "      <td>0.955141</td>\n",
       "      <td>0.912798</td>\n",
       "      <td>0.954129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.979283</td>\n",
       "      <td>0.798969</td>\n",
       "      <td>0.955141</td>\n",
       "      <td>0.889126</td>\n",
       "      <td>0.955141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.974237</td>\n",
       "      <td>0.826667</td>\n",
       "      <td>0.955141</td>\n",
       "      <td>0.900452</td>\n",
       "      <td>0.954479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>2510.000000</td>\n",
       "      <td>388.000000</td>\n",
       "      <td>0.955141</td>\n",
       "      <td>2898.000000</td>\n",
       "      <td>2898.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     0           1  accuracy    macro avg  weighted avg\n",
       "precision     0.969243    0.856354  0.955141     0.912798      0.954129\n",
       "recall        0.979283    0.798969  0.955141     0.889126      0.955141\n",
       "f1-score      0.974237    0.826667  0.955141     0.900452      0.954479\n",
       "support    2510.000000  388.000000  0.955141  2898.000000   2898.000000"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = [ int(\n",
    "    C1Classifier(\n",
    "        new_A_val.iloc[i][bigcut], \n",
    "        A_val.iloc[i][\"Q\"], \n",
    "        A_val.iloc[i][\"A\"]\n",
    "        )[0]<0.5) \n",
    "    for i in range(A_val.shape[0])]\n",
    "report = classification_report(A_val[\"label\"], y_pred, output_dict=True)\n",
    "val_report = pd.DataFrame(report)\n",
    "val_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(y_pred, open(\"data/y_pred_val_beto_best_nllf_ft_task_C1.pickle\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.69 s, sys: 3.96 ms, total: 5.69 s\n",
      "Wall time: 5.69 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.929856</td>\n",
       "      <td>0.801653</td>\n",
       "      <td>0.906942</td>\n",
       "      <td>0.865755</td>\n",
       "      <td>0.904102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.955638</td>\n",
       "      <td>0.713235</td>\n",
       "      <td>0.906942</td>\n",
       "      <td>0.834437</td>\n",
       "      <td>0.906942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.942571</td>\n",
       "      <td>0.754864</td>\n",
       "      <td>0.906942</td>\n",
       "      <td>0.848717</td>\n",
       "      <td>0.904863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>541.000000</td>\n",
       "      <td>136.000000</td>\n",
       "      <td>0.906942</td>\n",
       "      <td>677.000000</td>\n",
       "      <td>677.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0           1  accuracy   macro avg  weighted avg\n",
       "precision    0.929856    0.801653  0.906942    0.865755      0.904102\n",
       "recall       0.955638    0.713235  0.906942    0.834437      0.906942\n",
       "f1-score     0.942571    0.754864  0.906942    0.848717      0.904863\n",
       "support    541.000000  136.000000  0.906942  677.000000    677.000000"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = [ int(\n",
    "    C1Classifier(\n",
    "        new_A_test.iloc[i][bigcut], \n",
    "        A_test.iloc[i][\"Q\"], \n",
    "        A_test.iloc[i][\"A\"]\n",
    "        )[0]<0.5) \n",
    "    for i in range(A_test.shape[0])]\n",
    "report = classification_report(A_test[\"label\"], y_pred, output_dict=True)\n",
    "test_report = pd.DataFrame(report)\n",
    "test_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(y_pred, open(\"data/y_pred_test_beto_best_nllf_ft_task_C1.pickle\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9808    0.9771    0.9790       262\n",
      "           1     0.8571    0.8780    0.8675        41\n",
      "\n",
      "    accuracy                         0.9637       303\n",
      "   macro avg     0.9190    0.9276    0.9232       303\n",
      "weighted avg     0.9641    0.9637    0.9639       303\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import pickle\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "file_names = {\n",
    "    \"train\": \"data/train_task_C1.xlsx\",\n",
    "    \"test\": \"data/test_task_C1.xlsx\",\n",
    "    \"val\": \"data/val_task_C1.xlsx\",\n",
    "    \"mf_train\": \"data/mf_features_train_task_C1.xlsx\",\n",
    "    \"mf_test\": \"data/mf_features_test_task_C1.xlsx\",\n",
    "    \"mf_val\": \"data/mf_features_val_task_C1.xlsx\",\n",
    "}\n",
    "A_test = pd.read_excel(file_names[\"test\"])\n",
    "test_label_Q = pd.read_excel(\"data/gpt_label_v7_comp.xlsx\")\n",
    "A_test[\"label_Q\"] = A_test.apply(lambda x: test_label_Q[test_label_Q[\"id\"] == x[\"id\"]].iloc[0][\"tipo_preg\"], axis=1)\n",
    "y_pred = pickle.load(open(\"data/y_pred_test_beto_best_nllf_ft_task_C1.pickle\", \"rb\"))\n",
    "sub_index_test = A_test[\"label_Q\"] == 3\n",
    "print(classification_report(A_test.loc[A_test[sub_index_test].index][\"label\"], np.array(y_pred)[sub_index_test.values], digits=4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "net",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7108851178047dc680433843b93ee0e3779b5b27b2c4cebb614195d20b26b968"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
